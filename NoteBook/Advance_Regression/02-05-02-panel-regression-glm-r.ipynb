{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOS1fD5tZP7KR8GvoLCAIu7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-05-02-panel-regression-glm-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ],
      "metadata": {
        "id": "4qrItz_mJNWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.  Generalized Linear Models for Panel Data in R\n",
        "\n",
        "This tutorial demonstrates how to perform Generalized Linear Models for Panel Data in R. The GLM for Panel Data extends traditional GLMs to handle correlated observations in longitudinal or panel datasets."
      ],
      "metadata": {
        "id": "Dzp9ZseROTcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Generalized Linear Models (GLMs) for Panel Data extend traditional GLMs to handle correlated observations in longitudinal or panel datasets.\n",
        "These models account for within-subject or within-group correlations arising from repeated measurements over time, while accommodating non-normal response variables (e.g., binary, count, or ordinal outcomes).\n",
        "Below is a structured explanation:\n",
        "\n",
        "GLMs generalize linear regression by allowing:\n",
        "\n",
        "-   Non-normal distributions (e.g., binomial, Poisson).\\\n",
        "-   A link function (e.g., logit, log) connecting the linear predictor to the mean of the response.\\\n",
        "-   Model form: $g(E[Y|X]) = \\mathbf{X}\\beta$, where $g$ is the link function.\n",
        "\n",
        "Panel Data Challenges are addressed by GLMs:\n",
        "\n",
        "-   `Within-Subject Correlation`: Repeated measurements violate the independence assumption.\\\n",
        "-   `Unobserved Heterogeneity`: Time-invariant individual/group characteristics.\n",
        "\n",
        "Approaches for Panel Data GLMs are categorized into:\n",
        "\n",
        "-   **Random Effects (Mixed-Effects) Models**: Model individual-specific variability with random effects.\\\n",
        "-   **Generalized Estimating Equations (GEE)**: Account for correlation using a working correlation matrix.\\\n",
        "-   **Fixed Effects Models**: Control for time-invariant confounders via subject-specific intercepts.\n",
        "\n"
      ],
      "metadata": {
        "id": "TpcIOkTs30qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install rpy2"
      ],
      "metadata": {
        "id": "SDp3ULld8Gb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall rpy2 -y\n",
        "!pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "CiM6y-Mw8AJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4e0825-d092-4c56-ece9-6696d74dfbe2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rpy2 3.5.17\n",
            "Uninstalling rpy2-3.5.17:\n",
            "  Successfully uninstalled rpy2-3.5.17\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (3.1.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (2025.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (5.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2==3.5.1) (3.0.2)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp311-cp311-linux_x86_64.whl size=314973 sha256=28063ed14309eaf08b94546263ba9156f63fd8db0faf942b8d727ac1493f7dc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/55/d1/47be85a5f3f1e1f4d1e91cb5e3a4dcb40dd72147f184c5a5ef\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "O1zeuaCowiBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J-4ie4bwiJ1",
        "outputId": "89200c4b-8edc-4a32-8f6a-d0a1b63fca54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required R Packages\n",
        "\n",
        "Following R packages are required to run this notebook. If any of these packages are not installed, you can install them using the code below:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9T5ojBgKBv5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "packages <- c('tidyverse',\n",
        "              'DataExplorer',\n",
        "              'dlookr',\n",
        "              'DataExplorer',\n",
        "              'rstatix',\n",
        "              'corrplot',\n",
        "              'Hmisc',\n",
        "              'tseries',\n",
        "              'stargazer',\n",
        "              'plm',\n",
        "              'panelr',\n",
        "              'pglm',\n",
        "              'AER',\n",
        "              'corrplot',\n",
        "              'lmtest',\n",
        "              'ggstatsplot',\n",
        "              'gtsummary',\n",
        "              'ggExtra',\n",
        "              'gridExtra',\n",
        "              'kableExtra',\n",
        "              'GGally',\n",
        "              'gplots'\n",
        "                )"
      ],
      "metadata": {
        "id": "4ERkgB8gByVX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Install missing packages\n",
        "new.packages <- packages[!(packages %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')"
      ],
      "metadata": {
        "id": "J3nWFZpl-sr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jv6EE7Z-sx-",
        "outputId": "e30b270a-dd1e-427b-b34d-1d4c0895efcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Registered S3 methods overwritten by 'dlookr':\n",
            "  method          from  \n",
            "  plot.transform  scales\n",
            "  print.transform scales\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Registered S3 method overwritten by 'quantmod':\n",
            "  method            from\n",
            "  as.zoo.data.frame zoo \n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Registered S3 method overwritten by 'GGally':\n",
            "  method from   \n",
            "  +.gg   ggplot2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   tidyverse DataExplorer       dlookr DataExplorer      rstatix     corrplot \n",
            "        TRUE         TRUE         TRUE         TRUE         TRUE         TRUE \n",
            "       Hmisc      tseries    stargazer          plm       panelr         pglm \n",
            "        TRUE         TRUE         TRUE         TRUE         TRUE         TRUE \n",
            "         AER     corrplot       lmtest  ggstatsplot    gtsummary      ggExtra \n",
            "        TRUE         TRUE         TRUE         TRUE         TRUE         TRUE \n",
            "   gridExtra   kableExtra       GGally       gplots \n",
            "        TRUE         TRUE         TRUE         TRUE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load R Packages"
      ],
      "metadata": {
        "id": "MV7R29xfyWQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Load packages with suppressed messages\n",
        "invisible(lapply(packages, function(pkg) {\n",
        "  suppressPackageStartupMessages(library(pkg, character.only = TRUE))\n",
        "}))\n",
        "# Check loaded packages\n",
        "cat(\"Successfully loaded packages:\\n\")\n",
        "print(search()[grepl(\"package:\", search())])# Check loaded packages\n"
      ],
      "metadata": {
        "id": "232jNAHBykUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7000f25a-5e81-4439-a3cc-e35490f5b91c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded packages:\n",
            " [1] \"package:gplots\"       \"package:GGally\"       \"package:kableExtra\"  \n",
            " [4] \"package:gridExtra\"    \"package:ggExtra\"      \"package:gtsummary\"   \n",
            " [7] \"package:ggstatsplot\"  \"package:AER\"          \"package:survival\"    \n",
            "[10] \"package:sandwich\"     \"package:lmtest\"       \"package:zoo\"         \n",
            "[13] \"package:car\"          \"package:carData\"      \"package:pglm\"        \n",
            "[16] \"package:maxLik\"       \"package:miscTools\"    \"package:panelr\"      \n",
            "[19] \"package:lme4\"         \"package:Matrix\"       \"package:plm\"         \n",
            "[22] \"package:stargazer\"    \"package:tseries\"      \"package:Hmisc\"       \n",
            "[25] \"package:corrplot\"     \"package:rstatix\"      \"package:dlookr\"      \n",
            "[28] \"package:DataExplorer\" \"package:lubridate\"    \"package:forcats\"     \n",
            "[31] \"package:stringr\"      \"package:dplyr\"        \"package:purrr\"       \n",
            "[34] \"package:readr\"        \"package:tidyr\"        \"package:tibble\"      \n",
            "[37] \"package:ggplot2\"      \"package:tidyverse\"    \"package:tools\"       \n",
            "[40] \"package:stats\"        \"package:graphics\"     \"package:grDevices\"   \n",
            "[43] \"package:utils\"        \"package:datasets\"     \"package:methods\"     \n",
            "[46] \"package:base\"        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit Panel Generalized Linear Models (GLMs) in R\n",
        "\n",
        "Below is a step-by-step guide to fitting panel estimators for Generalized Linear Models (GLMs) using the `{pglm]` package in R for different distributions.\n",
        "`pglm()` function estimates the maximum likelihood of GLM (binomial and Poisson) and 'glm-like' models (Negbin and ordered) on longitudinal data.\n",
        "The function is similar to `plm()` for linear models but extends to non-Gaussian families."
      ],
      "metadata": {
        "id": "_tOKehw6B8ln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gaussian Model\n",
        "\n",
        "The Gaussian model is a linear panel regression model that assumes a Gaussian distribution for the response variable.\n",
        "It is suitable for continuous outcomes.\n",
        "In this example, we will use the `Hedonic` dataset from the `plm` package to predict median house values (`mv`) using structural variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "rSJqB05rO5ES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFpt_H01OPsa",
        "outputId": "f986672b-5a01-4134-b0ed-96eab76e8b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mv    crim zn    indus chas     nox      rm      age     dis     rad\n",
            "1 10.08580 0.00632 18 2.309999   no 28.9444 43.2306 65.19995 1.40854 0.00000\n",
            "2  9.98045 0.02731  0 7.070000   no 21.9961 41.2292 78.89996 1.60283 0.69315\n",
            "3 10.45450 0.02730  0 7.070000   no 21.9961 51.6242 61.09998 1.60283 0.69315\n",
            "4 10.41630 0.03237  0 2.179998   no 20.9764 48.9720 45.79999 1.80207 1.09861\n",
            "5 10.49680 0.06905  0 2.179998   no 20.9764 51.0796 54.19998 1.80207 1.09861\n",
            "6 10.26470 0.02985  0 2.179998   no 20.9764 41.3449 58.69998 1.80207 1.09861\n",
            "  tax  ptratio  blacks    lstat townid\n",
            "1 296 15.29999 0.39690 -3.00074      1\n",
            "2 242 17.79999 0.39690 -2.39251      2\n",
            "3 242 17.79999 0.39283 -3.21165      2\n",
            "4 222 18.70000 0.39464 -3.52744      3\n",
            "5 222 18.70000 0.39690 -2.93163      3\n",
            "6 222 18.70000 0.39412 -2.95555      3\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Load the Hedonic dataset\n",
        "data(\"Hedonic\", package = \"plm\")\n",
        "head(Hedonic)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code  below fits a Gaussian regression model for panel data, where the dependent variable is the median value of owner-occupied homes (`mv`). The model includes various socio-economic and environmental factors as independent variables. The data is from the Hedonic data frame, and the model uses random effects to account for town-specific effects. The estimation process includes a moderate level of printed output and uses the Newton-Raphson method for optimization (`methos = \"nr`). The `Newton-Raphson` method is an iterative numerical technique used for finding the roots of a real-valued function. In the context of estimation, especially in maximum likelihood estimation (MLE), it is used to find the parameter values that maximize (or minimize) a given likelihood function. The `family = gaussian` specifies the Gaussian distribution for the dependent variable."
      ],
      "metadata": {
        "id": "I8dFM0UCCpWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Fit random effects model\n",
        "gaussian_model <- pglm(mv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax,\n",
        "                       data = Hedonic,\n",
        "                       model = \"random\",  # Random effects\n",
        "                       print.level = 2,\n",
        "                       method = \"nr\",\n",
        "                       family = gaussian,\n",
        "                       index = \"townid\")  # Adjust index if needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmtJFmCMCpig",
        "outputId": "5263961b-f367-4b25-ddf0-2ebba1335e7e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Initial parameters: -----\n",
            "fcn value: 101.4937 \n",
            "                parameter initial gradient free\n",
            "(Intercept) 10.1431982409         48.71098    1\n",
            "crim        -0.0152229003       5341.74746    1\n",
            "zn           0.0016597986        212.90370    1\n",
            "indus       -0.0038685279        649.10677    1\n",
            "chasyes      0.1627672799       -158.82467    1\n",
            "nox         -0.0062097842       -703.80929    1\n",
            "rm           0.0197078131        335.94104    1\n",
            "age         -0.0033657047       2222.21444    1\n",
            "dis         -0.2887445566         93.45003    1\n",
            "rad          0.0788325926        145.00932    1\n",
            "tax         -0.0007227763      31581.07251    1\n",
            "sd.id        0.1653761061        -85.03668    1\n",
            "sd.idios     0.1588553097        518.07729    1\n",
            "Condition number of the (active) hessian: 6477161 \n",
            "-----Iteration 1 -----\n",
            "-----Iteration 2 -----\n",
            "-----Iteration 3 -----\n",
            "-----Iteration 4 -----\n",
            "-----Iteration 5 -----\n",
            "--------------\n",
            "successive function values within relative tolerance limit (reltol) \n",
            "5  iterations\n",
            "estimate: 10.0683 -0.007645667 0.0007862368 -0.001630563 -0.01850326 -0.01001396 0.01854551 -0.003185649 -0.1931323 0.09509491 -0.0005449124 0.173103 0.1546246 \n",
            "Function value: 144.058 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "summary(gaussian_model)"
      ],
      "metadata": {
        "id": "tO4j13t1IAjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e6aa03-9e36-4cce-a931-bb8c622181be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "Maximum Likelihood estimation\n",
            "Newton-Raphson maximisation, 5 iterations\n",
            "Return code 8: successive function values within relative tolerance limit (reltol)\n",
            "Log-Likelihood: 144.058 \n",
            "13  free parameters\n",
            "Estimates:\n",
            "              Estimate Std. error t value  Pr(> t)    \n",
            "(Intercept) 10.0682995  0.1436021  70.112  < 2e-16 ***\n",
            "crim        -0.0076457  0.0012114  -6.311 2.77e-10 ***\n",
            "zn           0.0007862  0.0008344   0.942 0.346031    \n",
            "indus       -0.0016306  0.0054942  -0.297 0.766634    \n",
            "chasyes     -0.0185033  0.0344964  -0.536 0.591695    \n",
            "nox         -0.0100140  0.0014160  -7.072 1.53e-12 ***\n",
            "rm           0.0185455  0.0010675  17.373  < 2e-16 ***\n",
            "age         -0.0031856  0.0004959  -6.423 1.33e-10 ***\n",
            "dis         -0.1931323  0.0572119  -3.376 0.000736 ***\n",
            "rad          0.0950949  0.0356706   2.666 0.007678 ** \n",
            "tax         -0.0005449  0.0002374  -2.296 0.021688 *  \n",
            "sd.id        0.1731030  0.0161897  10.692  < 2e-16 ***\n",
            "sd.idios     0.1546246  0.0053279  29.022  < 2e-16 ***\n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the summary output, we can interpret the coefficients of the structural variables (e.g., `rm` for rooms) and the random effects variance (`sigma_u` for individual, `sigma_e` for error)."
      ],
      "metadata": {
        "id": "DNRujh50CPxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordinal Probit Model\n",
        "\n",
        "The ordinal probit model is used to predict ordinal outcomes with an underlying continuous latent variable.\n",
        "In this example, we will use the `Fairness` dataset from the `pglm` package to predict fairness ratings (`fair`) using income and demographic variables."
      ],
      "metadata": {
        "id": "GNZC5A35CStk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "data(\"Fairness\", package = \"pglm\")        # Ordinal probit\n",
        "head(Fairness)"
      ],
      "metadata": {
        "id": "WTF2ZhKsINZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767f6184-3729-4b66-ce4b-62decab37f87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  id answer good         rule driving education recurring\n",
            "1  1      0  tgv        admin     yes        no        no\n",
            "2  1      0  tgv      lottery     yes        no        no\n",
            "3  1      3  tgv      queuing     yes        no        no\n",
            "4  1      1  tgv compensation     yes        no        no\n",
            "5  1      2  tgv        moral     yes        no        no\n",
            "6  1   <NA>  tgv    addsupply     yes        no        no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code fits an ordinal regression model with a probit link function for panel data, where the dependent variable is the numeric value of an ordinal response (`answer`). The model includes `education` level and `rule`-related factors as independent variables. The data is a subset of the Fairness data frame, specifically the first 105 rows where good is `'parking'`. The model uses an ordinal distribution with a probit link function, the `bfgs` optimization method, and includes `random` effects.  `bfgs` stands for Broyden–Fletcher–Goldfarb–Shanno algorithm, which is an iterative method for solving unconstrained nonlinear optimization problems. The estimation process includes a moderate level of printed output and uses 5 random draws for simulation-based estimation techniques."
      ],
      "metadata": {
        "id": "ypMLAot0CXx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "Parking <- subset(Fairness, good == 'parking')\n",
        "ordinal_model<- pglm(as.numeric(answer) ~ education + rule,\n",
        "           Parking[1:105, ],\n",
        "           family = ordinal('probit'),\n",
        "           R = 5,\n",
        "           print.level = 2,\n",
        "           method = 'bfgs',\n",
        "           index = 'id',\n",
        "           model = \"random\")\n",
        "\n",
        "summary(ordinal_model)"
      ],
      "metadata": {
        "id": "p_eUNGuwDNka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b991a6b-919e-4fbe-8fd5-d00854874dea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial  value 92.307736 \n",
            "iter   2 value 91.435879\n",
            "iter   3 value 91.231157\n",
            "iter   4 value 91.092405\n",
            "iter   5 value 90.945023\n",
            "iter   6 value 90.935860\n",
            "iter   7 value 90.796381\n",
            "iter   8 value 90.719380\n",
            "iter   9 value 90.669391\n",
            "iter  10 value 90.648223\n",
            "iter  11 value 90.646011\n",
            "iter  12 value 90.645785\n",
            "iter  13 value 90.643443\n",
            "iter  14 value 90.641762\n",
            "iter  15 value 90.641645\n",
            "iter  16 value 90.641377\n",
            "iter  17 value 90.641365\n",
            "iter  17 value 90.641365\n",
            "iter  17 value 90.641365\n",
            "final  value 90.641365 \n",
            "converged\n",
            "--------------------------------------------\n",
            "Maximum Likelihood estimation\n",
            "BFGS maximization, 42 iterations\n",
            "Return code 0: successful convergence \n",
            "Log-Likelihood: -90.64137 \n",
            "11  free parameters\n",
            "Estimates:\n",
            "                 Estimate Std. error t value  Pr(> t)    \n",
            "(Intercept)       -0.6829     0.4450  -1.535 0.124873    \n",
            "educationno       -0.1064     0.4560  -0.233 0.815453    \n",
            "ruleadmin          0.3018     0.4859   0.621 0.534543    \n",
            "rulelottery       -0.1740     0.5070  -0.343 0.731444    \n",
            "ruleaddsupply      1.1885     0.4776   2.488 0.012830 *  \n",
            "rulequeuing        3.0946     0.5486   5.641 1.69e-08 ***\n",
            "rulemoral          4.0504     0.6138   6.599 4.13e-11 ***\n",
            "rulecompensation   3.1033     0.5531   5.611 2.01e-08 ***\n",
            "mu_1               1.4203     0.2809   5.057 4.26e-07 ***\n",
            "mu_2               2.9207     0.3824   7.638 2.20e-14 ***\n",
            "sigma              0.8779     0.2450   3.583 0.000339 ***\n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binomial Probit\n",
        "\n",
        "The binomial probit model is used to predict binary outcomes with a probit link function. In this example, we will use the `UnionWage` dataset from the `pglm` package to predict union membership (`union`) using wages and demographic variables."
      ],
      "metadata": {
        "id": "ScXpBMBikzr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "data(\"UnionWage\", package = \"pglm\")       # Binomial probit\n",
        "head(UnionWage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh1DEtUxDSIl",
        "outputId": "0eda9fe8-07c1-4a2c-911c-8636799ac837"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  id year exper health hours married rural school union     wage\n",
            "1 13 1980     1     no  2672       0    no     14    no 1.197540\n",
            "2 13 1981     2     no  2320       0    no     14   yes 1.853060\n",
            "3 13 1982     3     no  2940       0    no     14    no 1.344462\n",
            "4 13 1983     4     no  2960       0    no     14    no 1.433213\n",
            "5 13 1984     5     no  3071       0    no     14    no 1.568125\n",
            "6 13 1985     6     no  2864       0    no     14    no 1.699891\n",
            "           sector       occ   com    region\n",
            "1  businessrepair   service white NorthEast\n",
            "2 personalservice   service white NorthEast\n",
            "3  businessrepair   service white NorthEast\n",
            "4  businessrepair   service white NorthEast\n",
            "5 personalservice  craftfor white NorthEast\n",
            "6  businessrepair manoffpro white NorthEast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The code fits a binomial regression model with a probit link function for panel data, where the dependent variable is union membership. The model includes wage, experience, and rural status as independent variables. The data is pooled across individuals and years, using a binomial distribution with a probit link function and the BFGS optimization method. The estimation process includes detailed printed output and uses 5 random draws for simulation-based estimation techniques. The panel structure is specified by the `id` identifier for individuals and the `year` variable. The `method = \"bfgs\"` pecifies the method used for estimation. `\"bfgs\"` stands for `Broyden–Fletcher–Goldfarb–Shanno` algorithm, which is an iterative method for solving unconstrained nonlinear optimization problems. The `model = \"pooling\"`: Specifies that a pooled model is used, which means that all data points are treated together rather than allowing for individual-specific effects (i.e., no fixed or random effects)."
      ],
      "metadata": {
        "id": "kVpip4LblDjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "binomial_model <- pglm(union ~ wage + exper + rural,\n",
        "                       data= UnionWage,\n",
        "                       family = binomial('probit'),\n",
        "                       model = \"pooling\",\n",
        "                       method = \"bfgs\",\n",
        "                       print.level = 3, R = 5,\n",
        "                       index = c(\"id\", \"year\"))\n",
        "\n",
        "summary(binomial_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQK3Q-3PDjWU",
        "outputId": "6adcb9a3-86d8-415d-d286-f7e2ccb031aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial function value: -2422.802 \n",
            "Initial gradient value:\n",
            "  (Intercept)          wage         exper      ruralyes \n",
            " 5.684342e-14  2.451840e+02  1.026742e+02 -6.714318e+00 \n",
            "initial  value 2422.801633 \n",
            "iter   2 value 2422.139675\n",
            "iter   3 value 2403.731724\n",
            "iter   4 value 2379.712980\n",
            "iter   5 value 2378.086129\n",
            "iter   6 value 2373.508560\n",
            "iter   7 value 2373.493851\n",
            "iter   7 value 2373.493840\n",
            "iter   7 value 2373.493840\n",
            "final  value 2373.493840 \n",
            "converged\n",
            "--------------------------------------------\n",
            "Maximum Likelihood estimation\n",
            "BFGS maximization, 37 iterations\n",
            "Return code 0: successful convergence \n",
            "Log-Likelihood: -2373.494 \n",
            "4  free parameters\n",
            "Estimates:\n",
            "             Estimate Std. error t value Pr(> t)    \n",
            "(Intercept) -1.348722   0.084777 -15.909  <2e-16 ***\n",
            "wage         0.416122   0.043021   9.673  <2e-16 ***\n",
            "exper       -0.008492   0.007697  -1.103   0.270    \n",
            "ruralyes     0.038684   0.052845   0.732   0.464    \n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Poisson Model\n",
        "\n",
        "The Poisson model is used to predict count outcomes with a log link function.\n",
        "In this example, we will use the `PatentsRDUS` dataset from the `pglm` package to predict patent counts (`patents`) using R&D spending (`rd`) and year."
      ],
      "metadata": {
        "id": "aP-ASSfDDzqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "data(\"PatentsRDUS\", package = \"pglm\")     # Poisson/Negative binomial\n",
        "head(PatentsRDUS)"
      ],
      "metadata": {
        "id": "8nCTpa_mD3Tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8cd596-8814-48ab-ccdc-37021c70ecd3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  cusip year ardssic scisect  capital72 sumpat         rd patents\n",
            "1   800 1970      15      no 438.605335    354  2.7097056      30\n",
            "2  1030 1970      14     yes   7.206043     13  0.6324526       3\n",
            "3  2824 1970       4     yes 284.004476    493 29.6819762      48\n",
            "4  4644 1970      13      no   1.981333      2  1.7218512       1\n",
            "5  7842 1970      16      no   7.880017     12  1.4845475       2\n",
            "6 10202 1970       3      no 396.533291    393  7.8366387      32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code fits a Poisson model with lagged R&D spending and sector variables as predictors. The code fits a Poisson regression model for panel data, where the dependent variable is the number of `patents`. The model incorporates lagged values of the logarithm of R&D expenditure, a scientific sector variable, the logarithm of capital from 1972, and year-specific effects. `lag(log(rd), 0:5)`: This term includes the current value and the lagged values (up to 5 lags) of the logarithm of `rd` (research and development expenditure). The data is pooled across firms and years, using a Poisson distribution and the `Newton-Raphson` method for estimation. The panel structure is specified by the `cusip` identifier for firms and the year variable. `model = \"pooling\"`: Specifies that a pooled model is used, which means that all data points are treated together rather than allowing for individual-specific effects (i.e., no fixed or random effects)."
      ],
      "metadata": {
        "id": "BFR0ja9GC6bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "poisson_model <- pglm(patents ~ lag(log(rd), 0:5) + scisect + log(capital72) + factor(year),\n",
        "                      data = PatentsRDUS,\n",
        "                      family = poisson,\n",
        "                      model = \"pooling\",\n",
        "                      index = c(\"cusip\", \"year\"),\n",
        "                      print.level = 0,\n",
        "                      method=\"nr\")\n",
        "\n",
        "summary(poisson_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzCy7aCJUvbP",
        "outputId": "9c751970-ceab-487d-d614-1f9df870f1a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "Maximum Likelihood estimation\n",
            "Newton-Raphson maximisation, 6 iterations\n",
            "Return code 8: successive function values within relative tolerance limit (reltol)\n",
            "Log-Likelihood: -17834.14 \n",
            "13  free parameters\n",
            "Estimates:\n",
            "                    Estimate Std. error t value  Pr(> t)    \n",
            "(Intercept)         0.809910   0.021189  38.224  < 2e-16 ***\n",
            "lag(log(rd), 0:5)0  0.134525   0.030718   4.379 1.19e-05 ***\n",
            "lag(log(rd), 0:5)1 -0.052944   0.042797  -1.237 0.216050    \n",
            "lag(log(rd), 0:5)2  0.008229   0.039784   0.207 0.836126    \n",
            "lag(log(rd), 0:5)3  0.066097   0.036969   1.788 0.073789 .  \n",
            "lag(log(rd), 0:5)4  0.090181   0.033336   2.705 0.006826 ** \n",
            "lag(log(rd), 0:5)5  0.239538   0.022460  10.665  < 2e-16 ***\n",
            "scisectyes          0.454310   0.009242  49.155  < 2e-16 ***\n",
            "log(capital72)      0.252863   0.004414  57.283  < 2e-16 ***\n",
            "factor(year)1976   -0.043515   0.013121  -3.316 0.000912 ***\n",
            "factor(year)1977   -0.052441   0.013288  -3.947 7.93e-05 ***\n",
            "factor(year)1978   -0.170242   0.013530 -12.583  < 2e-16 ***\n",
            "factor(year)1979   -0.201879   0.013534 -14.917  < 2e-16 ***\n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative Binomial\n",
        "\n",
        "The negative binomial model is used to predict count outcomes with overdispersion. In this example, we will use the `PatentsRDUS` dataset from the `pglm` package to predict patent counts (`patents`) using R&D spending (`rd`) and year."
      ],
      "metadata": {
        "id": "BHE412vmlYZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "data(\"PatentsRDUS\", package = \"pglm\")     # Poisson/Negative binomial\n",
        "head(PatentsRDUS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzedGbrtW3Ya",
        "outputId": "ea0e58ae-810f-4b7b-c24c-de92609e0a8f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  cusip year ardssic scisect  capital72 sumpat         rd patents\n",
            "1   800 1970      15      no 438.605335    354  2.7097056      30\n",
            "2  1030 1970      14     yes   7.206043     13  0.6324526       3\n",
            "3  2824 1970       4     yes 284.004476    493 29.6819762      48\n",
            "4  4644 1970      13      no   1.981333      2  1.7218512       1\n",
            "5  7842 1970      16      no   7.880017     12  1.4845475       2\n",
            "6 10202 1970       3      no 396.533291    393  7.8366387      32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below fits a Negative Binomial regression model for panel data, where the dependent variable is the number of patents. The model incorporates lagged values of the logarithm of R&D expenditure, a scientific sector variable, the logarithm of capital from 1972, and year-specific effects. The data is from the PatentsRDUS data frame, and the model (`model= \"within\"`)  uses fixed effects to control for individual-specific effects. The estimation process includes a low level of printed output and uses the Newton-Raphson method (`method = \"nr\"`) for optimization. The Negative Binomial family (` family = negbin`)is appropriate for modeling overdispersed count data. The panel structure is specified by the `cusip` identifier for firms and the year variable."
      ],
      "metadata": {
        "id": "sxYaQ_y0DL-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "negbin_model <- pglm(patents ~ lag(log(rd), 0:5) + scisect + log(capital72) + factor(year),\n",
        "                     data = PatentsRDUS,\n",
        "                     family = negbin,\n",
        "                     model = \"within\",\n",
        "                     print.level = 1,\n",
        "                     method = \"nr\",\n",
        "                    index = c('cusip', 'year'))\n",
        "\n",
        "summary(negbin_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnXig8cNXqKq",
        "outputId": "70845c56-8f48-4068-de71-462c833548d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------\n",
            "successive function values within relative tolerance limit (reltol) \n",
            "4  iterations\n",
            "estimate: 1.661392 0.272679 -0.09788661 0.03207622 -0.02039233 0.01622142 -0.009727993 0.01763978 0.2071488 -0.03839267 -0.03994033 -0.1443278 -0.1957518 \n",
            "Function value: -3203.064 \n",
            "--------------------------------------------\n",
            "Maximum Likelihood estimation\n",
            "Newton-Raphson maximisation, 4 iterations\n",
            "Return code 8: successive function values within relative tolerance limit (reltol)\n",
            "Log-Likelihood: -3203.064 \n",
            "13  free parameters\n",
            "Estimates:\n",
            "                    Estimate Std. error t value  Pr(> t)    \n",
            "(Intercept)         1.661392   0.343552   4.836 1.33e-06 ***\n",
            "lag(log(rd), 0:5)0  0.272679   0.070784   3.852 0.000117 ***\n",
            "lag(log(rd), 0:5)1 -0.097887   0.076792  -1.275 0.202416    \n",
            "lag(log(rd), 0:5)2  0.032076   0.070864   0.453 0.650804    \n",
            "lag(log(rd), 0:5)3 -0.020392   0.065771  -0.310 0.756522    \n",
            "lag(log(rd), 0:5)4  0.016221   0.062885   0.258 0.796443    \n",
            "lag(log(rd), 0:5)5 -0.009728   0.053286  -0.183 0.855143    \n",
            "scisectyes          0.017640   0.198074   0.089 0.929037    \n",
            "log(capital72)      0.207149   0.077968   2.657 0.007888 ** \n",
            "factor(year)1976   -0.038393   0.024472  -1.569 0.116688    \n",
            "factor(year)1977   -0.039940   0.025227  -1.583 0.113374    \n",
            "factor(year)1978   -0.144328   0.026460  -5.455 4.91e-08 ***\n",
            "factor(year)1979   -0.195752   0.027164  -7.206 5.75e-13 ***\n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tobit Model\n",
        "\n",
        "The Tobit model, developed by James Tobin in 1958, is a type of regression model designed to estimate linear relationships between variables when there is either left- or right-censoring in the dependent variable. Censoring occurs when the value of the dependent variable is only observed within certain bounds. The Tobit model is particularly useful when the dependent variable has a significant number of observations at a limiting value (e.g., zero). The classic example is modeling household expenditure on durable goods where many households report zero expenditure.\n",
        "\n",
        "When applying the Tobit model to panel data, we need to account for the repeated observations over time for the same individuals or entities. This involves adding individual-specific effects (fixed or random) to the model.\n",
        "\n",
        "The Tobit model is used to predict censored outcomes, where the dependent variable is left-censored at 0. In this example, we will use the `HealthIns` dataset from the `pglm` package to predict health insurance spending (`health_exp`) using demographic variables."
      ],
      "metadata": {
        "id": "1ZxtDmJJcqx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "data(\"HealthIns\", package = \"pglm\")       # Tobit\n",
        "head(HealthIns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8GXimNJc2BW",
        "outputId": "5302d099-ce34-4394-a4b9-62b5d3023763"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id year       med mdu coins  disease  sex      age size child\n",
            "1 125024    1  8.451119   0     0 13.73189 male 42.87748    4    no\n",
            "2 125024    2 62.075470   2     0 13.73189 male 43.87748    4    no\n",
            "3 125024    3  0.000000   0     0 13.73189 male 44.87748    4    no\n",
            "4 125024    4  0.000000   0     0 13.73189 male 45.87748    4    no\n",
            "5 125024    5  0.000000   0     0 13.73189 male 46.87748    4    no\n",
            "6 125025    1  0.000000   0     0 13.73189 male 16.59138    4   yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will create new data frame `health_pdata` with the required variables for the Tobit model. Then  the 2209th row from the HealthIns dataset and assigns the result to HealthIns2."
      ],
      "metadata": {
        "id": "hPJjVMnuDpU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "HealthIns$med2 <- HealthIns$med / 1000\n",
        "HealthIns2 <- HealthIns[-2209, ]\n",
        "\n",
        "# Check for NA values in the predictors and response\n",
        "sum(is.na(HealthIns2))\n",
        "# Remove rows with NA values\n",
        "HealthIns2 <- na.omit(HealthIns2)"
      ],
      "metadata": {
        "id": "H-Vzd2LJe3IS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below fits a Tobit regression model with random effects for the HealthIns2 dataset. The model uses the `med` variable as the dependent variable and includes `mdu`, `disease`, and `age `as independent variables. The Tobit model is appropriate for censored dependent variables, and the estimation is performed using the `Newton-Raphson` method with 5 random draws. The dataset is first processed by creating a new variable, removing a specific row, and taking a random subsample of 200 rows for the analysis."
      ],
      "metadata": {
        "id": "k7pbONBmDy4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Fit the Tobit model with random effects\n",
        "tobit_model <- pglm(med ~ mdu + disease + age,\n",
        "           data = HealthIns2,\n",
        "           model = 'random',\n",
        "           family = 'tobit',\n",
        "           print.level = 0,\n",
        "           method = 'nr', R = 5)\n",
        "\n",
        "# Summary of the model\n",
        "summary(tobit_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-T7zYiSe7eM",
        "outputId": "29e1b983-729e-4332-f348-a7306367d897"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "Maximum Likelihood estimation\n",
            "Newton-Raphson maximisation, 5 iterations\n",
            "Return code 1: gradient close to zero (gradtol)\n",
            "Log-Likelihood: -127807.9 \n",
            "6  free parameters\n",
            "Estimates:\n",
            "             Estimate Std. error t value  Pr(> t)    \n",
            "(Intercept) -333.0697    12.6778  -26.27  < 2e-16 ***\n",
            "mdu           58.6491     1.1701   50.12  < 2e-16 ***\n",
            "disease        5.5655     0.8382    6.64 3.14e-11 ***\n",
            "age            5.2772     0.3317   15.91  < 2e-16 ***\n",
            "sd.idios     675.2935     4.0108  168.37  < 2e-16 ***\n",
            "sd.id       -161.9779     8.5769  -18.89  < 2e-16 ***\n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "--------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary and Conclusions\n",
        "\n",
        "This tutorial demonstrated how to fit Generalized Linear Models (GLMs) for Panel Data in R using the `{pglm}` package. GLMs extend traditional linear models to handle correlated observations in longitudinal datasets with non-Gaussian outcomes. We covered various distributions, including Gaussian, ordinal probit, binomial probit, Poisson, negative binomial, and Tobit models, with examples from different datasets. The results provided insights into the relationships between predictors and outcomes, accounting for panel data structures and individual-specific effects. By applying these models, researchers can analyze longitudinal data with diverse response types and address challenges such as within-subject correlation and unobserved heterogeneity. The flexibility of GLMs for panel data allows for robust statistical inference and model selection in longitudinal studies."
      ],
      "metadata": {
        "id": "WRcixyIzpt2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1. [Panel Regression](https://rpubs.com/lumumba99/1011604)\n",
        "\n",
        "2.  [Panel Data Regression in R: An Introduction to Longitudinal Data analysis](https://medium.com/@akif.iips/panel-data-regression-in-r-a38ac8559f7f)\n",
        "\n",
        "3.  [Panel data econometrics in R](https://cran.r-project.org/web/packages/plm/vignettes/A_plmPackage.html)\n",
        "\n",
        "4.  [R Tutorial: Panel Data Analysis 1](https://rpubs.com/phle/r_tutorial_panel_data_analysis)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bLeAMiRQG59v"
      }
    }
  ]
}