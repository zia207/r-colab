{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMtoNcEJp4M3lfpN6nd5TNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-04-03-02-multilevel-glm-multinomial-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ],
      "metadata": {
        "id": "4qrItz_mJNWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2. Multilevels or Mixed-Effects Multinomial Model\n",
        "\n",
        "Multilevels or Mixed-Effect miltinomial model is an extension of the multinomial regression model that accounts for random effects. It's particularly useful when data is structured hierarchically or has a multilevel nature, such as repeated measurements within individuals or groups. In this tutorial, we will demonstrate how to build and fit a multilevel multinomial model in R, focusing on the theoretical background, model implementation, and interpretation of results."
      ],
      "metadata": {
        "id": "Dzp9ZseROTcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Multilevel multinomial models, also known as mixed-effects multinomial models, are used to analyze categorical outcomes with more than two categories while accounting for hierarchical structures in the data. These models extend the concept of mixed-effects models to multinomial outcomes, allowing for the estimation of both fixed and random effects. By incorporating random effects, these models can capture the variability within groups or clusters, providing more accurate estimates and predictions. In this tutorial, we will demonstrate how to build and fit a multilevel multinomial model in R, focusing on the theoretical background, model implementation, and interpretation of results.\n",
        "\n",
        "A **Mixed-Effects Multinomial Regression Model** is an extension of the multinomial regression model that accounts for random effects. It's particularly useful when data is structured hierarchically or has a multilevel nature, such as repeated measurements within individuals or groups.\n",
        "\n",
        "Below, I explain the model, starting with multinomial regression, then incorporating mixed effects.\n",
        "\n",
        "**1. Multinomial Regression**\n",
        "\n",
        "Multinomial regression models the probabilities of $K$ categorical outcomes ($y$) for a dependent variable, given predictors $\\mathbf{X}$. For $K$-category outcomes ($y \\in \\{1, 2, \\dots, K\\}$):\n",
        "\n",
        "$$ P(y = k \\mid \\mathbf{X}) = \\frac{\\exp(\\boldsymbol{\\beta}_k^\\top \\mathbf{X})}{\\sum_{j=1}^K \\exp(\\boldsymbol{\\beta}_j^\\top \\mathbf{X})}, \\quad k = 1, 2, \\dots, K $$\n",
        "\n",
        "-   $\\boldsymbol{\\beta}_k$: Coefficients for the predictors for category $k$.\n",
        "-   One category (often the last one) is treated as the **reference category**, and its coefficients $\\boldsymbol{\\beta}_K$ are set to 0 to avoid overparameterization.\n",
        "\n",
        "The log-odds of being in category $k$ relative to the reference category $K$ is:\n",
        "\n",
        "$$ \\log \\left( \\frac{P(y = k \\mid \\mathbf{X})}{P(y = K \\mid \\mathbf{X})} \\right) = \\boldsymbol{\\beta}_k^\\top \\mathbf{X} $$\n",
        "\n",
        "**2. Mixed-Effects Multinomial Regression**\n",
        "\n",
        "To incorporate random effects, the model adds random components to account for variability across clusters or groups (e.g., individuals, locations). The random effects modify the linear predictor.\n",
        "\n",
        "For each cluster $i$, we assume:\n",
        "\n",
        "$$ P(y_i = k \\mid \\mathbf{X}_i, \\mathbf{b}_i) = \\frac{\\exp((\\boldsymbol{\\beta}_k + \\mathbf{b}_{i,k})^\\top \\mathbf{X}_i)}{\\sum_{j=1}^K \\exp((\\boldsymbol{\\beta}_j + \\mathbf{b}_{i,j})^\\top \\mathbf{X}_i)}, \\quad k = 1, 2, \\dots, K $$\n",
        "\n",
        "-   $\\mathbf{b}_{i,k}$: Random effects for group $i$ and category $k$.\n",
        "-   $\\mathbf{b}_i = (\\mathbf{b}_{i,1}, \\dots, \\mathbf{b}_{i,K})$ are typically assumed to follow a multivariate normal distribution:\n",
        "-   $\\mathbf{b}_i \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{\\Sigma})$, where $\\mathbf{\\Sigma}$ is the covariance matrix of random effects.\n",
        "\n",
        "The random effects allow the model to capture unobserved heterogeneity across groups.\n",
        "\n",
        "\n",
        "\n",
        "**Model Interpretation**\n",
        "\n",
        "-   **Fixed Effects**: Represent the population-level relationships between predictors and the outcome probabilities.\n",
        "-   **Random Effects**: Capture deviations specific to each cluster or group.\n",
        "-   The probabilities for each category are obtained by combining fixed and random effects in the linear predictor.\n",
        "\n",
        "**Log-Likelihood Function**\n",
        "\n",
        "The log-likelihood for the mixed-effects multinomial model, given data ($\\mathbf{y}, \\mathbf{X}$), is:\n",
        "\n",
        "$$ \\mathcal{L}(\\boldsymbol{\\beta}, \\mathbf{\\Sigma}) = \\sum_{i=1}^N \\log \\int \\prod_{j=1}^{n_i} P(y_{ij} \\mid \\mathbf{X}_{ij}, \\mathbf{b}_i) f(\\mathbf{b}_i \\mid \\mathbf{\\Sigma}) , d\\mathbf{b}_i, $$\n",
        "\n",
        "where:\n",
        "\n",
        "-   $n_i$: Number of observations in group $i$.\n",
        "-   $f(\\mathbf{b}\\_i \\mid \\mathbf{\\Sigma})$: Density of the random effects.\n",
        "\n",
        "This integral is generally intractable, so numerical methods such as **Gaussian quadrature** or **Monte Carlo integration** are used.\n",
        "\n",
        "Suppose we want to model a patient's choice among three treatments ($A, B, C$) repeatedly observed across multiple hospitals. Predictor variables include patient characteristics ($\\mathbf{X}_{ij}$), and random effects account for variability in hospital-level preferences.\n",
        "\n",
        "-   Fixed effects: ($\\boldsymbol{\\beta}$) capture how predictors like age or severity influence treatment choice.\n",
        "-   Random effects: ($\\mathbf{b}_i$) allow each hospital to have its own baseline tendencies for treatment preferences.\n",
        "\n",
        "The model estimates how patient characteristics and hospital preferences jointly influence treatment choices, providing insights into the factors driving patient decisions.\n"
      ],
      "metadata": {
        "id": "TpcIOkTs30qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install rpy2"
      ],
      "metadata": {
        "id": "SDp3ULld8Gb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall rpy2 -y\n",
        "!pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "CiM6y-Mw8AJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd210c5-4860-4cf5-cfd0-0b060c2f8a64"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rpy2 3.4.2\n",
            "Uninstalling rpy2-3.4.2:\n",
            "  Successfully uninstalled rpy2-3.4.2\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (3.1.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (2025.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (5.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2==3.5.1) (3.0.2)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp311-cp311-linux_x86_64.whl size=314975 sha256=4ebc26b9d9fb6342b85b656fa4059d46b71bdca850d9302d5eaf245e761c80cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/55/d1/47be85a5f3f1e1f4d1e91cb5e3a4dcb40dd72147f184c5a5ef\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "O1zeuaCowiBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J-4ie4bwiJ1",
        "outputId": "8c672d5f-1f75-4076-dc9d-ded17bb1693b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilevel Multinomial Model from Scratch\n",
        "\n",
        "Building a multilevel multinomial logistic regression model from scratch in R without using specialized packages is a complex task because it involves implementing maximum likelihood estimation, handling the integration over random effects, and ensuring numerical stability. Below is a step-by-step outline for such an implementation:"
      ],
      "metadata": {
        "id": "UdMcXPIF4Bly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Example Data\n",
        "\n",
        "We’ll create synthetic data with both fixed and random effects for a multinomial outcome. The data will include a single predictor variable and group identifiers for the random effects. The design matrix will include an intercept term."
      ],
      "metadata": {
        "id": "ztl1QBDb4MYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Set seed for reproducibility\n",
        "set.seed(123)\n",
        "\n",
        "# Simulate Example Data\n",
        "set.seed(42)\n",
        "n <- 100  # Number of observations\n",
        "n_groups <- 5  # Number of groups\n",
        "X <- data.frame(X1 = rnorm(n))  # Single predictor\n",
        "group <- sample(1:n_groups, n, replace = TRUE)  # Group identifiers\n",
        "y <- sample(1:3, n, replace = TRUE)  # Multinomial outcome (3 categories)\n",
        "data <- data.frame(group = group, X1 = X$X1, y = y)\n",
        "\n",
        "# Design matrix including intercept\n",
        "X <- cbind(1, as.matrix(data[, \"X1\", drop = FALSE]))  # Add intercept\n",
        "# Initial parameter vector (length should match model requirements)\n",
        "num_predictors <- ncol(X)  # Including intercept\n",
        "num_categories <- length(unique(data$y))\n",
        "init_params <- c(rep(0, num_predictors * (num_categories - 1)), log(1))\n",
        "\n",
        "head(data)"
      ],
      "metadata": {
        "id": "q82MNCn64Q0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c598757-ede7-48ba-d175-e393fa2b98e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  group         X1 y\n",
            "1     2  1.3709584 3\n",
            "2     1 -0.5646982 2\n",
            "3     4  0.3631284 2\n",
            "4     3  0.6328626 1\n",
            "5     5  0.4042683 3\n",
            "6     2 -0.1061245 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the multinomial log-likelihood with random effects\n",
        "\n",
        "The log-likelihood function calculates the negative log-likelihood of the model given the data, parameters, and random effects. It integrates over the random effects using Gaussian quadrature to estimate the log-likelihood for each group. The function also includes a regularization term to prevent large random effect variances.  "
      ],
      "metadata": {
        "id": "zDBKsDwn4LQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#  Define the multinomial log-likelihood with random effects\n",
        "log_likelihood <- function(params, data, groups, X, y) {\n",
        "  # Number of predictors (including intercept)\n",
        "  num_predictors <- ncol(X)\n",
        "  # Number of categories\n",
        "  num_categories <- length(unique(y))\n",
        "  # Reshape beta parameters\n",
        "  beta <- matrix(params[1:(num_predictors * (num_categories - 1))],\n",
        "                 nrow = num_predictors,\n",
        "                 ncol = (num_categories - 1))\n",
        "  # Random effect variance (with regularization to prevent divergence)\n",
        "  sigma <- exp(params[(num_predictors * (num_categories - 1)) + 1])\n",
        "\n",
        "  # Small value to avoid log(0) and division by zero\n",
        "  epsilon <- 1e-10\n",
        "  regularization_penalty <- 1e-4  # Regularization term for sigma to avoid large variances\n",
        "\n",
        "  logL <- 0  # Initialize log-likelihood\n",
        "\n",
        "  # Loop over groups\n",
        "  for (g in unique(groups)) {\n",
        "    group_data <- data[groups == g, ]\n",
        "    group_X <- X[groups == g, , drop = FALSE]  # Ensure group_X is a matrix\n",
        "    group_y <- y[groups == g]\n",
        "\n",
        "    # Ensure group_X has the same number of columns as beta rows\n",
        "    if (ncol(group_X) != nrow(beta)) {\n",
        "      stop(\"Dimension mismatch: group_X and beta are not conformable!\")\n",
        "    }\n",
        "\n",
        "    # Integrate over random effects (using Gaussian quadrature)\n",
        "    b_vals <- seq(-3 * sigma, 3 * sigma, length.out = 10)  # Integration grid\n",
        "    integrand <- sapply(b_vals, function(b) {\n",
        "      lin_pred <- group_X %*% beta + b\n",
        "      exp_lin_pred <- exp(lin_pred)\n",
        "      pred_probs <- exp_lin_pred / rowSums(exp_lin_pred)  # Normalize to get probabilities\n",
        "\n",
        "      # Clip probabilities to avoid issues with log(0) or log(1)\n",
        "      pred_probs <- pmax(pmin(pred_probs, 1 - epsilon), epsilon)\n",
        "\n",
        "      # Map group_y values (1, 2, 3) to 1, 2 for indexing pred_probs\n",
        "      valid_group_y <- pmin(group_y, num_categories - 1)  # Map 3 to 2\n",
        "\n",
        "      # Log-probability for observations\n",
        "      log_prob <- sum(log(pred_probs[cbind(1:nrow(group_data), valid_group_y)]))\n",
        "      dnorm(b, mean = 0, sd = sigma, log = TRUE) + log_prob\n",
        "    })\n",
        "\n",
        "    # Aggregate log-likelihood\n",
        "    logL <- logL + log(sum(exp(integrand)))\n",
        "  }\n",
        "\n",
        "  # Add regularization term to prevent large sigma\n",
        "  logL <- logL - regularization_penalty * sigma^2\n",
        "\n",
        "  return(-logL)  # Return negative log-likelihood for optimization\n",
        "}\n"
      ],
      "metadata": {
        "id": "dhRM1tBj4MCd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization and  Fit the Model\n",
        "\n",
        "Optimize the log-likelihood function to estimate the model parameters. We used `Nelder-Mead` optimization method was used. This methods is often more stable when dealing with noisy or numerically unstable functions. The optimization process is controlled by the maximum number of iterations and the level of output tracing.\n"
      ],
      "metadata": {
        "id": "4BpOoaj34eBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "fit <- optim(\n",
        "  par = init_params,\n",
        "  fn = log_likelihood,\n",
        "  data = data,\n",
        "  groups = data$group,\n",
        "  X = X,  # Pass design matrix with intercept\n",
        "  y = data$y,\n",
        "  method = \"Nelder-Mead\",  # Using a more stable optimization method\n",
        "  control = list(trace = 1, maxit = 100)\n",
        ")\n"
      ],
      "metadata": {
        "id": "soSBO_2B4qVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db9564f-8025-40b1-9717-5fba630192f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Nelder-Mead direct search function minimizer\n",
            "function value for initial parameters = 67.290928\n",
            "  Scaled convergence tolerance is 1.00271e-06\n",
            "Stepsize computed as 0.100000\n",
            "BUILD              6 69.315876 65.515876\n",
            "EXTENSION          8 67.790950 63.493572\n",
            "LO-REDUCTION      10 67.596756 63.493572\n",
            "LO-REDUCTION      12 67.290928 63.493572\n",
            "EXTENSION         14 67.253382 61.472161\n",
            "EXTENSION         16 65.515876 59.987946\n",
            "LO-REDUCTION      18 64.433890 59.987946\n",
            "LO-REDUCTION      20 63.978613 59.987946\n",
            "LO-REDUCTION      22 63.493572 59.987946\n",
            "LO-REDUCTION      24 61.472161 59.832577\n",
            "LO-REDUCTION      26 60.414464 59.832577\n",
            "EXTENSION         28 60.291692 59.481949\n",
            "LO-REDUCTION      30 60.106304 59.481949\n",
            "EXTENSION         32 59.987946 59.327386\n",
            "LO-REDUCTION      34 59.961911 59.327386\n",
            "EXTENSION         36 59.832577 58.751213\n",
            "LO-REDUCTION      38 59.778740 58.751213\n",
            "EXTENSION         40 59.482787 58.449349\n",
            "LO-REDUCTION      42 59.481949 58.449349\n",
            "LO-REDUCTION      44 59.370115 58.449349\n",
            "EXTENSION         46 59.327386 57.669734\n",
            "LO-REDUCTION      48 58.971023 57.669734\n",
            "LO-REDUCTION      50 58.810619 57.669734\n",
            "EXTENSION         52 58.751213 56.861864\n",
            "LO-REDUCTION      54 58.449349 56.861864\n",
            "EXTENSION         56 58.149149 55.385219\n",
            "LO-REDUCTION      58 57.700287 55.385219\n",
            "EXTENSION         60 57.669734 54.486675\n",
            "LO-REDUCTION      62 56.983439 54.486675\n",
            "EXTENSION         64 56.861864 52.140200\n",
            "EXTENSION         66 55.589310 49.543349\n",
            "LO-REDUCTION      68 55.385219 49.543349\n",
            "LO-REDUCTION      70 54.504777 49.543349\n",
            "EXTENSION         72 54.486675 46.087789\n",
            "EXTENSION         74 52.140200 42.425183\n",
            "LO-REDUCTION      76 52.119265 42.425183\n",
            "EXTENSION         78 50.282328 35.113551\n",
            "LO-REDUCTION      80 49.543349 35.113551\n",
            "LO-REDUCTION      82 46.087789 35.113551\n",
            "EXTENSION         84 45.328019 29.605446\n",
            "EXTENSION         86 42.425183 17.363059\n",
            "LO-REDUCTION      88 36.513260 17.363059\n",
            "LO-REDUCTION      90 36.255227 17.363059\n",
            "EXTENSION         92 35.113551 -0.033669\n",
            "LO-REDUCTION      94 29.605446 -0.033669\n",
            "EXTENSION         96 20.889909 -19.118933\n",
            "LO-REDUCTION      98 19.448919 -19.118933\n",
            "EXTENSION        100 17.363059 -40.251794\n",
            "Exiting from Nelder Mead minimizer\n",
            "    102 function evaluations used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output Results\n",
        "\n",
        "Other results such as the optimized parameters, final log-likelihood, and convergence status are extracted from the optimization output."
      ],
      "metadata": {
        "id": "-JuTDU0fBTIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Output Results\n",
        "print(fit$par)      # Optimized parameters\n",
        "print(-fit$value)   # Final log-likelihood\n",
        "print(fit$convergence)  # Convergence status (0 = success)"
      ],
      "metadata": {
        "id": "8mioZdwbBT_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa35740-8845-4b77-fe34-22a9fe74b5ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]  13.842317   6.149148  13.000008   3.977466 -35.862473\n",
            "[1] 40.25179\n",
            "[1] 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation\n",
        "\n",
        "The estimated beta coefficients and random effect variance are extracted from the optimized parameters for model evaluation.  "
      ],
      "metadata": {
        "id": "9qwshPhD4f0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Evaluate Model\n",
        "beta_hat <- matrix(fit$par[1:(num_predictors * (num_categories - 1))],\n",
        "                   nrow = num_predictors,\n",
        "                   ncol = (num_categories - 1))\n",
        "sigma_hat <- exp(fit$par[(num_predictors * (num_categories - 1)) + 1])\n",
        "\n",
        "cat(\"\\nEstimated Beta Coefficients:\\n\")\n",
        "print(beta_hat)\n",
        "\n",
        "cat(\"\\nEstimated Random Effect Variance (Sigma):\\n\")\n",
        "print(sigma_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kexiyCEd4irJ",
        "outputId": "beb60b42-edd2-468e-f470-1d99e7189a3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estimated Beta Coefficients:\n",
            "          [,1]      [,2]\n",
            "[1,] 13.842317 13.000008\n",
            "[2,]  6.149148  3.977466\n",
            "\n",
            "Estimated Random Effect Variance (Sigma):\n",
            "[1] 2.661495e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Predictions Using the Fitted Model\n",
        "\n",
        "Predict the class labels for each observation based on the estimated parameters. The predicted probabilities are calculated using the linear predictor and normalized to obtain class probabilities. The class with the highest probability is assigned as the predicted class label.  "
      ],
      "metadata": {
        "id": "wo80C9kz4nMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "predict_multilevel <- function(fit, data, X, num_categories) {\n",
        "  # Extract the parameters from the fit object\n",
        "  beta <- matrix(fit$par[1:(ncol(X) * (num_categories - 1))], ncol = (num_categories - 1))\n",
        "  sigma <- exp(fit$par[(ncol(X) * (num_categories - 1)) + 1])  # Random effect variance\n",
        "\n",
        "  # Predicted probabilities for each class\n",
        "  pred_probs <- matrix(0, nrow = nrow(X), ncol = num_categories)\n",
        "\n",
        "  # Loop through the rows of the data to calculate probabilities\n",
        "  for (i in 1:nrow(X)) {\n",
        "    # Compute linear predictor (with random effect b = 0 for simplicity)\n",
        "    lin_pred <- X[i, , drop = FALSE] %*% beta\n",
        "    exp_lin_pred <- exp(lin_pred)\n",
        "    pred_probs[i, 1:(num_categories - 1)] <- exp_lin_pred / rowSums(exp_lin_pred)  # Normalize to get probabilities\n",
        "\n",
        "    # The probability for the reference category (num_categories)\n",
        "    pred_probs[i, num_categories] <- 1 - sum(pred_probs[i, 1:(num_categories - 1)])\n",
        "  }\n",
        "\n",
        "  # Convert probabilities to predicted class labels (the class with the highest probability)\n",
        "  predicted_classes <- apply(pred_probs, 1, which.max)\n",
        "\n",
        "  return(predicted_classes)\n",
        "}\n",
        "\n",
        "# Make predictions on the training data\n",
        "predicted_classes <- predict_multilevel(fit, data, X, num_categories = 3)\n",
        "\n",
        "# Evaluate the model performance\n",
        "conf_matrix <- table(Predicted = predicted_classes, Actual = data$y)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
        "print(paste(\"Accuracy:\", round(accuracy, 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNN5MZEu4n64",
        "outputId": "d5acd9ff-84a0-452f-ae39-81da44fd6d88"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Actual\n",
            "Predicted  1  2  3\n",
            "        1 19 22 28\n",
            "        2 12 15  4\n",
            "[1] \"Accuracy: 0.34\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilevel Multinomial Model in R\n",
        "\n",
        "In this section, we will focus on how to implement a mixed-effects multinomial regression model using the `mblogit()` function from the {mclogit} package in R. The `mblogit()` function allows you to fit multinomial models with random effects, making it suitable for analyzing categorical outcomes with hierarchical structures. We will demonstrate the step-by-step process of building and interpreting a mixed-effects multinomial model using the `mblogit()` function."
      ],
      "metadata": {
        "id": "90C3xCiGBa3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Required R Packages\n",
        "\n",
        "Following R packages are required to run this notebook. If any of these packages are not installed, you can install them using the code below:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9T5ojBgKBv5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "packages <- c('tidyverse',\n",
        "              'DataExplorer',\n",
        "              'sjPlot',\n",
        "              'margins',\n",
        "              'performance',\n",
        "              'mclogit'\n",
        "\t\t )"
      ],
      "metadata": {
        "id": "4ERkgB8gByVX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Install missing packages\n",
        "new.packages <- packages[!(packages %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')"
      ],
      "metadata": {
        "id": "J3nWFZpl-sr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "install.packages('mclogit', lib='drive/My Drive/R/')"
      ],
      "metadata": {
        "id": "Am6IqiUEAaEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jv6EE7Z-sx-",
        "outputId": "50f9d14e-910b-4abf-f92e-f153f0037b58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages:\n",
            "   tidyverse DataExplorer       sjPlot      margins  performance      mclogit \n",
            "        TRUE         TRUE         TRUE         TRUE         TRUE         TRUE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load R Packages"
      ],
      "metadata": {
        "id": "MV7R29xfyWQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Load packages with suppressed messages\n",
        "invisible(lapply(packages, function(pkg) {\n",
        "  suppressPackageStartupMessages(library(pkg, character.only = TRUE))\n",
        "}))\n",
        "# Check loaded packages\n",
        "cat(\"Successfully loaded packages:\\n\")\n",
        "print(search()[grepl(\"package:\", search())])# Check loaded packages\n"
      ],
      "metadata": {
        "id": "232jNAHBykUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9e1d0f-dbf0-4b3e-f38d-4067a35a88c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded packages:\n",
            " [1] \"package:mclogit\"      \"package:Matrix\"       \"package:performance\" \n",
            " [4] \"package:margins\"      \"package:sjPlot\"       \"package:DataExplorer\"\n",
            " [7] \"package:lubridate\"    \"package:forcats\"      \"package:stringr\"     \n",
            "[10] \"package:dplyr\"        \"package:purrr\"        \"package:readr\"       \n",
            "[13] \"package:tidyr\"        \"package:tibble\"       \"package:ggplot2\"     \n",
            "[16] \"package:tidyverse\"    \"package:tools\"        \"package:stats\"       \n",
            "[19] \"package:graphics\"     \"package:grDevices\"    \"package:utils\"       \n",
            "[22] \"package:datasets\"     \"package:methods\"      \"package:base\"        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "In this exercise we will use  use a synthatic data similar to `Transport` data set of {mclogit} package. The dataset contains information about the mode of transportation chosen by individuals based on the cost, working population, and distance traveled. The goal is to predict the mode of transportation based on these predictors using a mixed-effects multinomial model.\n",
        "\n",
        "`transport`: The chosen mode of transportation (Car, Bus, Train).\n",
        "`cost`: Cost of the transportation, influenced by distance and suburb class.\n",
        "`working`: Size of the working population in the suburb.\n",
        "`distance`: Distance traveled, uniformly distributed between 1 km and 50 km.\n",
        "`suburb`: Categorical variable indicating the suburb class (A, B, C, D).\n",
        "\n"
      ],
      "metadata": {
        "id": "rSJqB05rO5ES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFpt_H01OPsa",
        "outputId": "247bd95a-51ff-4f41-e559-7dec2436de4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 1,000\n",
            "Columns: 5\n",
            "$ transport <fct> Bus, Bus, Bus, Train, Car, Bus, Bus, Bus, Train, Bus, Car, C…\n",
            "$ cost      <dbl> 18.819656, 58.857251, 27.258692, 71.097966, 20.331215, 55.84…\n",
            "$ working   <dbl> 131.94321, 35.09452, 120.53570, 237.55307, 124.54167, 147.14…\n",
            "$ distance  <dbl> 11.085519, 47.184413, 19.586866, 31.685767, 9.991618, 33.301…\n",
            "$ suburb    <fct> B, D, C, A, A, B, C, A, C, C, A, C, D, C, B, A, B, B, C, A, …\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Load required package\n",
        "set.seed(123)  # For reproducibility\n",
        "\n",
        "# Define constants\n",
        "n_samples <- 1000\n",
        "suburb_classes <- c(\"A\", \"B\", \"C\", \"D\")\n",
        "transport_modes <- c(\"Car\", \"Bus\", \"Train\")\n",
        "n_suburbs <- length(suburb_classes)\n",
        "\n",
        "# Generate suburb data\n",
        "suburbs <- sample(suburb_classes, size = n_samples, replace = TRUE, prob = c(0.2, 0.3, 0.3, 0.2))\n",
        "\n",
        "# Generate working population size by suburb class\n",
        "working_population_by_class <- list(\n",
        "  A = c(mean = 200, sd = 50),\n",
        "  B = c(mean = 150, sd = 30),\n",
        "  C = c(mean = 100, sd = 20),\n",
        "  D = c(mean = 50, sd = 15)\n",
        ")\n",
        "working_population <- sapply(suburbs, function(suburb) {\n",
        "  rnorm(1, mean = working_population_by_class[[suburb]][\"mean\"],\n",
        "        sd = working_population_by_class[[suburb]][\"sd\"])\n",
        "})\n",
        "\n",
        "# Generate distance traveled (longer distances in suburban/rural areas)\n",
        "distance <- runif(n_samples, min = 1, max = 50)  # Between 1 km and 50 km\n",
        "\n",
        "# Generate cost (correlated with distance and suburb class)\n",
        "cost_base_by_class <- c(A = 2.0, B = 1.8, C = 1.5, D = 1.2)\n",
        "cost <- mapply(function(suburb, dist) {\n",
        "  dist * rnorm(1, mean = cost_base_by_class[suburb], sd = 0.2)\n",
        "}, suburb = suburbs, dist = distance)\n",
        "\n",
        "# Simulate multinomial choice for transport modes\n",
        "# Use a softmax-like function for transport probabilities\n",
        "softmax <- function(x) {\n",
        "  exp_x <- exp(x - max(x))\n",
        "  exp_x / sum(exp_x)\n",
        "}\n",
        "\n",
        "# Assign base utilities for transport modes by suburb\n",
        "base_utilities <- list(\n",
        "  Car = c(A = 2.5, B = 2.0, C = 1.5, D = 1.0),\n",
        "  Bus = c(A = 1.5, B = 1.8, C = 2.0, D = 2.5),\n",
        "  Train = c(A = 2.0, B = 1.5, C = 1.2, D = 1.0)\n",
        ")\n",
        "\n",
        "# Calculate probabilities and assign transport\n",
        "transport_choices <- sapply(1:n_samples, function(i) {\n",
        "  utilities <- sapply(transport_modes, function(mode) {\n",
        "    base_utilities[[mode]][suburbs[i]] - 0.05 * cost[i] + 0.02 * distance[i]\n",
        "  })\n",
        "  probabilities <- softmax(utilities)\n",
        "  sample(transport_modes, size = 1, prob = probabilities)\n",
        "})\n",
        "\n",
        "# Create the final dataset\n",
        "mf <- data.frame(\n",
        "  transport = transport_choices,\n",
        "  cost = cost,\n",
        "  working = working_population,\n",
        "  distance = distance,\n",
        "  suburb = suburbs\n",
        ")\n",
        "# convert to factor\n",
        "mf$transport <- as.factor(mf$transport)\n",
        "mf$suburb <- as.factor(mf$suburb)\n",
        "# Preview the dataset\n",
        "glimpse(mf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R -w 600 -h 500 -u px\n",
        "mf  |>\n",
        "  dplyr::select(cost, working, distance, suburb)  |>\n",
        "  DataExplorer::plot_boxplot(by = 'suburb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "MmtJFmCMCpig",
        "outputId": "df62bbca-9815-49b5-ac1c-be696ab67640"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit a Multilevel Multinomial Model\n",
        "\n",
        "We will fit a mixed-effects multinomial model to the `Transport` dataset using the `mblogit()` function from the {mclogit} package. The model will predict the choice of transportation based on the cost, walking distance, and working population of each suburb. We will include random effects for the `suburb` variable to account for the hierarchical structure of the data.\n"
      ],
      "metadata": {
        "id": "EcqUZt4cC5LI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Intercept Model\n",
        "\n",
        "In a first step, we generate a baseline model with random intercept only. This model assumes that the effect of the predictors is the same across all levels of the random effect.  \n",
        "\n"
      ],
      "metadata": {
        "id": "4Z_PXyWFDJ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Fit random intercept multinomial model\n",
        "model_inter <- mblogit(formula = transport ~ 1,\n",
        "              random = ~ 1 | suburb,\n",
        "              data = mf)"
      ],
      "metadata": {
        "id": "p_eUNGuwDNka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea6f93b-e94f-43d1-cfbc-a89214576d48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning:\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  Inner iterations did not coverge - nlminb message: false convergence (8)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1 - deviance = 2018.42 - criterion = 1.18739"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning:\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  Inner iterations did not coverge - nlminb message: false convergence (8)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 2 - deviance = 2019.28 - criterion = 0.01534171"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning:\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  Inner iterations did not coverge - nlminb message: false convergence (8)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 3 - deviance = 2019.471 - criterion = 1.05413e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning:\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  Inner iterations did not coverge - nlminb message: false convergence (8)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 4 - deviance = 2019.468 - criterion = 2.19327e-11\n",
            "converged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "summary(model_inter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufm4apQJIHs5",
        "outputId": "f70acde0-a934-4cd3-b555-4ed02a489a23"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Call:\n",
            "mblogit(formula = transport ~ 1, data = mf, random = ~1 | suburb)\n",
            "\n",
            "Equation for Car vs Bus:\n",
            "            Estimate Std. Error z value Pr(>|z|)\n",
            "(Intercept)  -0.1552     0.3993  -0.389    0.697\n",
            "\n",
            "Equation for Train vs Bus:\n",
            "            Estimate Std. Error z value Pr(>|z|)  \n",
            "(Intercept)  -0.7218     0.3415  -2.114   0.0345 *\n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "\n",
            "(Co-)Variances:\n",
            "Grouping level: suburb \n",
            "        Estimate        Std.Err.     \n",
            "Car~1   0.6133          0.3349       \n",
            "Train~1 0.4989 0.4334   0.2799 0.2339\n",
            "\n",
            "Approximate residual deviance: 2019 \n",
            "Number of Fisher scoring iterations:  4\n",
            "Number of observations\n",
            "  Groups by suburb: 4\n",
            "  Individual observations:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mixed-Effects Multinomial Model\n",
        "\n",
        "We will fit a mixed-effects multinomial model with random intercept allowing the effect of the predictors to vary across levels of the random effect.    \n"
      ],
      "metadata": {
        "id": "ScXpBMBikzr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Fit random intercept and slope multinomial model\n",
        "model_mixed <- mblogit(formula = transport ~ cost + working + distance,\n",
        "              random = ~ 1 | suburb,\n",
        "              data = mf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh1DEtUxDSIl",
        "outputId": "715cf2b0-fe24-47de-9dc1-558cff081783"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1 - deviance = 2020.804 - criterion = 1.179956"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning:\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  Inner iterations did not coverge - nlminb message: false convergence (8)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 2 - deviance = 2017.311 - criterion = 0.01854146"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning:\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  Inner iterations did not coverge - nlminb message: false convergence (8)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 3 - deviance = 2017.514 - criterion = 1.66178e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Warning:\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]:  Inner iterations did not coverge - nlminb message: false convergence (8)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 4 - deviance = 2017.509 - criterion = 9.349468e-11\n",
            "converged\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "summary(model_mixed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jRoWqmnIYfx",
        "outputId": "2a8c39f8-d4b5-4e0f-fae2-eecc715d49d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Call:\n",
            "mblogit(formula = transport ~ cost + working + distance, data = mf, \n",
            "    random = ~1 | suburb)\n",
            "\n",
            "Equation for Car vs Bus:\n",
            "             Estimate Std. Error z value Pr(>|z|)\n",
            "(Intercept) -0.314057   0.487163  -0.645    0.519\n",
            "cost        -0.002346   0.010427  -0.225    0.822\n",
            "working      0.001417   0.002365   0.599    0.549\n",
            "distance     0.003019   0.017704   0.171    0.865\n",
            "\n",
            "Equation for Train vs Bus:\n",
            "             Estimate Std. Error z value Pr(>|z|)   \n",
            "(Intercept) -1.152709   0.421166  -2.737   0.0062 **\n",
            "cost         0.005934   0.011392   0.521   0.6024   \n",
            "working      0.002561   0.002344   1.092   0.2747   \n",
            "distance    -0.005541   0.019596  -0.283   0.7774   \n",
            "---\n",
            "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
            "\n",
            "(Co-)Variances:\n",
            "Grouping level: suburb \n",
            "        Estimate        Std.Err.       \n",
            "Car~1   0.5117          0.13468        \n",
            "Train~1 0.3213 0.2239   0.08724 0.05652\n",
            "\n",
            "Approximate residual deviance: 2018 \n",
            "Number of Fisher scoring iterations:  4\n",
            "Number of observations\n",
            "  Groups by suburb: 4\n",
            "  Individual observations:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Comparison\n",
        "\n",
        "We can compare the two models using the `anova()` function to see if the mixed-effects model provides a better fit to the data than the random intercept model.  \n"
      ],
      "metadata": {
        "id": "kVpip4LblDjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "anova(model_inter, model_mixed)"
      ],
      "metadata": {
        "id": "TQK3Q-3PDjWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908edd74-7136-480d-8710-774570e5385a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis of Deviance Table\n",
            "\n",
            "Model 1: transport ~ 1\n",
            "Model 2: transport ~ cost + working + distance\n",
            "  Resid. Df Resid. Dev Df Deviance\n",
            "1      1995     2019.5            \n",
            "2      1989     2017.5  6   1.9592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the second model is significantly better, we are justified to believe that our fixed effects have explanatory power. We can now use the `getSummary.mmblogit()` function to get a summary of the model with the fixed effects."
      ],
      "metadata": {
        "id": "aP-ASSfDDzqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "getSummary.mmblogit(model_mixed)"
      ],
      "metadata": {
        "id": "8nCTpa_mD3Tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cec888-f875-4f53-83ad-e1627fe5c916"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$coef\n",
            ", , Car/Bus\n",
            "\n",
            "                     est          se       stat         p          lwr\n",
            "(Intercept) -0.314056911 0.487163046 -0.6446649 0.5191444 -1.268878937\n",
            "cost        -0.002345802 0.010426949 -0.2249749 0.8219988 -0.022782247\n",
            "working      0.001416738 0.002365095  0.5990195 0.5491599 -0.003218763\n",
            "distance     0.003018856 0.017703536  0.1705228 0.8645990 -0.031679437\n",
            "                    upr\n",
            "(Intercept) 0.640765114\n",
            "cost        0.018090643\n",
            "working     0.006052239\n",
            "distance    0.037717149\n",
            "\n",
            ", , Train/Bus\n",
            "\n",
            "                     est          se       stat          p          lwr\n",
            "(Intercept) -1.152708724 0.421165825 -2.7369474 0.00620122 -1.978178572\n",
            "cost         0.005933943 0.011391700  0.5209006 0.60243601 -0.016393379\n",
            "working      0.002560673 0.002344172  1.0923572 0.27467615 -0.002033819\n",
            "distance    -0.005541115 0.019596485 -0.2827607 0.77736030 -0.043949521\n",
            "                     upr\n",
            "(Intercept) -0.327238876\n",
            "cost         0.028261266\n",
            "working      0.007155164\n",
            "distance     0.032867290\n",
            "\n",
            "\n",
            "$suburb\n",
            ", , 1\n",
            "\n",
            "                             est         se stat  p lwr upr\n",
            "Car/Bus: VCov(~1,~1)   0.5117241 0.13467786   NA NA  NA  NA\n",
            "Train/Bus: VCov(~1,~1) 0.3212967 0.08724274   NA NA  NA  NA\n",
            "\n",
            ", , 2\n",
            "\n",
            "                             est         se stat  p lwr upr\n",
            "Car/Bus: VCov(~1,~1)   0.3212967 0.08724274   NA NA  NA  NA\n",
            "Train/Bus: VCov(~1,~1) 0.2238657 0.05651621   NA NA  NA  NA\n",
            "\n",
            "\n",
            "$Groups\n",
            "Groups by suburb \n",
            "               4 \n",
            "\n",
            "$sumstat\n",
            "          LR           df     deviance     McFadden    Cox.Snell   Nagelkerke \n",
            "1.797156e+02 1.100000e+01 2.017509e+03 8.179211e-02 1.644922e-01 1.850538e-01 \n",
            "         AIC          BIC            N \n",
            "2.039509e+03 2.093494e+03 1.000000e+03 \n",
            "\n",
            "$call\n",
            "mblogit(formula = transport ~ cost + working + distance, data = mf, \n",
            "    random = ~1 | suburb)\n",
            "\n",
            "$contrasts\n",
            "NULL\n",
            "\n",
            "$xlevels\n",
            "named list()\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the `tab_model()` function from the {sjPlot} package to generate a table of the model coefficients and their significance levels. Each row in the table represents a predictor variable, and the columns display `Odds Ratios`, `CI`, and `p-values`.  \n"
      ],
      "metadata": {
        "id": "BHE412vmlYZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "sjPlot::tab_model(model_mixed)\n"
      ],
      "metadata": {
        "id": "l1fTfuZqIsRS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the marginal effects of the predictors on the outcome variable using the `plot_model()` function from the {sjPlot} package. This function generates a plot showing the marginal effects of each predictor variable on the outcome variable, along with confidence intervals.  "
      ],
      "metadata": {
        "id": "1V01OGbhJ_W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R -w 600 -h 450 -u px\n",
        "# Plot marginal effects\n",
        "sjPlot::plot_model(model_mixed)"
      ],
      "metadata": {
        "id": "YzedGbrtW3Ya",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "33956f9b-870f-4c7c-aae1-5b6b0680509e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Performance\n",
        "\n",
        "We can evaluate the performance of the mixed-effects multinomial model using the `performance()` function from the {performance} package. This function provides various performance metrics such as the AIC, BIC, and log-likelihood of the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "O2lCgHEnleKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "performance::performance(model_mixed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWauvTPJW9i7",
        "outputId": "c554f694-0a2e-4ca8-d76e-4b79681e62ab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Indices of model performance\n",
            "\n",
            "AIC      |      BIC | Nagelkerke's R2 |  RMSE | Sigma\n",
            "-----------------------------------------------------\n",
            "2039.509 | 2093.494 |           0.185 | 0.447 | 1.426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Prediction Performance\n",
        "\n",
        "We can also evaluate the prediction performance of the model using the `predict()` function. This function generates predicted probabilities for each category of the outcome variable based on the model's fixed and random effects.  "
      ],
      "metadata": {
        "id": "SwwgRXjnEcja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Predict probabilities for each category\n",
        "pred_probs <- predict(model_mixed, type = \"response\")\n",
        "# # Convert probabilities to class\n",
        "pred_classes <- apply(pred_probs, 1, which.max)\n",
        "head(pred_classes)"
      ],
      "metadata": {
        "id": "3RJQuC2IEdQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f39d82-f92e-4741-cbd5-bd719f9d490b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 2 1 1 2 2 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Training set evaluation\n",
        "actual_classes <- as.numeric(mf$transport)\n",
        "# Convert to numeric if needed\n",
        "conf_matrix <- table(Predicted = pred_classes, Actual = actual_classes)\n",
        "conf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEaV0qDxEwWq",
        "outputId": "8558513e-b1a6-4e4b-e084-610f15b83dde"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Actual\n",
            "Predicted   1   2   3\n",
            "        1 287 143  81\n",
            "        2 148 223 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# accuracy\n",
        "accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "Iig_BCZEKnTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6ab163-f61e-4914-8bd4-c715f6d5cb8b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In-class Accuracy or Per-class Accuracy:"
      ],
      "metadata": {
        "id": "_lq9TnINl99n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Calculate in-class accuracy\n",
        "in_class_accuracy <- diag(conf_matrix) / colSums(conf_matrix)\n",
        "\n",
        "# Display in-class accuracy for each class\n",
        "cat(\"In-Class Accuracy for each class:\\n\")\n",
        "print(round(in_class_accuracy* 100, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkeAyXOFmCoE",
        "outputId": "0f564d8d-6ee3-4411-e051-f81c1f1635bf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-Class Accuracy for each class:\n",
            "     1      2      3 \n",
            " 65.98  60.93 144.22 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary and Concusion\n",
        "\n",
        "This tutorial demonstrated how to build and fit a multilevel multinomial model in R using the `mblogit()` function from the {mclogit} package. We started by generating synthetic data with hierarchical structures and categorical outcomes. We then fitted a mixed-effects multinomial model to predict the mode of transportation based on the cost, working population, and distance traveled. The model included random effects for the `suburb` variable to account for the hierarchical structure of the data. We compared the model with random intercept and slope to a model with random intercept only and found that the mixed-effects model provided a better fit to the data. We evaluated the model's performance using various metrics and generated predictions for the outcome variable. Overall, the tutorial provided a comprehensive overview of building and interpreting multilevel multinomial models in R, highlighting the importance of accounting for hierarchical structures in categorical data analysis."
      ],
      "metadata": {
        "id": "WRcixyIzpt2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        "1.  [Mixed-Effects Multinomial Regression](https://ladal.edu.au/regression.html#Mixed-Effects_Multinomial_Regression)\n",
        "\n",
        "2.  [The ultimate practical guide to multilevel multinomial conjoint analysis with R](https://www.andrewheiss.com/blog/2023/08/12/conjoint-multilevel-multinomial-guide/)\n",
        "\n",
        "3.  [Package ‘mclogit’](https://cran.r-project.org/web/packages/mclogit/mclogit.pdf)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bLeAMiRQG59v"
      }
    }
  ]
}