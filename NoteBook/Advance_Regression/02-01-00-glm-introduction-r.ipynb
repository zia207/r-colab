{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-00-glm-introduction-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsBkpmP_qjLM"
      },
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generalized Linear Models\n",
        "\n",
        "Generalized Linear Models (GLMs) are a versatile class of models that extend linear regression to handle a variety of response variable distributions and relationships. In R, GLMs are implemented through the glm() function and related packages, providing a powerful framework for analyzing both continuous and categorical data across a wide range of contexts. This tutorial introduces several types of GLMs, as well as related models, and demonstrates how to implement each in R."
      ],
      "metadata": {
        "id": "nQlXYe8YuRDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. [Generalized Linear Regression (Gaussian)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-01-glm-regression-r.ipynb)\n",
        "\n",
        "2. [Logistic Regression (Binary)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-02-glm-logistic-r.ipynb)\n",
        "\n",
        "3. [Probit Regression Model](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-03-glm-probit-r.ipynb)\n",
        "\n",
        "4. [Ordinal Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-04-glm-ordinal-r.ipynb)\n",
        "\n",
        "5. [Multinomial Logistic Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-05-glm-multinomial-logistic-r.ipynb)\n",
        "\n",
        "6. [Poisson Regression ](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-00-poisson-regression-introduction-r.ipynb)\n",
        "\n",
        "  6.1. [Standard Poisson Regression (count data)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-01-poisson-regression-standard-r.ipynb)\n",
        "\n",
        "  6.2.[Poisson Regression Model with Offset (rate data)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-02-poisson-regression-offset-r.ipynb)\n",
        "\n",
        "  6.3. [Poisson Regression Models for Overdispersed Data](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-03-poisson-regression-overdispersion-r.ipynb)\n",
        "\n",
        "  6.4. [Zero-Inflated Models](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-04-poisson-regression-zeroinflated-r.ipynb)\n",
        "\n",
        " 6.5. [Hurdle Model](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-05-poisson-regression-hurdle-r.ipynb)\n",
        "\n",
        "\n",
        "7. [Gamma Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-07-glm-gamma-regression-r.ipynb)\n",
        "\n",
        "8. [Beta Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-08-glm-gamma-regression-r.ipynb)\n",
        "\n",
        "9. [Generalized Additive Model (GAM) ](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-02-09-glm-gam-regression.ipynb)\n",
        "\n"
      ],
      "metadata": {
        "id": "8GZU1GlM23ig"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzp9ZseROTcY"
      },
      "source": [
        "##  Introduction to Generalized Linear Model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0FPXx8mGylY"
      },
      "source": [
        "\n",
        "The Generalized Linear Model (GLM) is a sophisticated extension of linear regression designed to model relationships between a dependent variable and independent variables when the underlying assumptions of linear regression are unmet. The GLM was first introduced by Sir John Nelder and Robert Wedderburn, both acclaimed statisticians, in 1972.\n",
        "\n",
        "The GLM is an essential tool in modern data analysis, as it can be used to model a wide range of data types that may not conform to the assumptions of traditional linear regression. It allows for modeling non-normal distributions, non-linear relationships, and correlations between observations. By utilizing **maximum likelihood estimation (MLE)**, the GLM can also handle missing data and provide accurate estimates even when some observations are missing. This makes it a valuable tool in business and academia, where the ability to model complex relationships accurately is essential.\n",
        "\n",
        "The GLM is a powerful and flexible tool integral to modern data analysis. Its ability to model complex relationships between variables and handle missing data has made it a valuable asset in business and academia.\n",
        "\n",
        "**Maximum Likelihood Estimation (MLE)** is a statistical technique used to estimate the parameters of a model by analyzing the observed data. This method involves finding the optimal values for the model parameters by maximizing the likelihood function. The likelihood function measures how well the model can explain the observed data. The higher the likelihood function, the more accurate the model explains the data. MLE is widely used in fields such as finance, economics, and engineering to create models that can predict future outcomes based on the available data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key features of Generalized Linear Models\n",
        "\n",
        "1.  **Link Function:** GLMs are characterized by a **link function** that connects the linear predictor, a combination of independent variables, to the mean of the dependent variable. This connection enables the estimation of the relationship between independent and dependent variables in a non-linear fashion.\n",
        "\n",
        "The selection of a link function in GLMs is contingent upon the nature of the data and the distribution of the response variable. The `identity` link function is utilized when the continuous response variable follows a normal distribution. The `logit` link function is employed when the response variable is binary, meaning it can only take on two values and follows a binomial distribution. The `log` link function is utilized when the response variable is count data and follows a Poisson distribution.\n",
        "\n",
        "Choosing an appropriate link function is a crucial aspect of modeling, as it impacts the interpretation of the estimated coefficients for independent variables. Therefore, a thorough understanding of the nature of the data and the response variable's distribution is necessary when selecting a link function.\n",
        "\n",
        "2.  **Distribution Family:** Unlike linear regression, which assumes a normal distribution for the residuals, GLMs allow for a variety of probability distributions for the response variable. The choice of distribution is based on the characteristics of the data. Commonly used distributions include:\n",
        "\n",
        "    -   **Normal distribution (Gaussian):** For continuous data.\n",
        "\n",
        "    -   **Binomial distribution:** For binary or dichotomous data.\n",
        "\n",
        "    -   **Poisson distribution:** For count data.\n",
        "\n",
        "    -   **Gamma distribution:** For continuous, positive, skewed data.\n",
        "\n",
        "3.  **Variance Function:** GLMs accommodate heteroscedasticity (unequal variances across levels of the independent variables) by allowing the variance of the response variable to be a function of the mean.\n",
        "\n",
        "4.  **Deviance:** Instead of using the sum of squared residuals as in linear regression, GLMs use deviance to measure lack of fit. Deviance compares the fit of the model to a saturated model (a model that perfectly fits the data).\n",
        "\n",
        "The **mathematical expression** of a Generalized Linear Model (GLM) involves the linear predictor, the link function, and the probability distribution of the response variable.\n",
        "\n",
        "Here's the general form of a GLM:\n",
        "\n",
        "1.  **Linear Predictor (η):**\n",
        "\n",
        "    $$ \\eta = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_kx_k $$\n",
        "\n",
        "    where:\n",
        "\n",
        "-   $\\eta$ is the linear predictor,\n",
        "\n",
        "-   $\\beta_0, \\beta_1, \\ldots, \\beta_k$ are the coefficients,\n",
        "\n",
        "-   $x_1, x_2, \\ldots, x_k$ are the independent variables.\n",
        "\n",
        "2.  **Link Function (**g):\n",
        "\n",
        "$$ g(\\mu) = \\eta $$\n",
        "\n",
        "The link function connects the linear predictor to the mean of the response variable. It transforms the mean (μ) to the linear predictor (η). Common link functions include:\n",
        "\n",
        "-   Identity link (for normal distribution):\n",
        "\n",
        "$$ g(\\mu) = \\mu $$\n",
        "\n",
        "-   Logit link (for binary data in logistic regression):\n",
        "\n",
        "$$ g(\\mu) = log(\\frac{\\mu}{1-\\mu}) $$\n",
        "\n",
        "-   Log link(for Poisson regression):\n",
        "\n",
        "$$ g(\\mu) = \\log(\\mu )$$\n",
        "\n",
        "3.  **Probability Distribution:** The response variable follows a probability distribution from the exponential family. The distribution is chosen based on the nature of the data. Common choices include:\n",
        "\n",
        "    -   Normal distribution (Gaussian) for continuous data.\n",
        "\n",
        "    -   Binomial distribution for binary or dichotomous data.\n",
        "\n",
        "    -   Poisson distribution for count data.\n",
        "\n",
        "    -   Gamma distribution for continuous, positive, skewed data.\n",
        "\n",
        "Putting it all together, the probability mass function (PMF) or probability density function (PDF) for the response variable (Y) is expressed as:\n",
        "\n",
        "$$ f(y;\\theta,\\phi) = \\exp\\left(\\frac{y\\theta - b(\\theta)}{a(\\phi)} + c(y,\\phi)\\right) $$\n",
        "\n",
        "where:\n",
        "\n",
        "-   f(y;θ,ϕ) is the PMF or PDF,\n",
        "\n",
        "-   θ is the natural parameter,\n",
        "\n",
        "-   ϕ is the dispersion parameter,\n",
        "\n",
        "-   a(ϕ), b(θ), c(y,ϕ) are known functions."
      ],
      "metadata": {
        "id": "G31UbMNZmo_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression vs Generalized Linear Models\n",
        "\n",
        "The primary difference between linear models (LM) and generalized linear models (GLM) is in their flexibility to handle different types of response variables and error distributions. Here’s a breakdown of the key distinctions:\n",
        "\n",
        "### 1. **Type of Response Variable**\n",
        "\n",
        "-   **LM (Linear Model)**: Assumes that the response variable is continuous and normally distributed. For example, predicting a continuous variable like height or weight.\n",
        "-   **GLM (Generalized Linear Model)**: Extends linear models to accommodate response variables that are not normally distributed, such as binary outcomes (0 or 1), counts, or proportions. GLMs can handle a variety of distributions (e.g., binomial, Poisson).\n",
        "\n",
        "### 2. **Link Function**\n",
        "\n",
        "-   **LM**: The relationship between the predictor variables and the response is assumed to be linear, with an identity link function (i.e., ($Y = X \\beta + \\epsilon$), where ($\\epsilon$) is normally distributed).\n",
        "-   **GLM**: Uses a link function to transform the linear predictor to accommodate different types of response variables. Common link functions include:\n",
        "    -   **Logit link** for binary data (logistic regression)\n",
        "    -   **Log link** for count data (Poisson regression)\n",
        "    -   **Identity link** for normal data (same as in LM)\n",
        "\n",
        "### 3. **Error Distribution**\n",
        "\n",
        "-   **LM**: Assumes errors are normally distributed with constant variance (homoscedasticity).\n",
        "-   **GLM**: Allows for different error distributions (e.g., binomial, Poisson, gamma) to better suit the data.\n",
        "\n",
        "### 4. **Use Cases**\n",
        "\n",
        "-   **LM**: Used when the response variable is continuous, normally distributed, and has a linear relationship with predictors.\n",
        "-   **GLM**: Used when the response variable does not fit these assumptions, such as binary outcomes (yes/no), counts, or proportions.\n",
        "\n",
        "### 5. **Examples**\n",
        "\n",
        "-   **LM**: Simple linear regression, multiple linear regression\n",
        "-   **GLM**: Logistic regression, Poisson regression, negative binomial regression, etc.\n",
        "\n",
        "In summary, GLMs generalize LMs by allowing for non-normal distributions and providing flexibility with link functions, making them more suitable for a wider range of data types and applications.\n",
        "\n",
        "In summary, the GLM combines the linear predictor, link function, and probability distribution to model the relationship between the mean of the response variable and the predictors, allowing for flexibility in handling various data types. The specific form of the GLM will depend on the chosen link function and distribution.\n"
      ],
      "metadata": {
        "id": "6b4_fnspfnyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GLM Models in R\n",
        "\n",
        "Before starting, ensure you have R and the necessary packages installed. Key packages include `stats` (for basic GLMs) and `mgcv` (for Generalized Additive Models). You may also need packages such as `MASS` for ordinal models and `betareg` for Beta regression.\n",
        "\n",
        "``` r\n",
        "# Install necessary packages if you haven't already\n",
        "install.packages(c(\"MASS\", \"mgcv\", \"betareg\"))\n",
        "```\n",
        "\n",
        "The basic form of the `glm()` function is:\n",
        "\n",
        "> glm(formula , family= familytype(link=linkfunction), data=)\n",
        "\n",
        "Family objects are a convenient way to specify the models used by functions like `glm()`. See `help(family)` for other allowable `link` functions for each family.\n",
        "\n",
        "`binomial(link = \"logit\")`\n",
        "\n",
        "`gaussian(link = \"identity\")`\n",
        "\n",
        "`Gamma(link = \"inverse\")`\n",
        "\n",
        "`inverse.gaussian(link = \"1/mu\\^2\")`\n",
        "\n",
        "`poisson(link = \"log\")`\n",
        "\n",
        "`quasi(link = \"identity\", variance = \"constant\")`\n",
        "\n",
        "`quasibinomial(link = \"logit\")`\n",
        "\n",
        "`quasipoisson(link = \"log\")`\n",
        "\n",
        "There are several GLM model families depending on the make-up of the response variable.\n",
        "\n",
        "### 1. [Generalized Linear Regression (Gaussian)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-01-glm-regression-r.ipynb)\n",
        "\n",
        "A Gaussian GLM is essentially linear regression and is useful when the response variable is continuous and normally distributed.\n",
        "\n",
        "``` r\n",
        "# Example of linear regression\n",
        "model_gaussian <- glm(y ~ x1 + x2, data = data, family = gaussian)\n",
        "summary(model_gaussian)\n",
        "```\n",
        "\n",
        "### 2. [Logistic Regression (Binary)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-02-glm-logistic-r.ipynb)\n",
        "\n",
        "Logistic regression models binary outcomes (0 or 1) and uses the logit link function to model probabilities.\n",
        "\n",
        "``` r\n",
        "# Example of logistic regression\n",
        "model_logistic <- glm(y ~ x1 + x2, data = data, family = binomial)\n",
        "summary(model_logistic)\n",
        "```\n",
        "\n",
        "### 3. [Probit Regression Model](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-03-glm-probit-r.ipynb)\n",
        "\n",
        "Probit regression is similar to logistic regression but uses the probit link function. It's useful for modeling binary outcomes when the probit function is a better fit than the logit.\n",
        "\n",
        "``` r\n",
        "# Example of probit regression\n",
        "model_probit <- glm(y ~ x1 + x2, data = data, family = binomial(link = \"probit\"))\n",
        "summary(model_probit)\n",
        "```\n",
        "\n",
        "### 4. [Ordinal Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-04-glm-ordinal-r.ipynb)\n",
        "\n",
        "Ordinal regression models ordered categorical outcomes. The `polr` function from the `MASS` package can be used for this purpose.\n",
        "\n",
        "``` r\n",
        "# Example of ordinal regression\n",
        "library(MASS)\n",
        "model_ordinal <- polr(y ~ x1 + x2, data = data, Hess = TRUE)\n",
        "summary(model_ordinal)\n",
        "```\n",
        "\n",
        "### 5. [Multinomial Logistic Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-05-glm-multinomial-logistic-r.ipynb)\n",
        "\n",
        "For nominal categorical responses with more than two levels, multinomial logistic regression can be used. The `nnet` package provides `multinom` for fitting such models.\n",
        "\n",
        "``` r\n",
        "# Example of multinomial logistic regression\n",
        "library(nnet)\n",
        "model_multinom <- multinom(y ~ x1 + x2, data = data)\n",
        "summary(model_multinom)\n",
        "```\n",
        "\n",
        "### 6. [Poisson Regression ](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-02-06-00-poisson-regression-introduction-r.ipynb)\n",
        "\n",
        "Poisson regression is used for count data and models the log of the expected counts.\n",
        "\n",
        "``` r\n",
        "# Example of Poisson regression\n",
        "model_poisson <- glm(y ~ x1 + x2, data = data, family = poisson)\n",
        "summary(model_poisson)\n",
        "```\n",
        "\n",
        "### 7. [Gamma Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-07-glm-gamma-regression-r.ipynb)\n",
        "\n",
        "Gamma regression is useful for modeling positive continuous outcomes with skewness.\n",
        "\n",
        "``` r\n",
        "# Example of Gamma regression\n",
        "model_gamma <- glm(y ~ x1 + x2, data = data, family = Gamma(link = \"log\"))\n",
        "summary(model_gamma)\n",
        "```\n",
        "\n",
        "### 8. [Beta Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-08-glm-gamma-regression-r.ipynb)\n",
        "\n",
        "Beta regression is used for modeling continuous data bounded between 0 and 1. The `betareg` package provides the `betareg` function for this purpose.\n",
        "\n",
        "``` r\n",
        "# Example of Beta regression\n",
        "library(betareg)\n",
        "model_beta <- betareg(y ~ x1 + x2, data = data)\n",
        "summary(model_beta)\n",
        "```\n",
        "\n",
        "### 9. [Generalized Additive Model (GAM) ](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-02-09-glm-gam-regression.ipynb)\n",
        "\n",
        "GAMs allow for flexible relationships between predictors and the response by using smooth functions. The `mgcv` package’s `gam` function is used for GAMs.\n",
        "\n",
        "``` r\n",
        "# Example of GAM\n",
        "library(mgcv)\n",
        "model_gam <- gam(y ~ s(x1) + s(x2), data = data, family = gaussian)\n",
        "summary(model_gam)\n",
        "```\n"
      ],
      "metadata": {
        "id": "0UzCmbKxl-5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "This tutorial covered various GLMs, each suited to different types of response data. Use `summary()` to inspect model results and diagnostics for each type of GLM. These models allow for a range of data structures and distributions, making them a versatile toolset in R for real-world applications."
      ],
      "metadata": {
        "id": "wc-0EJsSQkrT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUHrNY9J9lMg"
      },
      "source": [
        "## References\n",
        "\n",
        "1. [An Introduction to Statistical Learning](https://www.stat.berkeley.edu/~rabbee/s154/ISLR_First_Printing.pdf)\n",
        "\n",
        "2. [Generalized Linear Models With Examples in R](https://www.academia.edu/37886943/Springer_Texts_in_Statistics_Generalized_Linear_Models_With_Examples_in_R)\n",
        "\n",
        "3. [6.1 - Introduction to GLMs}](https://online.stat.psu.edu/stat504/lesson/6/6.1)\n",
        "\n",
        "4. [4 Generalized Linear Models](https://entnemdept.ufl.edu/Hahn/generalized-linear-models.html)\n",
        "\n",
        "5. [Generalized Linear Model](https://www.sciencedirect.com/topics/mathematics/generalized-linear-model)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Books\n",
        "\n",
        "### **Generalized Linear Models (GLMs)**\n",
        "1. **\"Generalized Linear Models\"** – *P. McCullagh and J.A. Nelder*  \n",
        "   - A classic, foundational text on GLMs.  \n",
        "\n",
        "2. **\"Generalized Linear Models with Examples in R\"** – *Peter K. Dunn and Gordon K. Smyth*  \n",
        "   - Practical applications of GLMs, including Gamma and Beta models, using R.  \n",
        "\n",
        "3. **\"Generalized Linear Models and Extensions\"** – *James W. Hardin and Joseph M. Hilbe*  \n",
        "   - Covers extensions of GLMs, with real-world applications.  \n",
        "\n",
        "4. **\"An Introduction to Generalized Linear Models\"** – *Annette J. Dobson and Adrian G. Barnett*  \n",
        "   - A beginner-friendly introduction with examples in R.  \n",
        "\n",
        "5. **\"Extending the Linear Model with R: Generalized Linear, Mixed Effects and Nonparametric Regression Models\"** – *Julian J. Faraway*  \n",
        "   - Covers GLMs, mixed models, and nonparametric regression with R.  \n",
        "\n",
        "6. **\"Applied Regression Analysis and Generalized Linear Models\"** – *John Fox*  \n",
        "   - A comprehensive introduction to regression analysis, including GLMs.  \n",
        "\n",
        "7. **\"Regression Modeling Strategies: With Applications to Linear Models, Logistic Regression, and Survival Analysis\"** – *Frank E. Harrell Jr.*  \n",
        "   - A detailed discussion of various regression models, including logistic and Poisson regression.  \n",
        "\n",
        "8. **\"Categorical Data Analysis\"** – *Alan Agresti*  \n",
        "   - A detailed look at categorical data analysis, including GLMs.  \n",
        "\n",
        "\n",
        "### **Logistic Regression and Multinomial Models**\n",
        "9. **\"An Introduction to Statistical Learning: with Applications in R\"** – *Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani*  \n",
        "   - Covers logistic regression and other machine learning techniques with R.  \n",
        "\n",
        "10. **\"Applied Logistic Regression\"** – *David W. Hosmer Jr., Stanley Lemeshow, and Rodney X. Sturdivant*  \n",
        "   - A practical guide to logistic regression, including real-world examples.  \n",
        "\n",
        "11. **\"Logistic Regression Models\"** – *Joseph M. Hilbe*  \n",
        "   - An in-depth exploration of logistic regression with applications in R.  \n",
        "\n",
        "\n",
        "\n",
        "### **Poisson and Count Data Models**\n",
        "12. **\"Modeling Count Data\"** – *Joseph M. Hilbe*  \n",
        "   - A focused discussion on modeling count data, including Poisson regression.  \n",
        "\n",
        "13. **\"Zero-Inflated Models and Generalized Linear Mixed Models with R\"** – *Alain F. Zuur and Elena N. Ieno*  \n",
        "   - Covers Zero-Inflated Poisson models and generalized mixed models.  \n",
        "\n",
        "14. **\"Count Data Models with R\"** – *John M. Hilbe*  \n",
        "   - A detailed guide to count data models, including Hurdle and Zero-Inflated models.  \n",
        "\n",
        "15. **\"Statistical Methods for Rates and Proportions\"** – *Joseph L. Fleiss, Bruce Levin, and Myunghee Cho Paik*  \n",
        "   - Includes discussions on Poisson and binomial regression methods.  \n",
        "\n",
        "16. **\"Introduction to Probability Models\"** – *Sheldon M. Ross*  \n",
        "   - Covers the Poisson process and other probability models.  \n",
        "\n",
        "\n",
        "\n",
        "### **Generalized Additive Models (GAMs)**\n",
        "17. **\"Generalized Additive Models\"** – *Trevor Hastie and Robert Tibshirani*  \n",
        "   - The foundational book introducing GAMs.  \n",
        "\n",
        "18. **\"Generalized Additive Models: An Introduction with R\"** – *Simon N. Wood*  \n",
        "   - Covers practical implementation of GAMs using the `mgcv` package in R.  \n",
        "\n",
        "19. **\"Introduction to Generalized Additive Models\"** – *Gareth James*  \n",
        "   - A beginner-friendly introduction to GAMs.  \n",
        "\n"
      ],
      "metadata": {
        "id": "1r3Ntf17ptrd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPGPOwav3HKiUkix62Ryz/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}