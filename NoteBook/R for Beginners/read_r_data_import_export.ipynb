{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/R%20for%20Beginners/read_r_data_import_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ],
      "metadata": {
        "id": "dJ4hbA1BsuYi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGoP0AbXEAUx"
      },
      "source": [
        "#  **Data Import and Export with readr in R**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "7Xnubq0nsvWU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kroLnhoOPPoV"
      },
      "source": [
        "[**readr**](https://readr.tidyverse.org/) offers a fast and user-friendly method of reading rectangular-shaped data from delimited files, including comma-separated values (CSV) and tab-separated values (TSV). Its design is intended to parse various data types encountered in real-world scenarios, and it provides a comprehensive problem report that informs you when parsing leads to unexpected outcomes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1oWBJ6wsDdVaThjQnOzkbSu-aNERJanSD)"
      ],
      "metadata": {
        "id": "4zaBS1wiPuYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation and use\n",
        "\n",
        "The easiest way to get readr is to install the [**tidyverse**](https://www.tidyverse.org/). The tidyverse is a collection of R packages designed for data science. It includes several packages that work well together to facilitate data manipulation, visualization, and analysis in a consistent and coherent manner. Some key packages within the tidyverse include **ggplot2** for plotting, **dplyr** for data manipulation, **tidyr** for data tidying, **readr** for data import, and more.\n",
        "\n",
        "\n",
        "> install.packages(\"readr\")\n",
        "\n",
        "or\n",
        "\n",
        "> install.packages(\"tidyverse\")\n"
      ],
      "metadata": {
        "id": "bXFL_wbCQv7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1nIxQ3b5no2Pk3ivCYzgiuabCSf4djdgP)\n",
        "\n"
      ],
      "metadata": {
        "id": "XMMd_9B6Q--a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core tidyverse includes the packages that you're likely to use in everyday data analyses. As of tidyverse 1.3.0, the following packages are included in the core tidyverse:"
      ],
      "metadata": {
        "id": "D8SZZ3kuRnEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1oR3AgKt5MVj4eUn1HswZ60YUapVmqXns)\n",
        "\n"
      ],
      "metadata": {
        "id": "tPzCwnwMR7vt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdQJ-mgsEU9J"
      },
      "source": [
        "## Install rpy2\n",
        "\n",
        "Easy way to run R in Colab with Python runtime using **rpy2** python package. We have to install this package using the pip command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOD7NpajDy5k"
      },
      "outputs": [],
      "source": [
        "!pip uninstall rpy2 -y\n",
        "! pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEDD0ccEurf"
      },
      "source": [
        "##  Mount Google Drive\n",
        "\n",
        "Then you must create a folder in Goole drive named \"R\" to install all packages permanently. Before installing R-package in Python runtime. You have to mount Google Drive and follow on-screen instruction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lClKZUW1Eu_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde74f35-052e-4294-d085-dce88b7d2e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check and Install Required R Packages"
      ],
      "metadata": {
        "id": "BSAv-kcUTTo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "pkg <- c('tidyverse')\n",
        "new.packages <- pkg[!(pkg %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')"
      ],
      "metadata": {
        "id": "Nan0amGMyBv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As well as **readr**, for reading flat files, the tidyverse package installs a number of other packages for reading data:\n",
        "\n",
        "-   **DBI** for relational databases. You'll need to pair DBI with a database specific backends like *RSQLite*, *RMariaDB*, *RPostgres*, or *odbc*. Learn more at https://db.rstudio.com.\n",
        "\n",
        "-   **haven** for SPSS, Stata, and SAS data.\n",
        "\n",
        "-   **httr** for web APIs.\n",
        "\n",
        "-   **readxl** for .xls and .xlsx sheets.\n",
        "\n",
        "-   **googlesheets4** for Google Sheets via the Sheets API v4.\n",
        "\n",
        "-   **googledrive** for Google Drive files.\n",
        "\n",
        "-   **rvest** for web scraping.\n",
        "\n",
        "-   **jsonlite** for JSON. (Maintained by Jeroen Ooms.)\n",
        "\n",
        "-   **xml2** for XML\n"
      ],
      "metadata": {
        "id": "NrbG-oVET1Tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Libaray"
      ],
      "metadata": {
        "id": "1ldcblnJYfks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "library(tidyverse)"
      ],
      "metadata": {
        "id": "nCnpYUs9YftD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "\n",
        "All data set use in this exercise can be downloaded from my [Dropbox](https://www.dropbox.com/scl/fo/fohioij7h503duitpl040/h?rlkey=3voumajiklwhgqw75fe8kby3o&dl=0) or from my [Github](https://github.com/zia207/r-colab/tree/main/Data/R_Beginners) accounts.\n",
        "\n"
      ],
      "metadata": {
        "id": "pcn48RSJ2Xnk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrmMavWXGoM_"
      },
      "source": [
        "## Read CSV files with readr\n",
        "\n",
        "A `tibble`, or `tbl_df`, is the latest method for reimagining of modern data-frame and It keeps all the crucial features regarding the data frame. Since R is an old language, and some things that were useful 10 or 20 years ago now get in your way. It's difficult to change base R without breaking existing code, so most innovation occurs in `tibble()` data-frame with tibble package.\n",
        "\n",
        "*Key features of Tibble*\n",
        "\n",
        "-   A Tibble never alters the input type.\n",
        "\n",
        "-   With Tibble, there is no need for us to be bothered about the automatic changing of characters to strings.\n",
        "\n",
        "-   Tibbles can also contain columns that are the lists.\n",
        "\n",
        "-   We can also use non-standard variable names in Tibble.\n",
        "\n",
        "-   We can start the name of a Tibble with a number, or we can also contain space.\n",
        "\n",
        "-   To utilize these names, we must mention them in backticks.\n",
        "\n",
        "-   Tibble only recycles the vectors with a length of 1.\n",
        "\n",
        "-   Tibble can never generate the names of rows.\n",
        "\n",
        "source: https://www.educative.io/answers/what-is-tibble-versus-data-frame-in-r\n",
        "\n",
        "We can use following functions **readr** package to import tabular data into R as tibble:\n",
        "\n",
        "`read_csv()` and `read_tsv()` are special cases of the more general `read_delim()`. They're useful for reading the most common types of flat file data, comma separated values and tab separated values, respectively. `read_csv2()` uses ⁠;⁠ for the field separator and ⁠,⁠ for the decimal point. This format is common in some European countries.\n",
        "\n",
        "For example, we will use `read_csv()` to import CSV file and see use `glimpse()` functions of **dplyr** package to explore the file structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Before start, you need to specify the working or destination directory in where you will save the data."
      ],
      "metadata": {
        "id": "QGMv7X8v74LC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXfSYaGPGpbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659f313e-7eb3-4e80-9bbd-78d6ed56f123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 20 Columns: 23\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr  (1): Subject\n",
            "dbl (22): Napthalene, 1-Methyl Napthalene, 2-Methyl Napthalene, Acenapthylen...\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "Rows: 20\n",
            "Columns: 23\n",
            "$ Subject                     <chr> \"P1\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", …\n",
            "$ Napthalene                  <dbl> 0.8993, 3.6257, 3.3921, 3.5772, 4.4907, NA…\n",
            "$ `1-Methyl Napthalene`       <dbl> 4.9681, 4.6941, 3.5386, 4.7475, 5.1147, NA…\n",
            "$ `2-Methyl Napthalene`       <dbl> 2.1508, 3.9316, 1.6955, 2.9361, 3.9976, NA…\n",
            "$ Acenapthylene               <dbl> 0.0131, 3.0151, 1.3859, 3.3943, 6.6593, NA…\n",
            "$ `1,2 Dimethyl napthalene`   <dbl> NA, NA, 1.2389, 2.6427, 2.1442, NA, 0.3623…\n",
            "$ `1,6 Dimethyl Napthalene`   <dbl> 0.7003, 2.6382, 1.3807, 1.1006, 2.2575, NA…\n",
            "$ Fluorene                    <dbl> 2.2481, 7.3490, 7.1567, 8.4422, 9.2363, NA…\n",
            "$ `1,6,7 Trimethylnapthalene` <dbl> 5.1024, 6.7913, 6.5171, 4.6803, 6.4649, NA…\n",
            "$ Anthracene                  <dbl> 10.1656, 9.6419, 22.3997, 26.3787, 20.9594…\n",
            "$ Dibenzothiopene             <dbl> 1.1633, 4.1160, 4.2256, 3.9885, 3.2560, NA…\n",
            "$ `2-Methyl Anthracene`       <dbl> 0.5409, 4.5190, 8.4014, 13.0101, 4.4900, N…\n",
            "$ `1-Methylphenanthrene`      <dbl> 14.9581, 12.0937, 19.4927, 11.2138, 2.0336…\n",
            "$ `2-Methylphenanthrene`      <dbl> 5.4785, 18.2456, 36.4282, 16.4553, 10.8040…\n",
            "$ Pyrene                      <dbl> 4.8498, 14.9369, 10.1099, 26.0579, 20.8687…\n",
            "$ Fluoranthene                <dbl> 4.4798, 9.7189, 9.8037, 19.0489, 20.0866, …\n",
            "$ `1-Phenyl napthalene`       <dbl> 2.8778, 6.2493, 5.2998, 7.9514, 10.1570, N…\n",
            "$ `2-Phenyl napthalene`       <dbl> 3.4092, 8.7412, 3.6956, 12.8510, 15.1037, …\n",
            "$ `1 Methylpyrene`            <dbl> 4.5763, 7.5114, 13.6010, 8.1125, 19.2354, …\n",
            "$ `Benzo(c)phenanthrene`      <dbl> 3.6456, 7.0372, 5.0960, 3.3828, 8.1571, NA…\n",
            "$ `Triphenylene/Chrysene`     <dbl> 1.7422, 5.1389, 3.1635, 5.7081, 6.7483, NA…\n",
            "$ `Benz(a)pyrene`             <dbl> NA, 2.8455, NA, 5.0701, 0.5873, NA, 9.0914…\n",
            "$ `Benz(e)pyrene`             <dbl> NA, 1.8163, 0.2980, 0.6617, 2.3666, NA, 2.…\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "dataFolder<- \"/content/drive/MyDrive/R_Website/R_Bigenner/Data/\"\n",
        "df.chem_01<-readr::read_csv(paste0(dataFolder,\"PAHdata.csv\"))\n",
        "dplyr::glimpse(df.chem_01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write CSV files with readr\n",
        "\n",
        "The `write()`⁠ family functions of are an improvement to analogous function such as `write.csv()` because they are approximately twice as fast. Unlike `write.csv()`, these functions do not include row names as a column in the written file. A generic function, output_column(), is applied to each variable to coerce columns to suitable output.\n",
        "\n",
        "We can use following functions **readr** package to extort tabular data from R:"
      ],
      "metadata": {
        "id": "SqJQoPMbC4sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1oJZIXaocGY6FoaHmXInqTNx6_j-TKYJd)"
      ],
      "metadata": {
        "id": "YD89tjhFV8z5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKU4UEAtHTHd"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "dataFolder<- \"/content/drive/MyDrive/R_Website/R_Bigenner/Data/\"\n",
        "# write as xlsx file\n",
        "readr::write_csv(df.chem_01, paste0(dataFolder,\"df.chem_01.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use `as_tibble()` function of **tibble** package"
      ],
      "metadata": {
        "id": "l1vfNT2E3YY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.chem_03<-tibble::as_tibble(read.csv(paste0(dataFolder,\"PAHdata.csv\"), check.names = FALSE))\n",
        "str(df.chem_03)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-KkDEuYWyQs",
        "outputId": "0fb42627-5b89-4241-f5cd-7f1472cf79c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tibble [20 × 23] (S3: tbl_df/tbl/data.frame)\n",
            " $ Subject                  : chr [1:20] \"P1\" \"P3\" \"P4\" \"P5\" ...\n",
            " $ Napthalene               : num [1:20] 0.899 3.626 3.392 3.577 4.491 ...\n",
            " $ 1-Methyl Napthalene      : num [1:20] 4.97 4.69 3.54 4.75 5.11 ...\n",
            " $ 2-Methyl Napthalene      : num [1:20] 2.15 3.93 1.7 2.94 4 ...\n",
            " $ Acenapthylene            : num [1:20] 0.0131 3.0151 1.3859 3.3943 6.6593 ...\n",
            " $ 1,2 Dimethyl napthalene  : num [1:20] NA NA 1.24 2.64 2.14 ...\n",
            " $ 1,6 Dimethyl Napthalene  : num [1:20] 0.7 2.64 1.38 1.1 2.26 ...\n",
            " $ Fluorene                 : num [1:20] 2.25 7.35 7.16 8.44 9.24 ...\n",
            " $ 1,6,7 Trimethylnapthalene: num [1:20] 5.1 6.79 6.52 4.68 6.46 ...\n",
            " $ Anthracene               : num [1:20] 10.17 9.64 22.4 26.38 20.96 ...\n",
            " $ Dibenzothiopene          : num [1:20] 1.16 4.12 4.23 3.99 3.26 ...\n",
            " $ 2-Methyl Anthracene      : num [1:20] 0.541 4.519 8.401 13.01 4.49 ...\n",
            " $ 1-Methylphenanthrene     : num [1:20] 14.96 12.09 19.49 11.21 2.03 ...\n",
            " $ 2-Methylphenanthrene     : num [1:20] 5.48 18.25 36.43 16.46 10.8 ...\n",
            " $ Pyrene                   : num [1:20] 4.85 14.94 10.11 26.06 20.87 ...\n",
            " $ Fluoranthene             : num [1:20] 4.48 9.72 9.8 19.05 20.09 ...\n",
            " $ 1-Phenyl napthalene      : num [1:20] 2.88 6.25 5.3 7.95 10.16 ...\n",
            " $ 2-Phenyl napthalene      : num [1:20] 3.41 8.74 3.7 12.85 15.1 ...\n",
            " $ 1 Methylpyrene           : num [1:20] 4.58 7.51 13.6 8.11 19.24 ...\n",
            " $ Benzo(c)phenanthrene     : num [1:20] 3.65 7.04 5.1 3.38 8.16 ...\n",
            " $ Triphenylene/Chrysene    : num [1:20] 1.74 5.14 3.16 5.71 6.75 ...\n",
            " $ Benz(a)pyrene            : num [1:20] NA 2.845 NA 5.07 0.587 ...\n",
            " $ Benz(e)pyrene            : num [1:20] NA 1.816 0.298 0.662 2.367 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary and Conclusion\n",
        "\n",
        "This tutorial provides an overview of the data import-export capabilities offered by the R package **readr**. By simplifying the process of reading and writing data in R, **readr** offers a seamless experience for handling various file formats. The tutorial begins by demonstrating how to use `read_csv()`, `read_tsv()`, and `read_delim()` functions to read data from CSV, TSV, and custom-delimited files respectively. The automatic data type inference and streamlined reading process make **readr** a valuable tool for handling diverse datasets. In addition, the tutorial covers the export functionalities of **readr**, demonstrating how to use `write_csv()`, `write_tsv()`, and `write_delim()` functions to write data frames to external files in a straightforward manner. The consistency in syntax across reading and writing functions simplifies the data import-export process. Another highlight is readr's support for handling large datasets efficiently, making it an ideal choice for projects involving extensive data volumes. As you integrate **readr** into your data analysis workflow, it is recommended that you explore its additional features, such as custom column types, locale settings, and flexible options for handling missing or malformed data. Leveraging these capabilities will enhance your ability to handle various data scenarios."
      ],
      "metadata": {
        "id": "qAFMeBzsIcc5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ovc25MJTsD8"
      },
      "source": [
        "## References\n",
        "\n",
        "1.  [Many Ways of Reading Data Into R 1](https://medium.com/analytics-vidhya/many-ways-of-reading-data-into-r-1-52b02825cb27)\n",
        "\n",
        "2.  [readr](https://readr.tidyverse.org/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNaKRBko0vxNvBXeRKLetWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}