{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPqs57zQl1OXkXKOTFGRbzK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/Machine_Learning/Tree_based/03-01-03-02-tree-based-models-gradient-boosted-lightgbm-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ],
      "metadata": {
        "id": "4qrItz_mJNWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Light Gradient Boosting Machine (LightGBM)\n",
        "\n",
        "LightGBM (Light Gradient Boosting Machine) is an open-source gradient boosting framework that is designed to be both efficient and scalable. It is based on the gradient boosting framework and uses a tree-based learning algorithm. This tutorial will guide you through the concepts and implementation of LightGBM, including its advantages, how it works, and how to implement it in R with {lightgbm} package.\n"
      ],
      "metadata": {
        "id": "Dzp9ZseROTcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Light Gradient Boosting Machine (LightGBM) is a high-performance, distributed, and efficient gradient boosting framework designed for speed and scalability, particularly for large-scale datasets. Developed by Microsoft, it is optimized for tasks like classification, regression, ranking, and other machine learning problems. LightGBM is part of the gradient boosting family, which builds an ensemble of weak learners (typically decision trees) to create a strong predictive model. LightGBM stands out due to its focus on computational efficiency and memory optimization, making it faster and less resource-intensive than other gradient boosting frameworks like XGBoost, especially for large datasets with high-dimensional features.\n"
      ],
      "metadata": {
        "id": "mLkAu88QToVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Features of LightGBM\n",
        "\n",
        "- Histogram-based learning for speed and low memory use.\n",
        "- Leaf-wise tree growth for high accuracy.\n",
        "- Native categorical feature support.\n",
        "- Parallel and GPU training.\n",
        "- Sparse data optimization.\n",
        "- Custom loss functions.\n",
        "- Feature importance and early stopping."
      ],
      "metadata": {
        "id": "WL2L7JRduO3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How LightGBM Works\n",
        "\n",
        "LightGBM (Light Gradient Boosting Machine) operates as a gradient boosting framework that builds an ensemble of decision trees iteratively to minimize a loss function. Below is an explanation of each step in the provided flowchart, including relevant equations where applicable.\n",
        "\n",
        "\n",
        "1. Data Preprocessing\n",
        "\n",
        "In the \"Data Preprocessing\" step, the algorithm loads the dataset, handles categorical features, and discretizes continuous features into histograms to optimize computation. This involves transforming feature values $x_j$ for feature $j$ into discrete bins $h_j(x_j)$), where the number of bins $k$ is predefined, reducing memory usage and speeding up subsequent calculations.\n",
        "\n",
        "2. Initialize Model\n",
        "\n",
        "Sets the initial predictions for all instances, typically starting with a constant value that minimizes the loss function. This is expressed as:\n",
        "\n",
        "$$ \\hat{y}_i^{(0)} = \\arg\\min_{\\gamma} \\sum_{i=1}^n L(y_i, \\gamma) $$\n",
        "\n",
        "where $L$ represents the loss function (e.g., mean squared error for regression or log loss for classification), and $y_i$ is the true target value for instance $i$.\n",
        "\n",
        "2. Compute Gradients and Hessians\n",
        "\n",
        "Calculates the first-order (gradient) and second-order (Hessian) derivatives of the loss function with respect to the predictions. These guide the tree-building process.\n",
        "\n",
        "Gradient:\n",
        "\n",
        "$$ g_i^{(t)} = \\frac{\\partial L(y_i, \\hat{y}_i^{(t-1)})}{\\partial \\hat{y}_i^{(t-1)}} $$\n",
        "Hessain:\n",
        "\n",
        "$$  h_i^{(t)} = \\frac{\\partial^2 L(y_i, \\hat{y}_i^{(t-1)})}{\\partial (\\hat{y}_i^{(t-1)})^2} $$\n",
        "\n",
        "These are computed for each instance $i$ at iteration $t$.\n",
        "\n",
        "3. Apply GOSS (Gradient-based One-Side Sampling)\n",
        "\n",
        "This step reduces the dataset size by sampling instances based on their gradient magnitudes, prioritizing those with larger gradients to focus on hard examples. The sampling probability is proportional to $p_i \\propto |g_i|$, allowing the algorithm to use a subset of instances for constructing the next tree, thus improving efficiency.\n",
        "\n",
        "::: callout-note\n",
        "Gradient-based One-Side Sampling\" (GOSS):\n",
        "\n",
        "Gradient-based One-Side Sampling (GOSS) is a data subsampling method used in LightGBM. GOSS is designed to speed up the training process of gradient boosting algorithms while maintaining or improving the model's accuracy.GOSS works by first sorting the training instances according to their gradients. The instances with larger gradients are considered more important for the model, as they provide more information about the loss function\n",
        ":::\n",
        "\n",
        "\n",
        "4. Apply EFB (Exclusive Feature Bundling)\n",
        "\n",
        "During the \"Apply EFB (Exclusive Feature Bundling)\" step, the algorithm groups mutually exclusive features into bundles to reduce dimensionality while minimizing information loss, which is particularly useful for sparse datasets. This involves combining features with no overlapping non-zero values into a single histogram, optimizing the feature space without significant loss of predictive power.\n",
        "\n",
        "5. Build Decision Tree (Histogram-based, Leaf-wise growth)\n",
        "\n",
        "The \"Build Decision Tree (Histogram-based, Leaf-wise growth)\" step constructs a decision tree using histogram-based splitting and selects the leaf with the maximum loss reduction for splitting, known as leaf-wise growth.\n",
        "\n",
        "The optimal output for a leaf $q$ is  defined as:\n",
        "\n",
        "$$\\gamma_q = -\\frac{G_q}{H_q + \\lambda}$$\n",
        "where $G_q = \\sum_{i \\in q} g_i$ is the sum of gradients, $H_q = \\sum_{i \\in q} h_i$ is the sum of Hessians, and $\\lambda$ is a regularization parameter. The gain (loss reduction) from a split is calculated as:\n",
        "\n",
        "$$ \\text{Gain} = \\frac{1}{2} \\left[ \\frac{G_L^2}{H_L + \\lambda} + \\frac{G_R^2}{H_R + \\lambda} - \\frac{G_q^2}{H_q + \\lambda} \\right] - \\gamma $$\n",
        "\n",
        "where $L$ and $R$ denote the left and right child nodes.\n",
        "\n",
        "6. Update Model Predictions\n",
        "\n",
        "The algorithm incorporates the new tree's contribution into the existing predictions, refining the model iteratively. This is done using the following equation:\n",
        "\n",
        "$$ \\hat{y}_i^{(t)} = \\hat{y}_i^{(t-1)} + \\eta \\cdot \\text{tree}_t(x_i) $$\n",
        "where $\\eta$ is the learning rate and $\\text{tree}_t(x_i)$ is the prediction from the new tree for instance $i$ at iteration $t$.\n",
        "\n",
        "::: callout-note\n",
        "Leaf-wise Growth:\n",
        "\n",
        "\"Leaf-wise\" growth strategy is a tree building algorithm used in gradient boosting algorithms such as LightGBM. In this strategy, the tree is grown leaf-wise, meaning that it starts by growing the tree with a single root node, and then at each step, it selects the leaf node that yields the largest reduction in the loss function, and splits it into two child nodes\n",
        ":::\n",
        "\n",
        "7. Check Stopping Criteria\n",
        "\n",
        "This step evaluates whether to continue training by checking if the maximum number of trees is reached or if convergence is achieved. This is determined by conditions such as $t \\geq \\text{max_trees}$ or $\\Delta L < \\epsilon$, where $\\Delta L$ is the change in loss and $\\epsilon$ is a small threshold, halting the process when no significant improvement is observed.\n",
        "\n",
        "8. Output Final Model\n",
        "\n",
        "Finally, the \"Output Final Model\" step combines all the trained trees to produce the final predictive model, which is the sum of contributions from each tree. The final prediction for an instance $i$ is given by:\n",
        "\n",
        "$$ \\hat{y}_i = \\sum_{t=1}^T \\eta \\cdot \\text{tree}_t(x_i)  $$\n",
        "\n",
        "where $T$ is the total number of trees, providing the complete model for inference."
      ],
      "metadata": {
        "id": "UXUhbmJVU64j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here below is a flowchart illustrating the lightGBM workflow:\n",
        "\n",
        "\n",
        "![alt text](http://drive.google.com/uc?export=view&id=197dEVzOVTfItn4SMIM-1i-bQc-QVRPNb)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uWCTcHkzvHE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages of LightGBM\n",
        "\n",
        "It is designed to be distributed and efficient with the following advantages:\n",
        "\n",
        "-   Faster training speed and higher efficiency.\n",
        "\n",
        "-   Lower memory usage.\n",
        "\n",
        "-   Better accuracy.\n",
        "\n",
        "-   Support of parallel, distributed, and GPU learning.\n",
        "\n",
        "-   Capable of handling large-scale data."
      ],
      "metadata": {
        "id": "NuhrbXQxGIIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations of LightGBM\n",
        "\n",
        "- Leaf-wise tree growth can lead to overfitting, especially with small datasets or insufficient regularization, as it aggressively splits nodes with the highest loss reduction.\n",
        "- Histogram-based learning may reduce precision for datasets with highly skewed or sparse features, potentially losing fine-grained information.\n",
        "- Requires careful tuning of hyperparameters (e.g., learning rate, max depth, and number of leaves) to achieve optimal performance, which can be time-consuming.\n",
        "- May struggle with extremely noisy data or datasets with a very high number of categorical features, where feature bundling might oversimplify relationships.\n",
        "- Parallel and GPU support, while advantageous, can be resource-intensive and may not always scale well on very small datasets or underconstrained hardware."
      ],
      "metadata": {
        "id": "70UMhkxtGPsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Hyperparameters of LightGBM\n",
        "\n",
        "The key hyperparameters of LightGBM that significantly influence its performance include:\n",
        "\n",
        "- `learning_rate`: Controls the step size for each iteration, typically set between 0.01 and 0.1, where a smaller value (e.g., \\( \\eta \\)) slows learning but may improve generalization.\n",
        "- `num_leaves`: Determines the maximum number of leaves in one tree, with higher values (e.g., 31 or 127) increasing model complexity and risk of overfitting.\n",
        "- `max_depth`: Limits the maximum depth of each tree, preventing overfitting by capping growth (e.g., 5-10 is common).\n",
        "- `min_data_in_leaf`: Sets the minimum number of data points in a leaf, helping to avoid overfitting (e.g., 20-100 depending on dataset size).\n",
        "- `feature_fraction`: Specifies the fraction of features to consider per tree (e.g., 0.8), introducing randomness to reduce overfitting.\n",
        "- `bagging_fraction`: Defines the fraction of data to sample for each iteration (e.g., 0.9), aiding in reducing variance.\n",
        "- `lambda_l1` and `lambda_l2`: Regularization parameters (L1 and L2) to penalize large weights, controlling model complexity (e.g., 0 to 1).\n",
        "- `min_gain_to_split`: Sets the minimum gain required to split a leaf, preventing unnecessary splits (e.g., 0.01).\n",
        "- `num_iterations`: Defines the total number of boosting iterations or trees to build (e.g., 100-1000), affecting training time and accuracy."
      ],
      "metadata": {
        "id": "EEG0JrW9GQRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison of GBM and LightGBM\n",
        "\n",
        "\n",
        "| **Aspect**              | **GBM (Gradient Boosting Machine)**         | **LightGBM**                              |\n",
        "|--------------------------|---------------------------------------------|-------------------------------------------|\n",
        "| `Speed and Efficiency` | Slower, less memory-efficient due to level-wise growth | Faster and memory-efficient with histogram-based learning |\n",
        "| `Tree Growth Strategy` | Level-wise, grows trees layer by layer      | Leaf-wise, splits leaf with max loss reduction |\n",
        "| `Scalability`          | Struggles with large datasets, sequential   | Optimized for large datasets, supports parallel/GPU training |\n",
        "| `Feature Handling`     | Requires preprocessed categorical features  | Natively supports categorical features    |\n",
        "| `Sampling Techniques`  | Lacks advanced sampling methods             | Uses GOSS and EFB for data/feature reduction |\n",
        "| `Overfitting Control`  | More robust due to level-wise approach      | Requires tuning (e.g., min_data_in_leaf) to prevent overfitting |\n"
      ],
      "metadata": {
        "id": "a6b4S4mWSAyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup R in Python Runtype"
      ],
      "metadata": {
        "id": "CyOope_pwUVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install {rpy2}\n",
        "\n",
        "{rpy2} is a Python package that provides an interface to the R programming language, allowing Python users to run R code, call R functions, and manipulate R objects directly from Python. It enables seamless integration between Python and R, leveraging R's statistical and graphical capabilities while using Python's flexibility. The package supports passing data between the two languages and is widely used for statistical analysis, data visualization, and machine learning tasks that benefit from R's specialized libraries."
      ],
      "metadata": {
        "id": "SDp3ULld8Gb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall rpy2 -y\n",
        "!pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "CiM6y-Mw8AJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c2fe21-e38d-4b06-8923-f7b2fbc69eaf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rpy2 3.5.17\n",
            "Uninstalling rpy2-3.5.17:\n",
            "  Successfully uninstalled rpy2-3.5.17\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (3.1.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (2025.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (5.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2==3.5.1) (3.0.2)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp311-cp311-linux_x86_64.whl size=314977 sha256=894a4a18e7a3486702dfd68e915055d3193fc772c528e755644d2e7f047255a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/55/d1/47be85a5f3f1e1f4d1e91cb5e3a4dcb40dd72147f184c5a5ef\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "O1zeuaCowiBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J-4ie4bwiJ1",
        "outputId": "8fd047d4-dd18-4165-b8ee-e7e7b7721063"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Light GBM Implementation from Scratch in R\n",
        "\n",
        "Implementing LightGBM from scratch in R for classification and regression without using any external packages involves creating a simplified version of its core concepts, such as gradient boosting with histogram-based learning and leaf-wise tree growth. Below is a basic implementation focusing on the key steps: initializing a model, computing gradients and Hessians, building decision trees iteratively, and updating predictions. This example uses a simple dataset and avoids advanced features like GOSS or EFB for simplicity."
      ],
      "metadata": {
        "id": "ztl1QBDb4MYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Synthetic Data\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lP2lCzFHBUip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Generate synthetic data\n",
        "set.seed(123)\n",
        "n <- 100\n",
        "\n",
        "# Regression data\n",
        "X_reg <- matrix(runif(n * 2), ncol = 2)  # 2 features\n",
        "y_reg <- 2 * X_reg[, 1] + 3 * X_reg[, 2] + rnorm(n)  # Linear target with noise\n",
        "\n",
        "# Classification data (binary)\n",
        "X_class <- matrix(runif(n * 2), ncol = 2)\n",
        "y_class <- ifelse(2 * X_class[, 1] + 3 * X_class[, 2] + rnorm(n) > 0, 1, 0)  # Binary target"
      ],
      "metadata": {
        "id": "aTjVIV5ZBW96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM Implementation\n",
        "\n",
        "- Parameters: `n_trees` = 10, `learning_rate` = 0.1, `max_depth` = 3, `min_data_in_leaf` = 5.\n",
        "\n",
        "- `build_tree` recursively builds a tree, returns $\\text{mean(grad)} / (\\text{mean(hess)} + 1e-10$ if `depth` = 0 or `grad` ≤ `min_data`.\n",
        "\n",
        "- Splits on first feature's median threshold, checks `min_data` in splits, recursively builds left/right subtrees, returns list with values, threshold, and feature.\n",
        "\n",
        "- `update_prediction` returns `tree * learning_rate` for numeric leaves, else compares $ x[\\text{tree$feature}] $ with `tree$threshold`, recursively calls `tree$left` or `tree$right`.\n"
      ],
      "metadata": {
        "id": "fwIhiSZNCO9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Parameters\n",
        "n_trees <- 10\n",
        "learning_rate <- 0.1\n",
        "max_depth <- 3\n",
        "min_data_in_leaf <- 5\n",
        "\n",
        "# Function to build a simple decision tree\n",
        "build_tree <- function(X, grad, hess, depth, min_data) {\n",
        "  if (depth == 0 || length(grad) <= min_data) {\n",
        "    return(mean(grad) / (mean(hess) + 1e-10))  # Leaf value\n",
        "  }\n",
        "\n",
        "  feature_idx <- 1\n",
        "  threshold <- median(X[, feature_idx])\n",
        "  left_idx <- which(X[, feature_idx] <= threshold)\n",
        "  right_idx <- which(X[, feature_idx] > threshold)\n",
        "\n",
        "  if (length(left_idx) < min_data || length(right_idx) < min_data) {\n",
        "    return(mean(grad) / (mean(hess) + 1e-10))\n",
        "  }\n",
        "\n",
        "  left_value <- build_tree(X[left_idx, ], grad[left_idx], hess[left_idx], depth - 1, min_data)\n",
        "  right_value <- build_tree(X[right_idx, ], grad[right_idx], hess[right_idx], depth - 1, min_data)\n",
        "\n",
        "  return(list(left = left_value, right = right_value, threshold = threshold, feature = feature_idx))\n",
        "}\n",
        "\n",
        "# Function to update predictions\n",
        "update_prediction <- function(x, tree) {\n",
        "  if (is.numeric(tree)) return(tree * learning_rate)\n",
        "  if (x[tree$feature] <= tree$threshold) {\n",
        "    return(update_prediction(x, tree$left))\n",
        "  } else {\n",
        "    return(update_prediction(x, tree$right))\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "vYPiX59GCiTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regression and Classification Implementation"
      ],
      "metadata": {
        "id": "8aFvX9PX6t7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Regression Implementation\n",
        "predictions_reg <- rep(mean(y_reg), n)\n",
        "for (t in 1:n_trees) {\n",
        "  gradients <- y_reg - predictions_reg  # Gradient for squared error\n",
        "  hessians <- rep(1, n)                # Hessian for squared error\n",
        "  tree <- build_tree(X_reg, gradients, hessians, max_depth, min_data_in_leaf)\n",
        "  for (i in 1:n) {\n",
        "    predictions_reg[i] <- predictions_reg[i] + update_prediction(X_reg[i, ], tree)\n",
        "  }\n",
        "}\n",
        "\n",
        "# Classification Implementation\n",
        "predictions_class <- rep(0, n)  # Initial log-odds (can start at 0)\n",
        "for (t in 1:n_trees) {\n",
        "  # Logistic loss gradient and Hessian\n",
        "  p <- 1 / (1 + exp(-predictions_class))  # Sigmoid\n",
        "  gradients <- p - y_class               # Gradient for log loss\n",
        "  hessians <- p * (1 - p)                # Hessian for log loss\n",
        "  tree <- build_tree(X_class, gradients, hessians, max_depth, min_data_in_leaf)\n",
        "  for (i in 1:n) {\n",
        "    predictions_class[i] <- predictions_class[i] + update_prediction(X_class[i, ], tree)\n",
        "  }\n",
        "}\n",
        "\n",
        "# Output results\n",
        "cat(\"Regression Predictions:\\n\")\n",
        "print(head(predictions_reg))\n",
        "cat(\"\\nClassification Predictions (Log-Odds):\\n\")\n",
        "print(head(predictions_class))\n",
        "cat(\"\\nClassification Probabilities:\\n\")\n",
        "print(head(1 / (1 + exp(-predictions_class))))  # Convert to probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foG5zY1Kcbe9",
        "outputId": "55a52977-3aaa-434a-e441-effb32b5f8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Predictions:\n",
            "[1] 2.433534 2.892064 2.141685 2.892064 3.074677 2.022697\n",
            "\n",
            "Classification Predictions (Log-Odds):\n",
            "[1] -701.964098   -8.477481 -701.964098 -701.964098   -8.477481   -8.477481\n",
            "\n",
            "Classification Probabilities:\n",
            "[1] 1.383138e-305  2.080590e-04 1.383138e-305 1.383138e-305  2.080590e-04\n",
            "[6]  2.080590e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Prediction Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "VPJv1wf3xLmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Regression Metrics\n",
        "mse <- mean((y_reg - predictions_reg)^2)\n",
        "rmse <- sqrt(mse)\n",
        "mae <- mean(abs(y_reg - predictions_reg))\n",
        "\n",
        "# Classification Metrics\n",
        "pred_prob <- 1 / (1 + exp(-predictions_class))  # Convert log-odds to probabilities\n",
        "predicted_class <- ifelse(pred_prob >= 0.5, 1, 0)  # Threshold at 0.5\n",
        "accuracy <- mean(predicted_class == y_class)\n",
        "\n",
        "# Log Loss\n",
        "epsilon <- 1e-15  # Avoid log(0)\n",
        "log_loss <- -mean(y_class * log(pred_prob + epsilon) + (1 - y_class) * log(1 - pred_prob + epsilon))\n",
        "\n",
        "# Print Results\n",
        "cat(\"Regression Evaluation:\\n\")\n",
        "cat(sprintf(\"MSE: %.4f\\n\", mse))\n",
        "cat(sprintf(\"RMSE: %.4f\\n\", rmse))\n",
        "cat(sprintf(\"MAE: %.4f\\n\", mae))\n",
        "cat(\"\\nClassification Evaluation:\\n\")\n",
        "cat(sprintf(\"Accuracy: %.4f\\n\", accuracy))\n",
        "cat(sprintf(\"Log Loss: %.4f\\n\", log_loss))"
      ],
      "metadata": {
        "id": "aSuBBDLKDHML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40ca14e-9468-4b09-cfcc-aa21b3fd53f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Evaluation:\n",
            "MSE: 1.5037\n",
            "RMSE: 1.2262\n",
            "MAE: 0.9923\n",
            "\n",
            "Classification Evaluation:\n",
            "Accuracy: 0.0500\n",
            "Log Loss: 23.8582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Light Gradient Boosting Machine (lightGBM) in R\n",
        "\n",
        "The {lightGBM} package in R is an interface to the Light Gradient Boosting Machine, a high-performance, scalable gradient boosting framework developed by Microsoft. Optimized for speed and memory efficiency, it supports regression, classification, ranking, and other machine learning tasks. Key features include histogram-based learning, Gradient-based One-Side Sampling (GOSS), Exclusive Feature Bundling (EFB), and leaf-wise tree growth, enabling faster training on large datasets compared to other boosting frameworks like XGBoost. The package provides functions to train models, make predictions, and tune hyperparameters, with native support for categorical features and parallel processing. It is widely used for its efficiency in handling high-dimensional data and large-scale applications.\n",
        "\n",
        "\n",
        "![alt text](http://drive.google.com/uc?export=view&id=1WxnlV7-utypgLOrMKfiJHXhpftvzalYF\n",
        ")"
      ],
      "metadata": {
        "id": "n5Z1SpIUbgLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LightGBM R package provides an implementation of the LightGBM algorithm, a highly efficient gradient boosting framework. Here are some key features of the LightGBM R package:\n",
        "\n",
        "1.  `High performance`: LightGBM is designed to be highly efficient and scalable, making it well-suited for large datasets and high-dimensional feature spaces. The R package provides an interface to the underlying C++ library, which allows it to take advantage of multi-threading and other optimization techniques.\n",
        "\n",
        "2.  `Cross-validation`: The LightGBM R package provides tools for cross-validation, which can be used to tune hyperparameters and assess model performance.\n",
        "\n",
        "3.  `Feature importance`: LightGBM computes the feature importance by measuring the number of times each feature is split on in the tree building process. The more a feature is used for splitting, the more important it is considered to be. The R package provides functions for visualizing the feature importance and selecting the most important features.\n",
        "\n",
        "4.  `Regularization`: LightGBM provides several regularization techniques, such as L1 and L2 regularization, to prevent overfitting. The R package provides options for controlling the amount of regularization.\n",
        "\n",
        "5.  `Missing value handling`: LightGBM can handle missing values in the data, using a default direction at each node to handle missing values.\n",
        "\n",
        "6.  `Flexibility`: LightGBM can be used for a wide range of machine learning tasks, including regression, classification, and ranking. It can also handle both numerical and categorical features, and supports custom objective functions.\n",
        "\n",
        "7.  `GPU acceleration`: The LightGBM R package supports GPU acceleration, which can significantly speed up training and inference on compatible hardware."
      ],
      "metadata": {
        "id": "qEloIhZwdk_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check amd Install Required R Packages\n",
        "\n",
        "Following R packages are required to run this notebook. If any of these packages are not installed, you can install them using the code below:"
      ],
      "metadata": {
        "id": "yXu-XY0mw1A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "packages <- c('tidyverse',\n",
        "              'plyr',\n",
        "              'lightgbm',\n",
        "              'Metrics',\n",
        "              'fastDummies',\n",
        "              'ggpmisc',\n",
        "              'Metrics')"
      ],
      "metadata": {
        "id": "TeYB57l0wz5N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Missing Packages"
      ],
      "metadata": {
        "id": "q7NH-51RYeIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Install missing packages\n",
        "new.packages <- packages[!(packages %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')"
      ],
      "metadata": {
        "id": "a0aTMYTHAraZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify Installation"
      ],
      "metadata": {
        "id": "Ah43eXWcYfpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9hpg7qnArfh",
        "outputId": "4e04631f-e9fb-4ad1-aa32-f8189e6a14f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Registered S3 methods overwritten by 'ggpp':\n",
            "  method                  from   \n",
            "  heightDetails.titleGrob ggplot2\n",
            "  widthDetails.titleGrob  ggplot2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  tidyverse        plyr    lightgbm     Metrics fastDummies     ggpmisc \n",
            "       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE \n",
            "    Metrics \n",
            "       TRUE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load R Packages"
      ],
      "metadata": {
        "id": "MV7R29xfyWQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Load packages with suppressed messages\n",
        "invisible(lapply(packages, function(pkg) {\n",
        "  suppressPackageStartupMessages(library(pkg, character.only = TRUE))\n",
        "}))"
      ],
      "metadata": {
        "id": "232jNAHBykUL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Loaded Packages"
      ],
      "metadata": {
        "id": "ULxgK067YntF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Check loaded packages\n",
        "cat(\"Successfully loaded packages:\\n\")\n",
        "print(search()[grepl(\"package:\", search())])# Check loaded packageswer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcAOZzmSYk4n",
        "outputId": "f9789e8e-8a32-401c-e4fe-1ca33e44446f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded packages:\n",
            " [1] \"package:ggpmisc\"     \"package:ggpp\"        \"package:fastDummies\"\n",
            " [4] \"package:Metrics\"     \"package:lightgbm\"    \"package:plyr\"       \n",
            " [7] \"package:lubridate\"   \"package:forcats\"     \"package:stringr\"    \n",
            "[10] \"package:dplyr\"       \"package:purrr\"       \"package:readr\"      \n",
            "[13] \"package:tidyr\"       \"package:tibble\"      \"package:ggplot2\"    \n",
            "[16] \"package:tidyverse\"   \"package:tools\"       \"package:stats\"      \n",
            "[19] \"package:graphics\"    \"package:grDevices\"   \"package:utils\"      \n",
            "[22] \"package:datasets\"    \"package:methods\"     \"package:base\"       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression with LightGBM"
      ],
      "metadata": {
        "id": "QabVFLr5jgrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data and Data Preparation\n",
        "\n"
      ],
      "metadata": {
        "id": "rSJqB05rO5ES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CFpt_H01OPsa"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Load Boston Housing dataset\n",
        "data(\"Boston\", package = \"MASS\")\n",
        "\n",
        "# Create a data frame with selected variables\n",
        "df <- Boston %>%\n",
        "  dplyr::select(medv, crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat)\n",
        "\n",
        "# Convert to matrix for LightGBM\n",
        "m <- as.matrix(df)\n",
        "set.seed(123)\n",
        "\n",
        "# Sample 75% of the data for training\n",
        "indices <- sample(1:nrow(df), size = 0.75 * nrow(df))\n",
        "train <- m[indices, ]\n",
        "test <- m[-indices, ]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Load the train and test data into the LightGBM dataset object"
      ],
      "metadata": {
        "id": "UPiv_OTsmKB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Load train and test data into LightGBM dataset object\n",
        "y_train <- train[, 1]  # medv is the target\n",
        "y_test <- test[, 1]\n",
        "train_lgb <- lgb.Dataset(\n",
        "  data = train[, 2:ncol(train)],\n",
        "  label = y_train,\n",
        "  params = list(feature_pre_filter = FALSE)\n",
        ")\n",
        "test_lgb <- lgb.Dataset(\n",
        "  data = test[, 2:ncol(test)],\n",
        "  label = y_test,\n",
        "  params = list(feature_pre_filter = FALSE)\n",
        ")"
      ],
      "metadata": {
        "id": "nmHkqU4kmNWI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit lightGBM model\n",
        "\n",
        "Next, we'll fit the light model by using the `lgb.train()` function, which displays the training and testing RMSE (root mean squared error) for each round of boosting\n"
      ],
      "metadata": {
        "id": "k6EFndFdP5qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Define parameters\n",
        "params <- list(\n",
        "  objective = \"regression\",\n",
        "  metric = \"l2\",\n",
        "  min_data_in_leaf = 1L,  # Corrected parameter name\n",
        "  learning_rate = 0.05,\n",
        "  num_threads = 2L,\n",
        "  feature_pre_filter = FALSE  # Added to resolve error\n",
        ")\n",
        "\n",
        "# fit lightgbm model\n",
        "lightgbm_model <- lgb.train(\n",
        "  params = params,\n",
        "  data = train_lgb,\n",
        "  nrounds = 100L,\n",
        "  early_stopping_rounds = 3L,\n",
        "  valids = list(test = test_lgb),\n",
        "  verbose = 1  # Enable logging to monitor training\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7fPSLSxsZie",
        "outputId": "0c168db5-5746-4f6e-d278-7a123fae7a4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 982\n",
            "[LightGBM] [Info] Number of data points in the train set: 379, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 22.512137\n",
            "[1]:  test's l2:75.323 \n",
            "Will train until there is no improvement in 3 rounds.\n",
            "[2]:  test's l2:68.4973 \n",
            "[3]:  test's l2:62.2759 \n",
            "[4]:  test's l2:56.6915 \n",
            "[5]:  test's l2:51.9838 \n",
            "[6]:  test's l2:47.6355 \n",
            "[7]:  test's l2:43.6113 \n",
            "[8]:  test's l2:40.1444 \n",
            "[9]:  test's l2:37.0938 \n",
            "[10]:  test's l2:34.439 \n",
            "[11]:  test's l2:32.0923 \n",
            "[12]:  test's l2:29.9094 \n",
            "[13]:  test's l2:27.9457 \n",
            "[14]:  test's l2:26.3152 \n",
            "[15]:  test's l2:24.8207 \n",
            "[16]:  test's l2:23.6034 \n",
            "[17]:  test's l2:22.4458 \n",
            "[18]:  test's l2:21.3545 \n",
            "[19]:  test's l2:20.3519 \n",
            "[20]:  test's l2:19.4315 \n",
            "[21]:  test's l2:18.6232 \n",
            "[22]:  test's l2:17.9574 \n",
            "[23]:  test's l2:17.3045 \n",
            "[24]:  test's l2:16.7059 \n",
            "[25]:  test's l2:16.2784 \n",
            "[26]:  test's l2:15.836 \n",
            "[27]:  test's l2:15.4188 \n",
            "[28]:  test's l2:15.106 \n",
            "[29]:  test's l2:14.8036 \n",
            "[30]:  test's l2:14.639 \n",
            "[31]:  test's l2:14.4137 \n",
            "[32]:  test's l2:14.2139 \n",
            "[33]:  test's l2:13.9759 \n",
            "[34]:  test's l2:13.9491 \n",
            "[35]:  test's l2:13.8647 \n",
            "[36]:  test's l2:13.7507 \n",
            "[37]:  test's l2:13.6898 \n",
            "[38]:  test's l2:13.5789 \n",
            "[39]:  test's l2:13.4866 \n",
            "[40]:  test's l2:13.4644 \n",
            "[41]:  test's l2:13.4695 \n",
            "[42]:  test's l2:13.4167 \n",
            "[43]:  test's l2:13.3775 \n",
            "[44]:  test's l2:13.3721 \n",
            "[45]:  test's l2:13.3783 \n",
            "[46]:  test's l2:13.3826 \n",
            "[47]:  test's l2:13.3811 \n",
            "Early stopping, best iteration is: [44]:  test's l2:13.3721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "summary(lightgbm_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyjnaLHUP946",
        "outputId": "f89e17bf-90f0-46d9-97c5-51731eefab5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Model (47 trees)\n",
            "Objective: regression\n",
            "Fitted to dataset with 13 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict and Evaluate Initial Model"
      ],
      "metadata": {
        "id": "ioqlVpARP_pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Prediction and Evaluation\n",
        "yhat_fit_train <- predict(lightgbm_model, train[, 2:ncol(train)])\n",
        "yhat_predict_test <- predict(lightgbm_model, test[, 2:ncol(test)])\n",
        "\n",
        "# Define RMSE function\n",
        "RMSE <- function(actual, predicted) {\n",
        "  sqrt(mean((actual - predicted)^2))\n",
        "}\n",
        "\n",
        "rmse_train <- RMSE(y_train, yhat_fit_train)\n",
        "rmse_test <- RMSE(y_test, yhat_predict_test)\n",
        "cat(\"Training RMSE:\", rmse_train, \"\\n\")\n",
        "cat(\"Test RMSE:\", rmse_test, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwTfSah-QYwz",
        "outputId": "09c15ea3-4734-4b86-e6f6-96e3767a889f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RMSE: 1.440585 \n",
            "Test RMSE: 3.656782 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter Tuning for the Best Parameters\n",
        "\n",
        "To find the best parameters for the LightGBM model using cross-validation (CV) and grid search, I'll implement a grid search over key hyperparameters (`num_leaves`, `learning_rate`, `max_depth`, m`in_data_in_leaf`) with 5-fold cross-validation to optimize the RMSE metric.\n"
      ],
      "metadata": {
        "id": "GqOYNF6YnQMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define Parameter Grid and Initialize Variables"
      ],
      "metadata": {
        "id": "PpIEnQNDoWLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Define parameter grid for grid search\n",
        "param_grid <- expand.grid(\n",
        "  num_leaves = c(20, 31, 50),\n",
        "  learning_rate = c(0.01, 0.05, 0.1),\n",
        "  max_depth = c(5, 7, -1),  # -1 means no limit\n",
        "  min_data_in_leaf = c(10, 20)\n",
        ")\n",
        "\n",
        "# Initialize variables to store best parameters and RMSE\n",
        "best_rmse <- Inf\n",
        "best_params <- NULL\n",
        "results <- data.frame()\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "for (i in 1:nrow(param_grid)) {\n",
        "  params <- list(\n",
        "    objective = \"regression\",\n",
        "    metric = \"l2\",\n",
        "    num_leaves = param_grid$num_leaves[i],\n",
        "    learning_rate = param_grid$learning_rate[i],\n",
        "    max_depth = param_grid$max_depth[i],\n",
        "    min_data_in_leaf = param_grid$min_data_in_leaf[i],\n",
        "    num_threads = 2L,\n",
        "    num_iterations = 1000,\n",
        "    early_stopping_rounds = 50\n",
        "  )\n",
        "\n",
        "  # Perform 5-fold cross-validation\n",
        "  cv_results <- lgb.cv(\n",
        "    params = params,\n",
        "    data = train_lgb,\n",
        "    nfold = 5,\n",
        "    stratified = FALSE,\n",
        "    verbose = -1\n",
        "  )\n",
        "\n",
        "  # Extract the best RMSE from cross-validation\n",
        "  cv_rmse <- sqrt(cv_results$best_score)  # Best L2 score is MSE, so take sqrt for RMSE\n",
        "\n",
        "  # Store results\n",
        "  results <- rbind(results, data.frame(\n",
        "    num_leaves = params$num_leaves,\n",
        "    learning_rate = params$learning_rate,\n",
        "    max_depth = params$max_depth,\n",
        "    min_data_in_leaf = params$min_data_in_leaf,\n",
        "    cv_rmse = cv_rmse\n",
        "  ))\n",
        "\n",
        "  # Update best parameters if current RMSE is better\n",
        "  if (cv_rmse < best_rmse) {\n",
        "    best_rmse <- cv_rmse\n",
        "    best_params <- params\n",
        "  }\n",
        "\n",
        "  cat(\"Grid search iteration\", i, \"of\", nrow(param_grid), \"CV RMSE:\", cv_rmse, \"\\n\")\n",
        "}"
      ],
      "metadata": {
        "id": "RjnlDmSzoWzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The best parameters"
      ],
      "metadata": {
        "id": "EuPB-9Tnot5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Output results\n",
        "cat(\"\\nBest Parameters:\\n\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYbWhgako6J4",
        "outputId": "9971b798-cf73-4006-8088-bf91cd3aee7c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters:\n",
            "$objective\n",
            "[1] \"regression\"\n",
            "\n",
            "$metric\n",
            "[1] \"l2\"\n",
            "\n",
            "$num_leaves\n",
            "[1] 20\n",
            "\n",
            "$learning_rate\n",
            "[1] 0.1\n",
            "\n",
            "$max_depth\n",
            "[1] 5\n",
            "\n",
            "$min_data_in_leaf\n",
            "[1] 10\n",
            "\n",
            "$num_threads\n",
            "[1] 2\n",
            "\n",
            "$num_iterations\n",
            "[1] 1000\n",
            "\n",
            "$early_stopping_rounds\n",
            "[1] 50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train and Validate Model with Best Parameters"
      ],
      "metadata": {
        "id": "qlo7UGqjpMJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Train final model with best parameters\n",
        "final_model <- lgb.train(\n",
        "  params = best_params,\n",
        "  data = train_lgb,\n",
        "  valids = list(test = test_lgb),\n",
        "  verbose = -1\n",
        ")"
      ],
      "metadata": {
        "id": "MWa_RuR3pMhJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Predictions and Evaluation"
      ],
      "metadata": {
        "id": "Q99NFqvipTF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Predictions and evaluation\n",
        "train_pred <- predict(final_model, train[, 2:ncol(train)])\n",
        "test_pred <- predict(final_model, test[, 2:ncol(test)])\n",
        "\n",
        "rmse_train_final <- RMSE(y_train, train_pred)\n",
        "rmse_test_final <- RMSE(y_test, test_pred)\n",
        "\n",
        "cat(\"\\nFinal Model Performance:\\n\")\n",
        "cat(\"Training RMSE:\", rmse_train_final, \"\\n\")\n",
        "cat(\"Test RMSE:\", rmse_test_final, \"\\n\")\n",
        "\n",
        "# Save grid search results\n",
        "# write.csv(results, \"grid_search_results.csv\", row.names = FALSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDzGkXFPpaFR",
        "outputId": "525a5f27-1787-4520-a2c8-cf848aefa44a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Model Performance:\n",
            "Training RMSE: 0.6145919 \n",
            "Test RMSE: 3.612103 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "formula<-y~x\n",
        "\n",
        "# 1:1 Plot of Predicted vs Observed values\n",
        "test_df <- data.frame(medv = y_test, medv_pred = test_pred)\n",
        "\n",
        "ggplot(test_df, aes(x = medv, y = medv_pred)) +\n",
        "  geom_point() +\n",
        "  geom_smooth(method = \"lm\") +\n",
        "  stat_poly_eq(use_label(c(\"eq\", \"adj.R2\")), formula = y ~ x) +\n",
        "  ggtitle(\"LightGBM: Predicted vs Observed House Prices\") +\n",
        "  xlab(\"Observed medv ($1,000s)\") +\n",
        "  ylab(\"Predicted medv ($1,000s)\") +\n",
        "  scale_x_continuous(limits = c(0, 55), breaks = seq(0, 55, 10)) +\n",
        "  scale_y_continuous(limits = c(0, 55), breaks = seq(0, 55, 10)) +\n",
        "  theme(\n",
        "    panel.background = element_rect(fill = \"grey95\", colour = \"gray75\", size = 0.5, linetype = \"solid\"),\n",
        "    axis.line = element_line(colour = \"grey\"),\n",
        "    plot.title = element_text(size = 14, hjust = 0.5),\n",
        "    axis.title.x = element_text(size = 14),\n",
        "    axis.title.y = element_text(size = 14),\n",
        "    axis.text.x = element_text(size = 13, colour = \"black\"),\n",
        "    axis.text.y = element_text(size = 13, angle = 90, vjust = 0.5, hjust = 0.5, colour = \"black\")\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "Ic0gVXQEzDOd",
        "outputId": "2698a8ba-372f-4bb0-d4f8-a830d1be8d23"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`geom_smooth()` using formula = 'y ~ x'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature Importance"
      ],
      "metadata": {
        "id": "5AKztLwDzNj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Compute and plot variable importance\n",
        "importance <- lgb.importance(final_model)\n",
        "feature_names <- colnames(df)[2:ncol(df)]  # All features after medv\n",
        "\n",
        "# Plot variable importance using ggplot2\n",
        "p <- ggplot(importance, aes(x = reorder(Feature, Gain), y = Gain)) +\n",
        "  geom_bar(stat = \"identity\", fill = \"#1f77b4\") +\n",
        "  coord_flip() +\n",
        "  labs(title = \"LightGBM Feature Importance (Gain)\", x = \"Feature\", y = \"Gain\") +\n",
        "  theme_minimal() +\n",
        "  theme(plot.title = element_text(hjust = 0.5))\n",
        "\n",
        "# Display the plot\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "IOT-EVsOzOZP",
        "outputId": "2e235920-c1c2-4f35-8419-1d48531bb98e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification with LightGBM\n",
        "\n",
        "In this section, we will use the {lightGBM} package to perform classification on a dataset. We will load the dataset, preprocess it, and then fit an lightgbm model for classification. The dataset will be split into training and testing sets, and we will evaluate the model's performance using accuracy and confusion matrix."
      ],
      "metadata": {
        "id": "Irqlj8sYYKas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data and Data Preparation\n",
        "\n",
        "We will use`health insurance` dataset to predict the product type (A, B, or C) based on various features such as age, household size, position level, and absence records."
      ],
      "metadata": {
        "id": "NRpPJB6-YUUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Load the dataset\n",
        "df <-readr::read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/Machine_Learning/health_insurance.csv\")\n",
        "# Create subset with specified variables\n",
        "df <- data.frame(\n",
        "  product = df$product,\n",
        "  age = df$age,\n",
        "  household = df$household,\n",
        "  position_level = df$position_level,\n",
        "  absent = df$absent,\n",
        "  gender = factor(df$gender)\n",
        ")\n",
        "\n",
        "# Create dummy variable for gender\n",
        "tmp <- df[, \"gender\", drop = FALSE]\n",
        "tmp1 <- dummy_cols(tmp)\n",
        "tmp1 <- tmp1[, 3:ncol(tmp1)]\n",
        "\n",
        "# Combine features with dummy variable\n",
        "d <- data.frame(df[, c(\"product\", \"age\", \"household\", \"position_level\", \"absent\")], tmp1)\n",
        "m <- as.matrix(d)\n",
        "\n",
        "# Encode target variable (product: A=0, B=1, C=2)\n",
        "d$product <- as.numeric(factor(d$product)) - 1\n",
        "\n",
        "# Create training and test datasets\n",
        "set.seed(123)\n",
        "indices <- sample(1:nrow(df), size = 0.75 * nrow(df))\n",
        "train <- m[indices, ]\n",
        "test <- m[-indices, ]\n",
        "\n",
        "# Load train and test data into LightGBM dataset objects\n",
        "y_train <- d$product[indices]\n",
        "y_test <- d$product[-indices]\n",
        "train_lgb <- lgb.Dataset(\n",
        "  data = train[, 2:ncol(train)],\n",
        "  label = y_train,\n",
        "  params = list(feature_pre_filter = FALSE)\n",
        ")\n",
        "test_lgb <- lgb.Dataset(\n",
        "  data = test[, 2:ncol(test)],\n",
        "  label = y_test,\n",
        "  params = list(feature_pre_filter = FALSE)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfumDV8yYaI2",
        "outputId": "979ff3e7-09fb-49b3-c673-1ac7e9f65756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 1448 Columns: 6\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr (2): product, gender\n",
            "dbl (4): age, household, position_level, absent\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit lightGBM Classification Model"
      ],
      "metadata": {
        "id": "5yliW4QeZMpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Fit initial model with fixed parameters\n",
        "initial_params <- list(\n",
        "  objective = \"multiclass\",\n",
        "  metric = \"multi_logloss\",\n",
        "  num_class = 3,\n",
        "  num_leaves = 31,\n",
        "  learning_rate = 0.05,\n",
        "  max_depth = 5,\n",
        "  min_data_in_leaf = 10,\n",
        "  num_threads = 2L\n",
        ")\n",
        "\n",
        "initial_model <- lgb.train(\n",
        "  params = initial_params,\n",
        "  data = train_lgb,\n",
        "  valids = list(test = test_lgb),\n",
        "  #num_iterations = 1000,\n",
        "  early_stopping_rounds = 50,\n",
        "  verbose = -1\n",
        ")\n",
        "summary(initial_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H3OVcIrZNK8",
        "outputId": "2ac00726-9db2-4ff9-eb36-e210c9b47bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Model (100 trees)\n",
            "Objective: multiclass (3 classes)\n",
            "Fitted to dataset with 5 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predictions and Evaluation\n",
        "\n",
        "For model evalution we will use `accuracy` and `multi-class log loss` as metrics. The accuracy is the proportion of correct predictions, while the multi-class log loss measures the performance of a classification model whose output is a probability value between 0 and 1 for each class.\n",
        "\n",
        "The `multi-class log loss` (also called cross-entropy loss) can be computed manually in R using the formula:\n",
        "\n",
        "$$ \\text{multi_logloss} = -\\frac{1}{N} \\sum_{i=1}^N \\sum_{k=1}^K y_{ik} \\log(\\hat{p}_{ik}) $$\n",
        "\n",
        "where:\n",
        "\n",
        "-   $N$: Number of observations.\n",
        "\n",
        "-   $K$: Number of classes (3 for `product`: A, B, C).\n",
        "\n",
        "-   $y_{ik}$: 1 if observation $i$ belongs to class $k$, 0 otherwise.\n",
        "\n",
        "-   $\\hat{p}_{ik}$: Predicted probability for observation $i$ and class $k$.\n",
        "\n",
        "The LightGBM model outputs predicted probabilities for each class (via `predict(..., reshape = TRUE)`), and the true labels are encoded as 0 (A), 1 (B), and 2 (C). We’ll create a custom `multi_logloss` function to compute this metric and update the script accordingly."
      ],
      "metadata": {
        "id": "Gp7pWvYaZS7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Custom multi-class log loss function\n",
        "multi_logloss <- function(y_true, y_pred) {\n",
        "  # Ensure y_true is integer (0, 1, 2 for A, B, C)\n",
        "  y_true <- as.integer(y_true)\n",
        "  # Number of observations\n",
        "  N <- length(y_true)\n",
        "  # Number of classes\n",
        "  K <- ncol(y_pred)\n",
        "  # Initialize log loss\n",
        "  logloss <- 0\n",
        "  # Small epsilon to avoid log(0)\n",
        "  eps <- 1e-15\n",
        "  # Compute log loss\n",
        "  for (i in 1:N) {\n",
        "    # True class index (1-based in R)\n",
        "    true_class <- y_true[i] + 1\n",
        "    # Predicted probability for true class, clipped to avoid log(0)\n",
        "    p <- pmax(pmin(y_pred[i, true_class], 1 - eps), eps)\n",
        "    logloss <- logloss - log(p)\n",
        "  }\n",
        "  # Average log loss\n",
        "  return(logloss / N)\n",
        "}"
      ],
      "metadata": {
        "id": "05n7c6Pt0Sqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Predictions and evaluation for initial model\n",
        "yhat_train <- predict(initial_model, train[, 2:ncol(train)])\n",
        "yhat_test <- predict(initial_model, test[, 2:ncol(test)])\n",
        "yhat_train_pred <- apply(yhat_train, 1, which.max) - 1\n",
        "yhat_test_pred <- apply(yhat_test, 1, which.max) - 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_train_initial <- mean(yhat_train_pred == y_train)\n",
        "accuracy_test_initial <- mean(yhat_test_pred == y_test)\n",
        "logloss_train_initial <- multi_logloss(y_train, yhat_train)\n",
        "logloss_test_initial <- multi_logloss(y_test, yhat_test)\n",
        "\n",
        "# Output results\n",
        "cat(\"\\nInitial Model Performance:\\n\")\n",
        "cat(\"Training Accuracy:\", accuracy_train_initial, \"\\n\")\n",
        "cat(\"Test Accuracy:\", accuracy_test_initial, \"\\n\")\n",
        "cat(\"Training Log Loss:\", logloss_train_initial, \"\\n\")\n",
        "cat(\"Test Log Loss:\", logloss_test_initial, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3Kv94NoZTyA",
        "outputId": "f02ace57-9ec7-49a3-c926-21e64697dddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Model Performance:\n",
            "Training Accuracy: 0.8839779 \n",
            "Test Accuracy: 0.7955801 \n",
            "Training Log Loss: 0.2651326 \n",
            "Test Log Loss: 0.4041625 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Importance\n",
        "\n"
      ],
      "metadata": {
        "id": "a-JpJLkCZbAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Feature importance for initial model\n",
        "importance_initial <- lgb.importance(initial_model)\n",
        "# Plot feature importance for initial model\n",
        "p_initial <- ggplot(importance_initial, aes(x = reorder(Feature, Gain), y = Gain)) +\n",
        "  geom_bar(stat = \"identity\", fill = \"#1f77b4\") +\n",
        "  coord_flip() +\n",
        "  labs(title = \"Initial LightGBM Feature Importance (Gain)\", x = \"Feature\", y = \"Gain\") +\n",
        "  theme_minimal() +\n",
        "  theme(plot.title = element_text(hjust = 0.5))\n",
        "print(p_initial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "lWflJ_FPZoso",
        "outputId": "241b4a92-9358-4112-f5e5-bf1f8fec1782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter Tuning for the Best Parameters\n",
        "\n",
        "To find the best parameters for the LightGBM classification model, we will perform a grid search over key hyperparameters (`num_leaves`, `learning_rate`, `max_depth`, `min_data_in_leaf`) using 5-fold cross-validation. This will help us optimize the multi-class log loss metric."
      ],
      "metadata": {
        "id": "A0Z8ixpisWlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define Parameter Grid and Initialize Variables"
      ],
      "metadata": {
        "id": "F2QUmf8mfUkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Define parameter grid for grid search\n",
        "param_grid <- expand.grid(\n",
        "  num_leaves = c(20, 31, 50),\n",
        "  learning_rate = c(0.01, 0.05, 0.1),\n",
        "  max_depth = c(3, 5, 7),\n",
        "  min_data_in_leaf = c(10, 20)\n",
        ")\n",
        "\n",
        "# Initialize variables to store best parameters and log loss\n",
        "best_logloss <- Inf\n",
        "best_params <- NULL\n",
        "results <- data.frame()\n",
        "\n",
        "# Perform grid search with 5-fold cross-validation\n",
        "for (i in 1:nrow(param_grid)) {\n",
        "  params <- list(\n",
        "    objective = \"multiclass\",\n",
        "    metric = \"multi_logloss\",\n",
        "    num_class = 3,\n",
        "    num_leaves = param_grid$num_leaves[i],\n",
        "    learning_rate = param_grid$learning_rate[i],\n",
        "    max_depth = param_grid$max_depth[i],\n",
        "    min_data_in_leaf = param_grid$min_data_in_leaf[i],\n",
        "    num_threads = 2L,\n",
        "    num_iterations = 1000,\n",
        "    early_stopping_rounds = 50\n",
        "  )\n",
        "\n",
        "  # Perform 5-fold cross-validation\n",
        "  cv_results <- lgb.cv(\n",
        "    params = params,\n",
        "    data = train_lgb,\n",
        "    nfold = 5,\n",
        "    stratified = TRUE,\n",
        "    verbose = -1\n",
        "  )\n",
        "\n",
        "  # Extract the best log loss from cross-validation\n",
        "  cv_logloss <- cv_results$best_score\n",
        "\n",
        "  # Store results\n",
        "  results <- rbind(results, data.frame(\n",
        "    num_leaves = params$num_leaves,\n",
        "    learning_rate = params$learning_rate,\n",
        "    max_depth = params$max_depth,\n",
        "    min_data_in_leaf = params$min_data_in_leaf,\n",
        "    cv_logloss = cv_logloss\n",
        "  ))\n",
        "\n",
        "  # Update best parameters if current log loss is better\n",
        "  if (cv_logloss < best_logloss) {\n",
        "    best_logloss <- cv_logloss\n",
        "    best_params <- params\n",
        "  }\n",
        "\n",
        "  cat(\"Grid search iteration\", i, \"of\", nrow(param_grid), \"CV Log Loss:\", cv_logloss, \"\\n\")\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW5ihdntsYep",
        "outputId": "d54c3318-4c72-4bc4-9d30-a844443f78a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search iteration 1 of 54 CV Log Loss: 0.374136 \n",
            "Grid search iteration 2 of 54 CV Log Loss: 0.3666565 \n",
            "Grid search iteration 3 of 54 CV Log Loss: 0.3714118 \n",
            "Grid search iteration 4 of 54 CV Log Loss: 0.3795039 \n",
            "Grid search iteration 5 of 54 CV Log Loss: 0.3748363 \n",
            "Grid search iteration 6 of 54 CV Log Loss: 0.371635 \n",
            "Grid search iteration 7 of 54 CV Log Loss: 0.3723882 \n",
            "Grid search iteration 8 of 54 CV Log Loss: 0.3798412 \n",
            "Grid search iteration 9 of 54 CV Log Loss: 0.3688146 \n",
            "Grid search iteration 10 of 54 CV Log Loss: 0.3974246 \n",
            "Grid search iteration 11 of 54 CV Log Loss: 0.3890119 \n",
            "Grid search iteration 12 of 54 CV Log Loss: 0.391992 \n",
            "Grid search iteration 13 of 54 CV Log Loss: 0.3994136 \n",
            "Grid search iteration 14 of 54 CV Log Loss: 0.3850187 \n",
            "Grid search iteration 15 of 54 CV Log Loss: 0.3870488 \n",
            "Grid search iteration 16 of 54 CV Log Loss: 0.3847712 \n",
            "Grid search iteration 17 of 54 CV Log Loss: 0.3927315 \n",
            "Grid search iteration 18 of 54 CV Log Loss: 0.3763153 \n",
            "Grid search iteration 19 of 54 CV Log Loss: 0.4066931 \n",
            "Grid search iteration 20 of 54 CV Log Loss: 0.4281316 \n",
            "Grid search iteration 21 of 54 CV Log Loss: 0.4140596 \n",
            "Grid search iteration 22 of 54 CV Log Loss: 0.4198345 \n",
            "Grid search iteration 23 of 54 CV Log Loss: 0.4177254 \n",
            "Grid search iteration 24 of 54 CV Log Loss: 0.4264146 \n",
            "Grid search iteration 25 of 54 CV Log Loss: 0.4108482 \n",
            "Grid search iteration 26 of 54 CV Log Loss: 0.4081839 \n",
            "Grid search iteration 27 of 54 CV Log Loss: 0.4094724 \n",
            "Grid search iteration 28 of 54 CV Log Loss: 0.3808216 \n",
            "Grid search iteration 29 of 54 CV Log Loss: 0.3764276 \n",
            "Grid search iteration 30 of 54 CV Log Loss: 0.3704922 \n",
            "Grid search iteration 31 of 54 CV Log Loss: 0.3719642 \n",
            "Grid search iteration 32 of 54 CV Log Loss: 0.3761661 \n",
            "Grid search iteration 33 of 54 CV Log Loss: 0.3747215 \n",
            "Grid search iteration 34 of 54 CV Log Loss: 0.3696643 \n",
            "Grid search iteration 35 of 54 CV Log Loss: 0.3760683 \n",
            "Grid search iteration 36 of 54 CV Log Loss: 0.3744893 \n",
            "Grid search iteration 37 of 54 CV Log Loss: 0.3894741 \n",
            "Grid search iteration 38 of 54 CV Log Loss: 0.3873163 \n",
            "Grid search iteration 39 of 54 CV Log Loss: 0.3891571 \n",
            "Grid search iteration 40 of 54 CV Log Loss: 0.3898282 \n",
            "Grid search iteration 41 of 54 CV Log Loss: 0.3998313 \n",
            "Grid search iteration 42 of 54 CV Log Loss: 0.389442 \n",
            "Grid search iteration 43 of 54 CV Log Loss: 0.3965225 \n",
            "Grid search iteration 44 of 54 CV Log Loss: 0.3825495 \n",
            "Grid search iteration 45 of 54 CV Log Loss: 0.3844751 \n",
            "Grid search iteration 46 of 54 CV Log Loss: 0.4090439 \n",
            "Grid search iteration 47 of 54 CV Log Loss: 0.4024553 \n",
            "Grid search iteration 48 of 54 CV Log Loss: 0.3996154 \n",
            "Grid search iteration 49 of 54 CV Log Loss: 0.3999813 \n",
            "Grid search iteration 50 of 54 CV Log Loss: 0.3988765 \n",
            "Grid search iteration 51 of 54 CV Log Loss: 0.4059982 \n",
            "Grid search iteration 52 of 54 CV Log Loss: 0.3953501 \n",
            "Grid search iteration 53 of 54 CV Log Loss: 0.4066083 \n",
            "Grid search iteration 54 of 54 CV Log Loss: 0.3905566 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The Best Parameters"
      ],
      "metadata": {
        "id": "0SlcKgW5fgwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "cat(\"\\nBest Parameters from Grid Search:\\n\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeHbzkR_tbp0",
        "outputId": "4136fbba-1daa-4904-d612-d986691586f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters from Grid Search:\n",
            "$objective\n",
            "[1] \"multiclass\"\n",
            "\n",
            "$metric\n",
            "[1] \"multi_logloss\"\n",
            "\n",
            "$num_class\n",
            "[1] 3\n",
            "\n",
            "$num_leaves\n",
            "[1] 31\n",
            "\n",
            "$learning_rate\n",
            "[1] 0.01\n",
            "\n",
            "$max_depth\n",
            "[1] 3\n",
            "\n",
            "$min_data_in_leaf\n",
            "[1] 10\n",
            "\n",
            "$num_threads\n",
            "[1] 2\n",
            "\n",
            "$num_iterations\n",
            "[1] 1000\n",
            "\n",
            "$early_stopping_rounds\n",
            "[1] 50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train and Validate Model with Best Parameters"
      ],
      "metadata": {
        "id": "dd8rbCCouCwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Train final model with best parameters\n",
        "final_model <- lgb.train(\n",
        "  params = best_params,\n",
        "  data = train_lgb,\n",
        "  valids = list(test = test_lgb),\n",
        "  verbose = -1\n",
        ")\n",
        "summary(final_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPm6NZeguFOT",
        "outputId": "65c21d88-0a2e-4668-fc30-62a7060eec8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Model (731 trees)\n",
            "Objective: multiclass (3 classes)\n",
            "Fitted to dataset with 5 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Predictions and Evaluation for Final Model"
      ],
      "metadata": {
        "id": "9cvH3K9ot8Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Predictions and evaluation for final model\n",
        "yhat_train_final <- predict(final_model, train[, 2:ncol(train)])\n",
        "yhat_test_final <- predict(final_model, test[, 2:ncol(test)])\n",
        "yhat_train_final_pred <- apply(yhat_train_final, 1, which.max) - 1\n",
        "yhat_test_final_pred <- apply(yhat_test_final, 1, which.max) - 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_train_final <- mean(yhat_train_final_pred == y_train)\n",
        "accuracy_test_final <- mean(yhat_test_final_pred == y_test)\n",
        "logloss_train_final <- multi_logloss(y_train, yhat_train_final)\n",
        "logloss_test_final <- multi_logloss(y_test, yhat_test_final)\n",
        "\n",
        "cat(\"Training Accuracy:\", accuracy_train_final, \"\\n\")\n",
        "cat(\"Test Accuracy:\", accuracy_test_final, \"\\n\")\n",
        "cat(\"Training Log Loss:\", logloss_train_final, \"\\n\")\n",
        "cat(\"Test Log Loss:\", logloss_test_final, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qNY29UBuKo7",
        "outputId": "b3b8537e-7303-4d6b-b02f-ef0e64a66ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.8406998 \n",
            "Test Accuracy: 0.7983425 \n",
            "Training Log Loss: 0.3167224 \n",
            "Test Log Loss: 0.3905005 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Variable Importance for Final Model"
      ],
      "metadata": {
        "id": "KvmMMBPHsSrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Feature importance for final model\n",
        "importance_final <- lgb.importance(final_model)\n",
        "# Plot feature importance for final model\n",
        "p_final <- ggplot(importance_final, aes(x = reorder(Feature, Gain), y = Gain)) +\n",
        "  geom_bar(stat = \"identity\", fill = \"#1f77b4\") +\n",
        "  coord_flip() +\n",
        "  labs(title = \"Final LightGBM Feature Importance (Gain)\", x = \"Feature\", y = \"Gain\") +\n",
        "  theme_minimal() +\n",
        "  theme(plot.title = element_text(hjust = 0.5))\n",
        "print(p_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "dN6PFWRCuRpS",
        "outputId": "0899b6dc-a455-44bc-b886-8d5f304de5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary and Conclusion\n",
        "\n",
        "LightGBM is a gradient boosting framework optimized for speed, scalability, and efficiency, using techniques like GOSS, EFB, histogram-based learning, and leaf-wise tree growth. It minimizes the same objective function as other boosting algorithms but approximates gradients and feature splits more efficiently. Compared to XGBoost, LightGBM is faster and more memory-efficient, especially for large datasets, but it may require more careful tuning to avoid overfitting due to its leaf-wise approach. Both are powerful, but LightGBM excels in scenarios with large, high-dimensional data, while XGBoost may be preferred for smaller datasets or when robustness is critical. This exercise demonstrated how to implement LightGBM for regression and classification tasks in R, including data preparation, model training, evaluation, and hyperparameter tuning using grid search and cross-validation. The results showed that LightGBM can achieve competitive performance with efficient training and prediction times."
      ],
      "metadata": {
        "id": "Nb0kdVIuGlK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1.  **Kuhn, M., & Johnson, K. (2019). *Feature Engineering and Selection*. CRC Press.**\n",
        "    -   Covers gradient boosting and LightGBM applications in R.\n",
        "    -   [Amazon](https://www.amazon.com/Feature-Engineering-Selection-Practical-Predictive/dp/1138079227)\n",
        "2.  **Hastie, T., et al. (2009). *The Elements of Statistical Learning* (2nd ed.). Springer.**\n",
        "    -   Explains boosting theory behind LightGBM.\n",
        "    -   [Free PDF](https://web.stanford.edu/~hastie/ElemStatLearn/)\n",
        "3.  **Boehmke, B., & Greenwell, B. (2019). *Hands-On Machine Learning with R*. CRC Press.**\n",
        "    -   Practical LightGBM tutorials in R.\n",
        "    -   [CRC Press](https://www.crcpress.com/Hands-On-Machine-Learning-with-R/Boehmke-Greenwell/p/book/9781138495685)\n",
        "\n",
        "### Journal Articles\n",
        "\n",
        "1.  **Ke, G., et al. (2017). LightGBM: A Highly Efficient Gradient Boosting Decision Tree. *NeurIPS*.**\n",
        "    -   Introduces LightGBM’s algorithms (GOSS, EFB).\n",
        "    -   [arXiv](https://arxiv.org/abs/1711.04289)\n",
        "2.  **Friedman, J. H. (2001). Greedy Function Approximation: A Gradient Boosting Machine. *Annals of Statistics*.**\n",
        "    -   Foundational gradient boosting theory.\n",
        "    -   [Stanford](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)\n",
        "3.  **Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. *KDD*.**\n",
        "    -   Context for LightGBM’s improvements over XGBoost.\n",
        "    -   [arXiv](https://arxiv.org/abs/1603.02754)\n",
        "\n",
        "### Online R Tutorials\n",
        "\n",
        "1.  **DataCamp: LightGBM in R**\n",
        "    -   Beginner guide to LightGBM with R code for classification/regression.\n",
        "    -   [DataCamp](https://www.datacamp.com/community/tutorials/lightgbm-in-r)\n",
        "2.  **R-bloggers: Gradient Boosting with LightGBM**\n",
        "    -   Practical tutorial on binary classification and feature importance.\n",
        "    -   [R-bloggers](https://www.r-bloggers.com/2021/03/gradient-boosting-with-lightgbm-in-r/)\n",
        "3.  **Towards Data Science: LightGBM for Multi-Class Classification**\n",
        "    -   Advanced R tutorial with grid search and evaluation.\n",
        "    -   [Towards Data Science](https://towardsdatascience.com/lightgbm-in-r-2c6b5f96b3f1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ACNQyq1seLc7"
      }
    }
  ]
}