{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONT6pkXc+BB5nc6YkOLEb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/Machine_Learning/Tree_based/03-01-02-05-tree-based-models-bagging-quantile-regression-forest-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ],
      "metadata": {
        "id": "zYZbTX0qQrZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5 Quantile Regression Forest (QRF)\n",
        "\n",
        "Quantile Regression Forests (QRF) is a machine learning method that extends Random Forests to predict conditional quantiles of a response variable, rather than just the mean. It’s particularly useful for modeling the uncertainty and heterogeneity in data by estimating the full conditional distribution of the response variable, allowing you to predict specific quantiles (e.g., median, 90th percentile) instead of a single point estimate. This makes QRF valuable in applications like forecasting, risk analysis, and decision-making under uncertainty."
      ],
      "metadata": {
        "id": "RGBfrL2GQoII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "Quantile Regression Forests, introduced by Meinshausen (2006), combine the principles of Random Forests (ensemble of decision trees) with quantile regression. While a standard Random Forest predicts the conditional mean of the response variable given predictors, QRF estimates the conditional quantiles (e.g., 10th, 50th, or 90th percentiles). This is achieved by maintaining the full set of observed response values in the leaf nodes of the trees and using them to approximate the conditional distribution.\n",
        "\n",
        "QRF is particularly effective for:\n",
        "\n",
        "- Modeling non-linear relationships.\n",
        "- Capturing heteroscedasticity (varying variance in the response variable).\n",
        "- Providing prediction intervals and uncertainty quantification.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S77MsgmqIYD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Features of Quantile Regression Forests\n",
        "\n",
        "1. **Non-parametric Approach**: QRF does not assume a specific distribution for the response variable, making it robust to non-Gaussian data and outliers.\n",
        "2. **Quantile Estimation**: It can estimate any quantile (e.g., τ = 0.1 for the 10th percentile, τ = 0.5 for the median) of the conditional distribution.\n",
        "3. **Uncertainty Quantification**: QRF provides prediction intervals (e.g., 10th to 90th percentile) to quantify uncertainty.\n",
        "4. **Handles High-Dimensional Data**: Like Random Forests, QRF can handle many predictors and complex interactions between them.\n",
        "5. **Robustness**: Inherits the robustness of Random Forests to noise and irrelevant features.\n",
        "6. **Flexibility**: Works well for both regression and classification problems, though it’s primarily used for regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "VwEoykvwI2dS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How Quantile Regression Forests Work\n",
        "\n",
        "QRF builds on the Random Forest algorithm but modifies how predictions are made. Instead of averaging the response values in a leaf node to predict the mean, QRF retains all response values in the leaf nodes and uses them to estimate the conditional cumulative distribution function (CDF) for a given input. Quantiles are then derived from this estimated CDF.\n",
        "\n",
        "Here’s a step-by-step explanation of how QRF works, including the relevant equations:\n",
        "\n",
        "1. Data Preparation\n",
        "\n",
        "- A dataset with predictors $X = \\{x_1, x_2, \\dots, x_n\\}$ (where each $x_i$ in $\\mathbb{R}^p$) and response variable $Y = \\{y_1, y_2, \\dots, y_n\\}$.\n",
        "- For a new input $x$, estimate the conditional quantiles $Q_Y(\\tau | x)$, where $\\tau \\in (0, 1)$ is the desired quantile (e.g., $\\tau = 0.5$ for the median).\n",
        "\n",
        "The conditional quantile $Q_Y(\\tau | x)$ is defined as:\n",
        "\n",
        "$$ Q_Y(\\tau | x) = \\inf \\{ y : P(Y \\leq y | X = x) \\geq \\tau \\} $$\n",
        "\n",
        "This represents the value $y$ such that the probability of $Y \\leq y$ given $X = x$ is at least $\\tau$.\n",
        "\n",
        "2. Build a Random Forest\n",
        "\n",
        "QRF constructs an ensemble of decision trees using the Random Forest algorithm:\n",
        "\n",
        "- `Bootstrap Sampling`: For each tree $t = 1, 2, \\dots, T$, sample a random subset of the data (with replacement) to create a bootstrap sample.\n",
        "\n",
        "- `Feature Subsampling`: At each node of a tree, randomly select a subset of features (e.g., $m < p$) to consider for splitting.\n",
        "\n",
        "- `Splitting Criterion`: Use a criterion (e.g., variance reduction) to split nodes, as in standard Random Forests. The split at node $h$ minimizes:\n",
        "\n",
        "$$ \\text{Impurity} = \\sum_{i \\in \\text{left child}} (y_i - \\bar{y}_{\\text{left}})^2 + \\sum_{i \\in \\text{right child}} (y_i - \\bar{y}_{\\text{right}})^2 $$\n",
        "\n",
        "where $\\bar{y}_{\\text{left}}$ and $\\bar{y}_{\\text{right}}$ are the means of the response values in the left and right child nodes, respectively.\n",
        "\n",
        "- Each tree grows until a stopping criterion is met (e.g., minimum node size or maximum depth).\n",
        "\n",
        "- Unlike standard Random Forests, QRF stores all response values $y_i$ for the training samples that fall into each leaf node, not just their mean.\n",
        "\n",
        "3. Assign Weights to Observations\n",
        "\n",
        "For a new input $x$, QRF computes the weight of each training observation $y_i$ based on its proximity to $x$ in the forest:\n",
        "\n",
        "- For each tree $t$, identify the leaf node  $L_t(x)$ that $x$ falls into.\n",
        "\n",
        "- Assign a weight $w_i(x)$ to each training observation $y_i$ based on whether it falls into the same leaf as \\( x \\) across all trees:\n",
        "\n",
        "$$ w_i(x) = \\frac{1}{T} \\sum_{t=1}^T \\mathbb{I}\\{ (x_i, y_i) \\in L_t(x) \\} $$\n",
        "\n",
        "where $\\mathbb{I}\\{ \\cdot \\}$ is the indicator function (1 if the condition is true, 0 otherwise), and $L_t(x)$ is the leaf node in tree $t$ containing $x$. The weight $w_i(x)$ represents the average proportion of trees where $x_i$ and $x$ share the same leaf.\n",
        "\n",
        "4. Estimate the Conditional CDF\n",
        "\n",
        "Using the weights $w_i(x)$, QRF approximates the conditional cumulative distribution function (CDF) of $Y$ given $X = x$:\n",
        "\n",
        "$$ \\hat{F}(y | x) = \\sum_{i=1}^n w_i(x) \\mathbb{I}\\{ y_i \\leq y \\} $$\n",
        "\n",
        "This is a weighted empirical CDF, where each observation $y_i$ contributes to the CDF based on its weight $w_i0(x)$.\n",
        "\n",
        "5. Compute Conditional Quantiles\n",
        "\n",
        "To estimate the conditional quantile $Q_Y(\\tau | x)$ for a given $\\tau$, find the value $y$ such that the estimated CDF reaches or exceeds $\\tau$:\n",
        "\n",
        "$$ \\hat{Q}_Y(\\tau | x) = \\inf \\{ y : \\hat{F}(y | x) \\geq \\tau \\} $$\n",
        "\n",
        "In practice, this is computed by sorting the response values $y_i$ with non-zero weights $w_i(x)$ and finding the value $y$ where the cumulative sum of weights reaches $\\tau$.\n",
        "\n",
        "For example:\n",
        "\n",
        "- Sort the $y_i$ values in ascending order: $y_{(1)} \\leq y_{(2)} \\leq \\dots \\leq y_{(n)}$.\n",
        "\n",
        "- Compute the cumulative weights: $\\sum_{i: y_i \\leq y_{(k)}} w_i(x)$.\n",
        "\n",
        "- Find the smallest $y_{(k)}$ such that $\\sum_{i: y_i \\leq y_{(k)}} w_i(x) \\geq \\tau$.\n",
        "\n",
        "6. Prediction Intervals (Optional)\n",
        "\n",
        "To construct a prediction interval (e.g., 80% interval), compute the quantiles for $\\tau = 0.1$ and $\\tau = 0.9$:\n",
        "\n",
        "$$ \\hat{Q}_Y(0.1 | x), \\hat{Q}_Y(0.9 | x) $$\n",
        "\n",
        "This interval captures the central 80% of the conditional distribution of $Y$.\n",
        "\n",
        "7. Output\n",
        "\n",
        "For a given input $x$, QRF outputs:\n",
        "\n",
        "- The estimated quantiles $\\hat{Q}_Y(\\tau | x)$ for specified $\\tau$ (e.g., median for $\\tau = 0.5$).\n",
        "\n",
        "- Optionally, prediction intervals or the full conditional distribution.\n",
        "\n"
      ],
      "metadata": {
        "id": "uJS_IJgVI-bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a flowchart summarizing the QRF algorithm:\n",
        "\n",
        "\n",
        "![alt text](http://drive.google.com/uc?export=view&id=1l61dWCA6kQkFf7Q2-hNZEu78cc8Z-flu)\n"
      ],
      "metadata": {
        "id": "MfeqJ2MyFVfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QRF Differs from Standard Random Forests\n",
        "\n",
        "- **Standard Random Forest**: Predicts the conditional mean \\( \\mathbb{E}[Y | X = x] \\) by averaging the response values in the leaf nodes.\n",
        "- **QRF**: Retains all response values in the leaf nodes and uses them to estimate the conditional CDF, allowing quantile predictions.\n"
      ],
      "metadata": {
        "id": "8q-gt5kxUIlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages and Limitations\n",
        "\n",
        "**Advantages**:\n",
        "\n",
        "- Provides a full picture of the conditional distribution, not just the mean.\n",
        "- Handles complex, non-linear relationships without distributional assumptions.\n",
        "- Robust to outliers and heteroscedasticity.\n",
        "- Can generate prediction intervals for uncertainty quantification.\n",
        "\n",
        "**Limitations**:\n",
        "\n",
        "- Computationally intensive, especially for large datasets, as it stores all response values in leaf nodes.\n",
        "- Interpretability is limited compared to simpler models like linear quantile regression.\n",
        "- Performance depends on the quality and diversity of the Random Forest ensemble.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_oHgtdo9Tx-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Applications\n",
        "\n",
        "- **Finance**: Estimating quantiles of asset returns for risk management (e.g., Value-at-Risk).\n",
        "- **Environmental Science**: Predicting extreme weather events (e.g., 95th percentile of rainfall).\n",
        "- **Healthcare**: Modeling variability in patient outcomes.\n",
        "- **Energy**: Forecasting energy demand with uncertainty intervals.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iQ-vcH8iUBDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Differences from Random Forests\n",
        "\n",
        "-   `More Randomness`: Extra Trees randomizes both feature splits and threshold selection, while Random Forests optimize splits based on a criterion (e.g., Gini or entropy).\n",
        "-   `Faster Training`: Random split selection avoids computationally expensive optimization, making Extra Trees faster to train.\n",
        "-   `Bias-Variance Tradeoff`: Extra Trees increases bias slightly (due to random splits) but reduces variance, which can lead to better generalization on noisy datasets.\n",
        "-   `Overfitting`: Extra Trees is less prone to overfitting than Random Forests, especially when the dataset is small or noisy."
      ],
      "metadata": {
        "id": "5kbEVEgICPd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages\n",
        "\n",
        "-   `Speed`: Faster training due to random split selection.\n",
        "-   `Robustness`: Handles noisy data well and reduces overfitting.\n",
        "-   `Simplicity`: Fewer hyperparameters to tune compared to other ensemble methods.\n",
        "-   `Versatility`: Works for both classification and regression tasks."
      ],
      "metadata": {
        "id": "zoVtYA7e3_qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disadvantages\n",
        "\n",
        "-   `Less Interpretable`: Like Random Forests, the ensemble nature makes it harder to interpret individual trees.\n",
        "-   `Slightly Higher Bias`: Random splits may lead to less optimal individual trees compared to optimized splits in Random Forests.\n",
        "-   `Memory Usage`: Building many trees can be memory-intensive for large datasets."
      ],
      "metadata": {
        "id": "0BkKGa9k4BdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When to Use Extra Trees\n",
        "\n",
        "-   When you need a fast, robust ensemble method for classification or regression.\n",
        "-   When dealing with noisy or high-dimensional datasets.\n",
        "-   When computational resources are limited, and training speed is a priority.\n",
        "-   As an alternative to Random Forests when overfitting is a concern."
      ],
      "metadata": {
        "id": "gg_wMc694I5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup R in Python Runtype"
      ],
      "metadata": {
        "id": "Bn4w4oqMCagF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install {rpy2}\n",
        "\n",
        "{rpy2} is a Python package that provides an interface to the R programming language, allowing Python users to run R code, call R functions, and manipulate R objects directly from Python. It enables seamless integration between Python and R, leveraging R's statistical and graphical capabilities while using Python's flexibility. The package supports passing data between the two languages and is widely used for statistical analysis, data visualization, and machine learning tasks that benefit from R's specialized libraries."
      ],
      "metadata": {
        "id": "yerTCtKKCmik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall rpy2 -y\n",
        "!pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqeCyNf0Crlc",
        "outputId": "50cd1a3a-9903-4403-a64a-0c14d8869f42"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rpy2 3.5.17\n",
            "Uninstalling rpy2-3.5.17:\n",
            "  Successfully uninstalled rpy2-3.5.17\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (3.1.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (2025.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (5.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2==3.5.1) (3.0.2)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp311-cp311-linux_x86_64.whl size=314979 sha256=53db052524c36cdea7e4d5c95ff2bcbea9f8b18ac9515f5431d563c4fb2fec90\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/55/d1/47be85a5f3f1e1f4d1e91cb5e3a4dcb40dd72147f184c5a5ef\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "vOzGUgYCCyqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lngQQKKC2lc",
        "outputId": "31a39e95-ab28-4d1d-9897-e9400b61f7ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantile Regression Forest from scratch\n",
        "\n",
        "Implementing a QRF model from scratch in base R is highly complex because Random Forests (and by extension, QRF) rely on ensemble tree-building and randomization techniques that are typically handled by packages like {randomForest} or {quantregForest}. Without packages, we would need to manually code decision tree construction, bootstrap sampling, random feature selection, and quantile estimation, which is impractical for a concise response and computationally intensive.\n",
        "\n",
        "However, I can provide a conceptual implementation of a simplified QRF in base R, focusing on the core mechanics, and then use the provided data to fit and validate the model. To make this feasible, I’ll approximate the QRF by building a small ensemble of decision trees and estimating quantiles manually.\n"
      ],
      "metadata": {
        "id": "_W-exb0KKCFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data and Data preparation"
      ],
      "metadata": {
        "id": "NMJamUQ5XZDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Read and prepare the data\n",
        "data = readr::read_csv( \"https://github.com//zia207/r-colab/raw/main/Data/Machine_Learning/gp_soil_data.csv\")\n",
        "predictors <- c(\"DEM\", \"Slope\", \"Aspect\", \"TPI\", \"KFactor\", \"SiltClay\", \"MAT\", \"MAP\", \"NDVI\")\n",
        "X <- data[, predictors]\n",
        "y <- data$SOC\n",
        "\n",
        "\n",
        "# Split data into training (70%) and testing (30%) sets\n",
        "set.seed(123)  # For reproducibility\n",
        "n <- nrow(data)\n",
        "train_idx <- sample(1:n, size = 0.7 * n)\n",
        "train_X <- X[train_idx, ]\n",
        "train_y <- y[train_idx]\n",
        "test_X <- X[-train_idx, ]\n",
        "test_y <- y[-train_idx]"
      ],
      "metadata": {
        "id": "bnJ7L5JfKEFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d3e14c-2568-4174-8e0f-996fc28ba353"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 467 Columns: 19\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr  (4): STATE, COUNTY, NLCD, FRG\n",
            "dbl (15): ID, FIPS, STATE_ID, Longitude, Latitude, SOC, DEM, Aspect, Slope, ...\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simplified QRF Implementation Function\n",
        "\n",
        "The R function `build_simple_tree()` constructs a simplified decision tree for regression, used in Quantile Regression Forests.\n",
        "\n",
        "- **Inputs**:\n",
        "  - `X`: Data frame of predictors.\n",
        "  - `y`: Response vector.\n",
        "  - `n_features`: Number of features to consider.\n",
        "\n",
        "- **Steps**:\n",
        "  1. Validates `X` as a data frame.\n",
        "  2. Randomly selects `n_features` features.\n",
        "  3. For each feature and its unique values (as thresholds):\n",
        "     - Splits data into left (`<= threshold`) and right (`> threshold`) groups.\n",
        "     - Computes weighted variance: `(var(left_y) * left_size + var(right_y) * right_size) / n`.\n",
        "     - Keeps split with lowest variance.\n",
        "  4. Returns a list: best feature, threshold, loss, and response values (`left_y`, `right_y`).\n",
        "\n",
        "- **Key Features**:\n",
        "  - Random feature selection.\n",
        "  - Variance-based splitting.\n",
        "  - Stores response values for quantile estimation.\n",
        "\n",
        "- **Limitations**:\n",
        "  - No recursion or stopping criteria.\n",
        "  - Regression-focused.\n",
        "\n",
        "Used to build trees in QRF for quantile predictions."
      ],
      "metadata": {
        "id": "BrOesvibXnLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Simplified decision tree function\n",
        "build_simple_tree <- function(X, y, n_features) {\n",
        "  if (!is.data.frame(X)) stop(\"X must be a data frame\")\n",
        "  n <- nrow(X)\n",
        "  selected_features <- sample(1:ncol(X), size = min(n_features, ncol(X)))\n",
        "  best_split <- list(feature = NULL, threshold = NULL, loss = Inf, left_y = NULL, right_y = NULL)\n",
        "\n",
        "  for (feature in selected_features) {\n",
        "    feature_values <- as.numeric(X[[feature]])\n",
        "    values <- sort(unique(feature_values))\n",
        "    if (length(values) < 2) next\n",
        "    for (threshold in values[-length(values)]) {\n",
        "      left_idx <- feature_values <= threshold\n",
        "      right_idx <- !left_idx\n",
        "      if (sum(left_idx) > 0 & sum(right_idx) > 0) {\n",
        "        left_y <- y[left_idx]\n",
        "        right_y <- y[right_idx]\n",
        "        # Fixed syntax: Added parentheses to var() calls\n",
        "        loss <- var(left_y, na.rm = TRUE) * sum(left_idx) / n + var(right_y, na.rm = TRUE) * sum(right_idx) / n\n",
        "        if (!is.na(loss) && loss < best_split$loss) {\n",
        "          best_split <- list(\n",
        "            feature = feature,\n",
        "            threshold = threshold,\n",
        "            loss = loss,\n",
        "            left_y = left_y,\n",
        "            right_y = right_y\n",
        "          )\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return(best_split)\n",
        "}"
      ],
      "metadata": {
        "id": "XEGwQbt_bTd1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QRF model\n",
        "\n",
        "This R code builds a Quantile Regression Forest (QRF) by creating an ensemble of decision trees:\n",
        "\n",
        "- **Inputs**: `train_X` (predictors), `train_y` (response), `n_trees` (10 trees), `n_features` (3 features per split).\n",
        "- **Process**:\n",
        "  1. Loops `n_trees` times.\n",
        "  2. For each tree:\n",
        "     - Randomly samples data with replacement (`boot_idx`).\n",
        "     - Creates bootstrap subsets `boot_X` and `boot_y`.\n",
        "     - Builds a tree using `build_simple_tree` with `n_features`.\n",
        "     - Stores the tree in `trees` list.\n",
        "- **Output**: List of `n_trees` trees for QRF predictions."
      ],
      "metadata": {
        "id": "QF70BOZBbZ8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# QRF model (ensemble of simple trees)\n",
        "n_trees <- 10  # Small number for simplicity\n",
        "n_features <- 3  # Number of features to consider at each split\n",
        "trees <- list()\n",
        "# Build trees\n",
        "for (i in 1:n_trees) {\n",
        "  boot_idx <- sample(1:nrow(train_X), size = nrow(train_X), replace = TRUE)\n",
        "  boot_X <- train_X[boot_idx, , drop = FALSE]\n",
        "  boot_y <- train_y[boot_idx]\n",
        "  tree <- build_simple_tree(boot_X, boot_y, n_features)\n",
        "  trees[[i]] <- tree\n",
        "}\n"
      ],
      "metadata": {
        "id": "ttAmoFuebame"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction Function\n",
        "\n",
        "The R function `predict_qrf` predicts quantiles for new data using a Quantile Regression Forest (QRF):\n",
        "\n",
        "- **Inputs**: `X_new` (new predictors), `trees` (list of QRF trees), `quantiles` (e.g., 0.1, 0.5, 0.9).\n",
        "- **Process**:\n",
        "  1. Initializes a matrix for predictions (rows = samples, columns = quantiles).\n",
        "  2. For each sample in `X_new`:\n",
        "     - Collects response values (`left_y` or `right_y`) from each tree’s leaf based on feature and threshold.\n",
        "     - Computes specified quantiles from collected values.\n",
        "     - Assigns NA if no values are collected.\n",
        "  3. Names columns (e.g., \"q0.1\", \"q0.5\", \"q0.9\").\n",
        "- **Output**: Matrix of quantile predictions for each sample."
      ],
      "metadata": {
        "id": "2S6NVZr8bmZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Prediction function for quantiles\n",
        "predict_qrf <- function(X_new, trees, quantiles = c(0.1, 0.5, 0.9)) {\n",
        "  n <- nrow(X_new)\n",
        "  predictions <- matrix(NA, nrow = n, ncol = length(quantiles))\n",
        "\n",
        "  for (i in 1:n) {\n",
        "    collected_y <- c()\n",
        "    for (tree in trees) {\n",
        "      if (is.null(tree$feature)) next\n",
        "      feature <- tree$feature\n",
        "      threshold <- tree$threshold\n",
        "      if (as.numeric(X_new[i, feature]) <= threshold) {\n",
        "        collected_y <- c(collected_y, tree$left_y)\n",
        "      } else {\n",
        "        collected_y <- c(collected_y, tree$right_y)\n",
        "      }\n",
        "    }\n",
        "    if (length(collected_y) > 0) {\n",
        "      predictions[i, ] <- quantile(collected_y, probs = quantiles, na.rm = TRUE)\n",
        "    } else {\n",
        "      predictions[i, ] <- NA\n",
        "    }\n",
        "  }\n",
        "  colnames(predictions) <- paste0(\"q\", quantiles)\n",
        "  return(predictions)\n",
        "}"
      ],
      "metadata": {
        "id": "3DEviDNdbox8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation\n",
        "\n",
        "**Quantile Loss** (also called pinball loss) is a loss function used in quantile regression to measure the error between true values and predicted quantiles. It penalizes under- and over-predictions asymmetrically based on the target quantile $\\tau \\in (0, 1)$). For a quantile $\\tau$, the loss encourages the prediction to align with the $\\tau$-th percentile of the data.\n",
        "\n",
        "$$ L_{\\tau}(y_{\\text{true}}, y_{\\text{pred}}) =\n",
        "  \\begin{cases}\n",
        "  \\tau \\cdot (y_{\\text{true}} - y_{\\text{pred}}) & \\text{if } y_{\\text{true}} \\geq y_{\\text{pred}}, \\\\\n",
        "  (1 - \\tau) \\cdot (y_{\\text{pred}} - y_{\\text{true}}) & \\text{if } y_{\\text{true}} < y_{\\text{pred}}.\n",
        "  \\end{cases}\n",
        "  $$\n",
        "\n",
        "In Quantile Regression Forests, quantile loss isn’t directly used for tree building (which uses variance reduction), but it’s useful for evaluating the accuracy of quantile predictions or fine-tuning models."
      ],
      "metadata": {
        "id": "CkucSoDVbuHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Predict on test set\n",
        "quantiles <- c(0.1, 0.5, 0.9)  # Define quantiles explicitly\n",
        "test_predictions <- predict_qrf(test_X, trees, quantiles)\n",
        "\n",
        "# Validation using quantile loss\n",
        "quantile_loss <- function(y_true, y_pred, tau) {\n",
        "  errors <- y_true - y_pred\n",
        "  loss <- mean(ifelse(errors >= 0, tau * errors, (tau - 1) * errors), na.rm = TRUE)\n",
        "  return(loss)\n",
        "}\n",
        "\n",
        "# Calculate quantile loss for each quantile\n",
        "losses <- sapply(1:ncol(test_predictions), function(i) {\n",
        "  quantile_loss(test_y, test_predictions[, i], quantiles[i])\n",
        "})\n",
        "names(losses) <- paste0(\"q\", quantiles)\n",
        "\n",
        "# Print results\n",
        "cat(\"Test Quantile Predictions (first 5 rows):\\n\")\n",
        "print(head(test_predictions))\n",
        "cat(\"\\nQuantile Losses:\\n\")\n",
        "print(losses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMs9AvFNbzGN",
        "outputId": "e345e552-d8f9-4fe4-dd9a-c4fc69a97bcd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Quantile Predictions (first 5 rows):\n",
            "       q0.1  q0.5   q0.9\n",
            "[1,] 1.1348 4.594 11.220\n",
            "[2,] 1.4900 5.899 13.758\n",
            "[3,] 1.8410 6.384 14.977\n",
            "[4,] 1.3090 5.009 12.587\n",
            "[5,] 1.8410 6.384 14.977\n",
            "[6,] 1.3600 5.313 13.007\n",
            "\n",
            "Quantile Losses:\n",
            "     q0.1      q0.5      q0.9 \n",
            "0.5520858 1.7203582 0.9385313 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantile Regression Forest in R\n",
        "\n",
        "Quantile Regression Forest extends Random Forests to estimate conditional quantiles, providing a robust, non-parametric way to model the full distribution of a response variable. It works by collecting observations from tree leaves and computing quantiles from the empirical distribution. It’s particularly valuable for applications requiring uncertainty quantification or modeling non-standard distributions.\n",
        "\n",
        "The {quantregForest} package in R is designed for fitting Quantile Regression Forests (QRF), an extension of Random Forests that predicts conditional quantiles of a response variable instead of just the mean. It allows users to estimate the full conditional distribution, making it ideal for modeling uncertainty, variability, or heteroskedasticity. The package provides functions to train QRF models, predict quantiles (e.g., 10th, 50th, 90th percentiles), and assess variable importance. It is particularly useful for non-parametric regression tasks in fields like ecology, finance, and risk assessment.\n",
        "\n",
        "The **{quantregForest}** package in R provides several key functions for building and analyzing Quantile Regression Forests (QRF). Below are the most important functions, based on the package's documentation and common usage:\n",
        "\n",
        "1.  `quantregForest()`: Constructs an ensemble of decision trees to estimate conditional quantiles of the response variable, retaining all observations in leaf nodes to compute quantiles.\n",
        "\n",
        "    -   **Key Arguments**:\n",
        "        -   `x`: Matrix or data frame of predictor variables.\\\n",
        "        -   `y`: Vector of response variable values.\\\n",
        "        -   `ntree`: Number of trees in the forest (default: 500).\\\n",
        "        -   `mtry`: Number of predictors to consider at each split (default: `floor(ncol(x)/3)`).\\\n",
        "        -   `nodesize`: Minimum number of observations in a terminal node (default: 5).\\\n",
        "        -   `importance`: Logical to compute variable importance (default: FALSE).\n",
        "\n",
        "2.  `predict.quantregForest()`: \\*: Makes predictions for specified quantiles using a fitted QRF model. Generates quantile predictions (e.g., 10th, 50th, 90th percentiles) for new data based on the empirical distribution of responses in the leaf nodes.\n",
        "\n",
        "    -   **Key Arguments**:\n",
        "        -   `object`: A fitted `quantregForest` model.\\\n",
        "        -   `newdata`: Data frame or matrix of predictors for which to predict quantiles.\\\n",
        "        -   `what`: Vector of quantiles to predict (e.g., `c(0.1, 0.5, 0.9)`) or a function (e.g., `mean` for conditional mean).\\\n",
        "        -   `all`: Logical to return predictions for all trees (default: FALSE).\n",
        "\n",
        "3.  `importance.quantregForest()`: Extracts variable importance measures from a fitted QRF model.\n",
        "\n",
        "    -   **Key Arguments**:\n",
        "        -   `x`: A fitted `quantregForest` model with `importance = TRUE`.\n",
        "\n",
        "4.  `conditionalQuantiles()`: Estimates conditional quantiles for specific predictor values.\n",
        "\n",
        "    -   **Key Arguments**:\n",
        "        -   `object`: A fitted `quantregForest` model.\\\n",
        "        -   `newdata`: Data for which to compute quantiles.\\\n",
        "        -   `quantiles`: Vector of quantiles to estimate (e.g., `c(0.1, 0.5, 0.9)`).\n",
        "\n",
        "These functions make {quantregForest} a powerful tool for non-parametric quantile regression, particularly for applications requiring uncertainty quantification or robust predictions.\n"
      ],
      "metadata": {
        "id": "bh7jEhGCLDZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Check Required Libraries"
      ],
      "metadata": {
        "id": "RlLmnBj77AMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "packages <- c('tidyverse',\n",
        "              'plyr',\n",
        "              'quantregForest',\n",
        "              'mlbench',\n",
        "              'Metrics'\n",
        "         )"
      ],
      "metadata": {
        "id": "9rXvjfapLYED"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Missing Packages"
      ],
      "metadata": {
        "id": "MDwlBWYYLc1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Install missing packages\n",
        "new.packages <- packages[!(packages %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')"
      ],
      "metadata": {
        "id": "PWzWe7xULb2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify Installation"
      ],
      "metadata": {
        "id": "HM3Bl4-PLfFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHr9zUJvLfNl",
        "outputId": "1f7c8710-e371-444f-fcde-6ce7e379dcef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages:\n",
            "     tidyverse           plyr quantregForest        mlbench        Metrics \n",
            "          TRUE           TRUE           TRUE           TRUE           TRUE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load R Packages"
      ],
      "metadata": {
        "id": "2cPLFz1GLlRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Load packages with suppressed messages\n",
        "invisible(lapply(packages, function(pkg) {\n",
        "  suppressPackageStartupMessages(library(pkg, character.only = TRUE))\n",
        "}))"
      ],
      "metadata": {
        "id": "cQl-1GIuLmCD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Loaded Packages"
      ],
      "metadata": {
        "id": "AH4vKW2yL1OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Check loaded packages\n",
        "cat(\"Successfully loaded packages:\\n\")\n",
        "print(search()[grepl(\"package:\", search())])# Check loaded packageswer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du3QbdUeL1Yw",
        "outputId": "45d32ef3-27bc-4073-ac58-5cb888375b6e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded packages:\n",
            " [1] \"package:Metrics\"        \"package:mlbench\"        \"package:quantregForest\"\n",
            " [4] \"package:RColorBrewer\"   \"package:randomForest\"   \"package:plyr\"          \n",
            " [7] \"package:lubridate\"      \"package:forcats\"        \"package:stringr\"       \n",
            "[10] \"package:dplyr\"          \"package:purrr\"          \"package:readr\"         \n",
            "[13] \"package:tidyr\"          \"package:tibble\"         \"package:ggplot2\"       \n",
            "[16] \"package:tidyverse\"      \"package:tools\"          \"package:stats\"         \n",
            "[19] \"package:graphics\"       \"package:grDevices\"      \"package:utils\"         \n",
            "[22] \"package:datasets\"       \"package:methods\"        \"package:base\"          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data and Data Processing\n",
        "\n",
        "For classification, we will use the {party} packages to build a cforest model on [Health Iinsurance](http://peopleanalytics-regression-book.org/data/health_insurance.csv) data. The dataset contains information about individuals' choices of insurance products based on various features.\n",
        "\n",
        "We will use `read_csv()` function of {readr} package to import data as a **tidy** data.\n"
      ],
      "metadata": {
        "id": "euKDzTA_OEl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Read file from github\n",
        "mf = readr::read_csv( \"https://github.com//zia207/r-colab/raw/main/Data/Machine_Learning/gp_soil_data.csv\")\n",
        "\n",
        "# Create a data frame with selected variables\n",
        "df <- mf %>% dplyr::select(SOC, DEM, Slope, Aspect, TPI, KFactor, SiltClay, MAT, MAP, NDVI, NLCD, FRG)\n",
        "\n",
        "# Convert categorical variables to factors\n",
        "df$NLCD <- as.factor(df$NLCD)\n",
        "df$FRG <- as.factor(df$FRG)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seeds <- 11076\n",
        "tr_prop <- 0.70\n",
        "\n",
        "# Split data into training and test sets, stratified by NLCD and FRG\n",
        "seeds=123\n",
        "set.seed(seeds)\n",
        "train <- ddply(df, .(NLCD, FRG),\n",
        "               function(., seed) { set.seed(seed); .[sample(1:nrow(.), trunc(nrow(.) * tr_prop)), ] }, seed = 101)\n",
        "test <- ddply(df, .(NLCD, FRG),\n",
        "              function(., seed) { set.seed(seed); .[-sample(1:nrow(.), trunc(nrow(.) * tr_prop)), ] }, seed = 101)\n",
        "\n",
        "# Scale numeric features (exclude SOC, NLCD, FRG)\n",
        "train[-c(1, 11, 12)] <- scale(train[-c(1, 11, 12)])\n",
        "test[-c(1, 11, 12)] <- scale(test[-c(1, 11, 12)])\n",
        "\n",
        "# Prepare predictors and response for QRF\n",
        "X_train <- train %>% dplyr::select(-SOC)\n",
        "y_train <- train$SOC\n",
        "X_test <- test %>% dplyr::select(-SOC)\n",
        "y_test <- test$SOC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiC3ipq-OHim",
        "outputId": "c51a0b3d-042e-402f-89f8-1e617f9465cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 467 Columns: 19\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr  (4): STATE, COUNTY, NLCD, FRG\n",
            "dbl (15): ID, FIPS, STATE_ID, Longitude, Latitude, SOC, DEM, Aspect, Slope, ...\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit Quantile Regression Forest\n",
        "\n",
        "`quantregForest()` function from the {quantregForest} package is used to fit a Quantile Regression Forest model. It builds an ensemble of decision trees to estimate conditional quantiles of the response variable, retaining all observations in leaf nodes to compute quantiles."
      ],
      "metadata": {
        "id": "FgeTUFfedgmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Fit Quantile Regression Forest\n",
        "\n",
        "set.seed(seeds)\n",
        "qrf_model <- quantregForest(x = X_train, y = y_train,\n",
        "                           ntree = 500,\n",
        "                           nodesize = 5,\n",
        "                           mtry = floor(ncol(X_train)/3),\n",
        "                           importance = TRUE)\n",
        "qrf_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70oxisindhV9",
        "outputId": "bd982e8a-5c84-43a9-9af5-86bb55300d7b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Call:\n",
            " quantregForest(x = X_train, y = y_train, ntree = 500, nodesize = 5,      mtry = floor(ncol(X_train)/3), importance = TRUE) \n",
            "\n",
            "                     Number of trees: 500\n",
            "No. of variables tried at each split: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction and Evaluation"
      ],
      "metadata": {
        "id": "9w_DIFMAfLIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Predict quantiles (10th, 50th, 90th percentiles)\n",
        "quantiles <- c(0.10, 0.50, 0.90)\n",
        "qrf_predictions <- predict(qrf_model, newdata = X_test, what = quantiles)\n",
        "\n",
        "# Evaluate model performance\n",
        "# Function to calculate RMSE for a specific quantile\n",
        "calc_rmse <- function(actual, predicted) {\n",
        "  sqrt(mean((actual - predicted)^2))\n",
        "}\n",
        "\n",
        "# Calculate RMSE for each quantile\n",
        "rmse_results <- sapply(1:length(quantiles), function(i) {\n",
        "  calc_rmse(y_test, qrf_predictions[, i])\n",
        "})\n",
        "\n",
        "# Print RMSE for each quantile\n",
        "names(rmse_results) <- paste0(\"Quantile_\", quantiles)\n",
        "print(\"RMSE for each quantile:\")\n",
        "print(rmse_results)\n",
        "\n",
        "# Calculate coverage for 80% prediction interval (10th to 90th percentile)\n",
        "coverage <- mean(y_test >= qrf_predictions[, 1] & y_test <= qrf_predictions[, 3])\n",
        "cat(\"Coverage of 80% prediction interval:\", coverage, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyniMS25fLSJ",
        "outputId": "bed9c928-4bde-4bfe-993d-aaa2fd41c4dc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"RMSE for each quantile:\"\n",
            "Quantile_0.1 Quantile_0.5 Quantile_0.9 \n",
            "    6.391295     4.202219     5.914064 \n",
            "Coverage of 80% prediction interval: 0.7328767 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variable Importance"
      ],
      "metadata": {
        "id": "ThUECMifg60O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Variable importance\n",
        "var_imp_qrf <- importance(qrf_model)\n",
        "var_imp_qrf <- sort(var_imp_qrf[,1], decreasing = TRUE) # Sort by importance\n",
        "var_imp_qrf <- data.frame(Variable = names(var_imp_qrf), Importance = var_imp_qrf)\n",
        "# plot variable importance\n",
        "ggplot(var_imp_qrf, aes(x = reorder(Variable, Importance), y = Importance)) +\n",
        "  geom_bar(stat = \"identity\") +\n",
        "  coord_flip() +\n",
        "  labs(title = \"Variable Importance for QRF\", x = \"Variable\", y = \"Importance\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "HVf0Bpb3g7jE",
        "outputId": "03912b03-015e-492b-c916-9bf7ebcc40d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAC61BMVEUAAAABAQECAgIDAwMEBAQFBQUGBgYHBwcJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUWFhYXFxcYGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJycoKCgpKSkqKiorKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tMTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRWVlZXV1dZWVlaWlpbW1tcXFxdXV1eXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29xcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGCgoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OUlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWmpqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4uLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnKysrLy8vMzMzNzc3Pz8/Q0NDS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7////A7o8iAAAVP0lEQVR4nO3ce3xU5Z3H8VGrbCuLiFXXXcu6rtbb1lsXrXKxqKxbLdutSpdad6lZa0W8AFlIG4fcSDAEEkSMpIQaaNZwC5dRjDBAIoXVEFQsQlZKECRZQhJyv/3+3DM3OMzk8vzmeWaec06+n5evkMxkDs/5vV9zOISXj4uQo3PpXgCKbQB2eAB2eAB2eNEBT3zR/8uEmeceqnGdOf+zcw/4u2fBIMd85+Tgv2/G5QkRj60fe+mwW+d3EY26eNiwv7gpx3ho1IUXGc0Z/HhDoOiA145qNz5+ceHhcw/1nOgNfhYl8E2fDP77fm9lxEN5ly473uS57qcG63qi7l0j1gc+Q4GiA+66ZpXxcdYk2nrndaNzqOaivG+XGZ7Br1z5N17x81Yf8Ef33/h3+YGXGMDHLlj+2HeS33js+gX05QW5k27/RSuV33Pjze4e3+tvdV33u+ABjl3w+8nfm9xOO2+/8s5tZDrIv1xyza9NL/nceKhpeIHvmQPf2B5kfXgugM1F+Wdw8niizqtKO0asoaqLDtS65vQYnsGvalwJPfU3LDYeOH3V7+mrq7f5X2EA17ry6KMLX6OqSzpqXL+hzrsW1l+2lmq/U+R7Pbk+obOHS6PuG1ad/ssttPnSRvNBbi0h80uMtl7Y7n/mvlmBd3DZt94HsLkogb+6+CCtubabGowpX1ta5/rMf0UOfFXj+pRo9k+MB/5wtfGtLz3jf4UBXOeqoUbXIWp3Ha1xfUn0mx+X/L3xzH896Xu9D/js4aqJHk1/53rjyZM95oMYwOaXGK2+KrCgJ6bRqG+OGPGN24qNL0a5fK2IfioOKtq76H99hSalEC29b8w9w9bXuWr9wIGvalyniLLGGw8svWT06NFXP+5/gR/4NJ1xnaAu15c1xqe0YGzeD4xnXpvge70fOHS4OqLJKUvH+F9oPogBbH6JUXnwHTx2nv99+9I43xd4B58rWuCyK48MO0HvX2681672ixiewa9qXAeN99hPjQc23nDuBeHAfzLe5ZPX+N6ks6f4RQ1g0+EM4LXXGk8eaDUfxAA2v8SoaeRy3y/VF3/oZ228yve+BfC5ogXuvfGRJ4hW3thNecPfDgIHv6pxvUxN333DeKDp2xuoffo2/wvCgV+iM9/NrR+5nr6+dq1f6+Kd5sMZwI0jiumDb502H8T3Z7DpJb6WDl/ZRHtu+XmQ9XdXnAKwuah/0LHQ5SVqfuRv714xe0RJADj41YoLVtzxN9Pafdfsvfddf/1zgWtoOPDSO//66XaquPemW14jv9YvvplsOpwBTBW3jbrNuGUyHcQANr/E35rbhg27Pbs3yNo7ZhqAzWn6SVbYX5Ll+tL1hbqDOS0nANPEKd0Kj+asHAH8v/eOzFF4OEeFf2xweAB2eAB2eAB2eAB2eAB2eNEB19eF19Ad8VDUtSo70mlLrqq+R9mhBlpVC4BZATgei2YGYAALB+B4LJoZgAEs3FAHnoJ0BmCHB2CHB2CHB2CHB2CHB2CHB2CHB2CHB2CHB2CHB2CHB2CHB2CHFx1w5dQmqsuuTEhNzu9IrCM6sLg6B8CWLErgrMU+4AIiz1s7VhPlfAFgixYl8LplVQHg3he6XuxtSSQf8B9+9atjneF16T7DIV4ESGdnhwhwa+IxP3DPDFr50eYyP/DnZWW1TeG16D7DIV4ESFNTmwgw7VnoB964kmqzktoJl2iLFu0lmijDf5O1zHi/z88nAFu16ID7DcBWC8AOD8AOD8AOD8AOD8AOD8AOD8AOD8AOD8AOD8AOD8AOD8AOD8AOL/bAltwsAVs4AFg4AMdj0cwADGDhhjqw7rsMrfFQAGy7eCgAtl08FADbLh4KgG0XDwXAtouHAmDbxUMBsO3ioQDYdvFQAGy7eCgAtl08FADbLh4KgG0XD8UiwLsrPd7Q5+c+A3Bf8VC0A3csnJ++qNvHWl1K2+e65xwA8MDxULQDVxUQ7an3eD3e7JkfJHVSwyqPtyFlYWbPrBZachjAkfFQtAO3uPN3t5APuKK0ZEfgEn30IGX/eeP7vYnYZaeP+tjjZoC6iPf9A9XT/1MD7bJT651VHQB+xxsAPrkk/4VDDUmfFGOXnT7qY4+bAWru5X3/QHX0/1T/u+x8vJ9og8cH/OH6w4ntdDrX482vonkHKXX+CfwZ3Ee8y6r2S3RDelp6VosP+MjzB7yJycnGu/nDuW8ULqCKV3CT1Vc8FO3A/ed9F8B9xUOxLvCa1C4A9xUPxbrAZwPw+fFQAGy7eCgAtl08FADbLh4KgG0XDwXAtouHAmDbxUMBsO3ioQDYdvFQAGy7eCgAtl08FADbLh6KPYEtuVkCtnAAsHAAjseimQEYwMINdWDd9zn6YqMA2F6xUQBsr9goALZXbBQA2ys2CoDtFRsFwPaKjQJge8VGAbC9YqMA2F6xUQBsr9goALZXbBQA2ys2CoDtFRvFQsCVUzqIFuUSFRUZXySkpmR1ATg8NoqVgGeWU0dSLp3YsqqZKguICisAHB4bxUrAxdm0a1MurWw8sskPnLsPu+yEx94ZxwK77JwFXpffkHc8t2N6VtZs/yV6NWGXnfDYO+No32XHDHy4+O2Tudt2Eq39zPcODoZLtCn2ZdVKl+h1lHj0ZG6i8b1fZQO479goFgLuLwCbYqMA2F6xUQBsr9goALZXbBQA2ys2CoDtFRsFwPaKjQJge8VGAbC9YqMA2F6xUQBsr9goALZXbBQA2ys2CoDtFRvFnsCW3CwBWzgAWDgAx2PRzAAMYOGGOrDuWx3JpEbJDMAakholMwBrSGqUzACsIalRMgOwhqRGyQzAGpIaJTMAa0hqlMwArCGpUTIDsIakRskMwBqSGiUzAGtIapTMAKwhqVEyA7CGpEbJDMAakholM0sBm/fZecs9NcldC2DZrAVs3meHkuvxDpbPWsDmfXYCwOtnzz7WHl6nbiHJIk4oou7Bv0Wwjl5lhxpwVWLA5n12AsD71q79+kx4rbqFJIs4oYg6B/8WwVp6lR1qoFWJ7LITts8OLtFKstYl2rzPDoCVZCngvgOwTADWkNQomQFYQ1KjZAZgDUmNkhmANSQ1SmYA1pDUKJkBWENSo2QGYA1JjZIZgDUkNUpmANaQ1CiZAVhDUqNkBmANSY2SGYA1JDVKZgDWkNQomdkT2JKbJWALBwALB+B4LJoZgAEs3FAH1n2XJJ76UTIDcGxTP0pmAI5t6kfJDMCxTf0omQE4tqkfJTMAxzb1o2QG4NimfpTMABzb1I+SGYBjm/pRMgNwbFM/SmYAjm3qR8kMwLFN/SiZATi2qR8lMwDHNvWjZKYbuLKATiQ1VD7jdrt7Q49VlwI4ytdFph/45G/rfcxEDSkLM3sa09KXZ8/cn5E7v+3dzLcBLJ124AXP1VIA+OhByv5z8W7a5i0tqaDSbVuLyP677MRgPxteunfZqXx5c57xcVpycubJJfkvHFpyiKii9PWDtKd463tk/1121O9nw0z3LjvGe7eoJPAOzq+ieQdLdtGmbevX7KIN3q1b8WewfNov0QXUm1XuB/5w7huFCxpT0/OPPL93/pLsTgCrSDewQACWCcCxTf0omQE4tqkfJTMAxzb1o2QG4NimfpTMABzb1I+SGYBjm/pRMgNwbFM/SmYAjm3qR8kMwLFN/SiZATi2qR8lMwDHNvWjZAbg2KZ+lMwAHNvUj5KZPYEtuVkCtnA4C9yen0QftwO4/2wOPO3ZuynzKQD3n82Bf0jjyfcfgPvL5sDjDN3W70sA6751Or/gqgB8Fjjtn0e/fFMGgKMaJTM9d9HeV+dXiPoCWCoNwD8KBuCoRslMA3BZMABHNUpmWi7RDTm/TFhyBsBRjZKZFuCHp765bOqjAI5qlMy0AN/r+/AggKMaJTMtwD87aVymnwZwVKNkpuUuevzw8T8cORHAUY2Smb676NUAjmqUzPT8oGNfWdnmmwEc1SiZaQGefseV4y5bAOCoRslM0130ZNr/YiSlxwvgQUfJTAvwWJrUQw+ZETsWzk9f1A1ggVEy0wL8H4uTHpt+lxmxqoBoT73H2+jbXmdLVmH6meaMJXldAJZOC3DXie4VaUfMwC3u/N0txiXav72OZzW9t7VkJ63bTfRuWtrxtvA6dJOeX2hVvRELjbouZUdqj8+qzLvsPEl9/WtSrXdWtcfr317HU0Z7i1+fl5NWRvTHwsKvm8Nr0016fsFVtfZGLDTqOpUdKU6rMu+ys4Mi/zXp4/1EGzwer397HU8RbS4r2UOnWnGJlk7LJbog4kaqIT0tPavF423yba/jyV6W3NyUmZPSAGDptABPOB15r2wq7GYawDJpAf6nkfdPnNj/z6IBbHfg7eVGGwZ8FwNYUfhZtHzBVQEYP4tWMUpmlvpZNIAFRsnMIj+LBrDwKJlZ5GfRABYeJTMNwF/18bNoAAuPkpkG4JGPrusUxQWwbBqAW1dN+quXPwNwlKNkpufvwcez/uEHbwE4qlEy07VHx4EplwA4qlEy0wL8f3nfv21hHYCjGiUzDcAbfnLFM3tEdfsGtuQoARwEvn9FC4MXwHJhnyxlRwIwgIUb6sC6b6vOK7QqAANYxSiZAVi60KoADGAVo2QGYOlCqwIwgFWMkhmApQutCsAAVjFKZgCWLrQqAANYxSiZAVi60KoADGAVo2QGYOlCqwIwgFWMkpmFgCsTUpPzOyqfcbvdf6qc0kG0KBfA0lkJuIDI85bvo/H5zHLqSAKwfBYD7n3BeB+nprZVFmfTrk25tthl5+yqsMvO4MA9M4Lv4HX5DXnHc22xy06c97NhpmGXnYGAN64MAR8ufvskLtHyWekSbdxkLQvcZO2qXEeJRwGsIAsB9xeAZQKwdKFVARjAKkbJDMDShVYFYACrGCUzAEsXWhWAAaxilMwALF1oVQAGsIpRMgOwdKFVARjAKkbJDMDShVYFYACrGCUzAEsXWhWAsYWDcACOx6KZARjAwgE4HotmBmC73mQJnj6AASwcgAEsGIABLByAlQVgAAsGYAALB2BlARjAggEYwMIBWFkABrBgAAawcABWluOAK6c2UV124P/u3z7XPedAYMsdAEtnFeCsxSHgQ0md1LAqsOUOgKWzCvC6ZVVB4JId/gcKfFvuWGOXHcE9aLDLzoDArYnHAsDveEPAPTOsscuO4B402GVnQGDaszAAfDixnU7nBrbcwSVaOstcookysn077Gwhb2JycnVgyx0AS2cR4IECsEwABrBwAFYWgAEsGIABLByAlQVgAAsGYAALB2BlARjAggEYwMIBWFkABrBgAAawcNjCQVkAjseimQEYwMIBOB6LZgZgC91kCS2aGYABLByAASwYgJWdPoABLByAASwYgJWdPoABLByAASwYgJWdPoABLByAASwYgJWdPoABLJwzgX3//7f7o4TU1DlV9EGSe85eAMtnKeCC4IfPsg8md1FbEYDlsx5wQuor7uPFu4KPeXNzj7eG1y4NfO5YXRFHj7b2XmWHst+qBttlJwA8LTk501Den0PFXtqX/OJRAEtnKeDQJXruUd9WO5RTjUu0dNa7RBsf9mfQrjnzXi3uAbB0VgLuJwDLBGBlpw9gAAsHYAALBmBlpw9gAAsHYAALBmBlpw9gAAsHYAALBmBlpw9gAAsHYAALBmBlpw9gbOEgHIDjsWhmAAawcACOx6KZAVjbTVaUi2YGYAALB2AACwZg6dMOBWAACwdgAAsGYOnTDgVgAAsHYAALBmDp0w4FYAALB2AACwZg6dMOBWAAC+c04KKivh6tLgWwdJYAPrFlVTN9mrKwcEtWYfqZ5owleV2NaenLs2ceAbBslgBe2XhkExVtpyOe1fTe1pKdtG538W7a5i1VtAlLlBuLMMMmLP0Bd0zPyppNTcsTN3rKaG/x6/Ny0sqWHCKqALB8VgDetpNo7WcHu3pnlhbR5rKSPXSqtWQXbdq2Hn8GS2eFS3Si8exX2btfzXnTk70subkpMyeloTE1Pf/I8wcALJsVgM/l8fbxIIBlArD0aYcCMH7QIRyAASwYgKVPOxSAASwcgAEsGIClTzsUgAEsHIABLBiApU87FIABLByAASwYgKVPOxSAsYWDcACOx6KZARjAwgE4HotmBmA9N1nRL5oZgAEsHIABLBiA5c7ZFIABLByAASwYgOXO2RSAASwcgAEsGIDlztkUgAEsHIABLBiA5c7ZFIABLJyDgd9yT01yv5eQmpLVVZ0DYOksB0yUXE+VBUSFFQBWkHWBc/f5gP9YWPh1c3htHOCIV59f5yDPi9faq+xQ9ltVGxPYuESvJh/wu2lpx9vC6+AAR7z6/LoGeV68jl5lh1K4qvb4rGrAXXb6fgcT4RKtIOteogGsJAsChwdgmQAsd86mAAxg4QAMYMEALHfOpgAMYOEADGDBACx3zqYADGDhAAxgwQAsd86mAAxg4QAMYMEALHfOpgCMLRyEA3A8Fs0MwAAWDsDxWDQzAANYuCEF3FAfXt2xiIeirlXZkepqlB1K5aqOKjvUQKtqlQCOrOpxRQdS2oHHdK+gr6onxfE3A3D8syVwzZuKDqS0E6/rXkFf1S6O42+mChhZNAA7PEXALemZr/WoOZSqetZOteC6GtwZ7rZ4rkoR8PodVFKh5lCqqv90lgXXVfUJFe2N56oUAefUUOXbag6lrlmWXFeXuz6eq1II/N9qDqWuWVZcV8P8Q3FdlSLgjV4q/h81h1LXLAuuqynlVHxXpQi4LTNjca+aQ6nq89Sfpe623LpWzUhN3RPPVeGvSQ4PwA4PwA4PwA4PwA5vaAFfdKb/51bFbxnxDMDBWu6K4zri2FAD3v7Q9Iefznzq3rqt4/79iUcb6bf3TUjo2P7IAwVThz/VNW3svdNp+8O/njLhDM298+43iTLHP5TQrnvVUg014PJrOruHb6WEwrLLm+m5nO1juunJ5eUj6+nz2+nEIqI79pVf2UJT3nl/bE/TA807HyF6Nl/3qqUacsAPEo3+muYuKjM+WT4tYzbR0v8sv598wN2/eWjylWXlE4hmLEtJ8n2/e/T48Xcn6V61VEMOeJIBXEdzc8oeIMr/pR/42fKJfuAVj3XT+DLfFzPeSJ3j+/75L+tesXRDF/iyBvq3vB339NDjhT7TgzdR2nTaf9mWAPD2f+xuu+9Uxc1ttOBj3auWaugCj31q4o+b6dVxDzzX7TNtu3nsl3c+OCPrlg1+YJo75u6lRBljxk3FTZYtK/uR7hXEJwA7vCELPFQCsMMDsMMDsMMDsMP7fyDGRqcNRHjqAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning\n",
        "\n",
        "To perform hyperparameter tuning for the `quantregForest` model in R,  we can implement a custom grid search with k-fold cross-validation. We'll use the provided data processing code and the `quantile_loss` function to evaluate performance, focusing on optimizing `ntree`, `nodesize`, and `mtry`. Below is a concise R code for hyperparameter tuning using base R and parallel processing with `doParallel`.\n",
        "\n",
        "Steps for Hyperparameter Tuning:\n",
        "\n",
        "1. **Define Parameter Grid**: Create combinations of `ntree`, `nodesize`, and `mtry`.\n",
        "2. **Custom Cross-Validation**: Implement k-fold CV manually to compute quantile loss for each parameter set.\n",
        "3. **Select Best Parameters**: Choose the combination with the lowest average quantile loss.\n",
        "4. **Train Final Model**: Use the best parameters to train the QRF model.\n",
        "5. **Evaluate on Test Set**: Compute quantile losses for multiple quantiles on the test set.\n"
      ],
      "metadata": {
        "id": "mTRIKFnZhBER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define quantile loss function"
      ],
      "metadata": {
        "id": "pt63CFZ_iP4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Define quantile loss function\n",
        "quantile_loss <- function(y_true, y_pred, tau) {\n",
        "  errors <- y_true - y_pred\n",
        "  loss <- mean(ifelse(errors >= 0, tau * errors, (tau - 1) * errors), na.rm = TRUE)\n",
        "  return(loss)\n",
        "}"
      ],
      "metadata": {
        "id": "R72m2YemiQR_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Parameter Grid"
      ],
      "metadata": {
        "id": "ZIf6cdnSiW_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Define parameter grid\n",
        "param_grid <- expand.grid(\n",
        "  ntree = c(100, 500, 1000),\n",
        "  nodesize = c(5, 10, 15),\n",
        "  mtry = c(floor(ncol(X_train)/4), floor(ncol(X_train)/3), floor(ncol(X_train)/2))\n",
        ")"
      ],
      "metadata": {
        "id": "h1hsRpc9iXIA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom k-fold Cross-Validation Function"
      ],
      "metadata": {
        "id": "GcwZGQimifZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Custom k-fold cross-validation function\n",
        "qrf_cv <- function(params, x, y, k = 5, tau = 0.5, seed = seeds) {\n",
        "  set.seed(seed)\n",
        "  n <- length(y)\n",
        "  folds <- sample(rep(1:k, length.out = n))\n",
        "  losses <- numeric(k)\n",
        "\n",
        "  for (fold in 1:k) {\n",
        "    train_idx <- which(folds != fold)\n",
        "    val_idx <- which(folds == fold)\n",
        "\n",
        "    x_tr <- x[train_idx, ]\n",
        "    y_tr <- y[train_idx]\n",
        "    x_val <- x[val_idx, ]\n",
        "    y_val <- y[val_idx]\n",
        "\n",
        "    model <- quantregForest(\n",
        "      x = x_tr, y = y_tr,\n",
        "      ntree = params$ntree,\n",
        "      nodesize = params$nodesize,\n",
        "      mtry = params$mtry\n",
        "    )\n",
        "\n",
        "    pred <- predict(model, newdata = x_val, what = tau)\n",
        "    losses[fold] <- quantile_loss(y_val, pred, tau)\n",
        "  }\n",
        "\n",
        "  return(mean(losses))\n",
        "}"
      ],
      "metadata": {
        "id": "fNuirRI1ifhe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Perform Grid Search"
      ],
      "metadata": {
        "id": "vhPETApdin5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Perform grid search\n",
        "results <- data.frame(param_grid, loss = NA)\n",
        "for (i in 1:nrow(param_grid)) {\n",
        "  params <- param_grid[i, ]\n",
        "  results$loss[i] <- qrf_cv(params, X_train, y_train, k = 5, tau = 0.5, seed = seeds)\n",
        "}"
      ],
      "metadata": {
        "id": "5OBl2yLrioxb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best Parameters"
      ],
      "metadata": {
        "id": "tObQiqDeir35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Find best parameters\n",
        "best_params <- results[which.min(results$loss), ]\n",
        "cat(\"Best Parameters:\\n\")\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWKESTttiw3C",
        "outputId": "6f0955fe-c838-4716-dbd5-a70824db92f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:\n",
            "   ntree nodesize mtry     loss\n",
            "11   500        5    3 1.220187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Final Model with Best Parameters"
      ],
      "metadata": {
        "id": "4Eyt89Hdi-aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Train final model with best parameters\n",
        "set.seed(seeds)\n",
        "final_qrf_model <- quantregForest(\n",
        "  x = X_train, y = y_train,\n",
        "  ntree = as.numeric(best_params$ntree),\n",
        "  nodesize = as.numeric(best_params$nodesize),\n",
        "  mtry = as.numeric(best_params$mtry),\n",
        "  importance = TRUE\n",
        ")"
      ],
      "metadata": {
        "id": "BBjbJapEi-rU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict and Evaluate on Test Set"
      ],
      "metadata": {
        "id": "KHS1QSc5jCF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Predict on test set for multiple quantiles\n",
        "quantiles <- c(0.1, 0.5, 0.9)\n",
        "test_pred <- predict(final_qrf_model, newdata = X_test, what = quantiles)\n",
        "colnames(test_pred) <- paste0(\"q\", quantiles)\n",
        "\n",
        "# Evaluate test set performance\n",
        "test_losses <- sapply(seq_along(quantiles), function(i) {\n",
        "  quantile_loss(y_test, test_pred[, i], quantiles[i])\n",
        "})\n",
        "names(test_losses) <- paste0(\"q\", quantiles)\n",
        "cat(\"Test Set Quantile Losses:\\n\")\n",
        "print(test_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYZG0zhqjCRG",
        "outputId": "31eceddb-0047-4da6-f45f-d22f17fb7ce6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Quantile Losses:\n",
            "     q0.1      q0.5      q0.9 \n",
            "0.5086186 1.4230017 0.7623329 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary and Conclusion\n",
        "\n",
        "Quantile Regression Forest extends Random Forests to estimate conditional quantiles, providing a robust, non-parametric way to model the full distribution of a response variable. It works by collecting observations from tree leaves and computing quantiles from the empirical distribution. It’s particularly valuable for applications requiring uncertainty quantification or modeling non-standard distributions. This tutorial  demonstrated how to implement QRF from scratch, fit a model using the {quantregForest} package, and perform hyperparameter tuning with k-fold cross-validation. The results showed how to predict quantiles and evaluate model performance using quantile loss."
      ],
      "metadata": {
        "id": "_j759RVMQMut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "\n",
        "1.  Meinshausen, N. (2006). Quantile Regression Forests. Journal of Machine Learning Research, 7, 983–999.\n",
        "\n",
        "2.  Athey, S., Tibshirani, J., & Wager, S. (2019). Generalized Random Forests. The Annals of Statistics, 47(2), 1148–1178\n",
        "\n",
        "3.  Koenker, R., & Bassett, G. (1978). Regression Quantiles. Econometrica, 46(1), 33–50.\n",
        "\n",
        "4.  Breiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32.\n",
        "\n",
        "5.  Zhang, H., Zimmerman, J., Nettleton, D., & Nordman, D. J. (2019). Random Forest Prediction Intervals. The American Statistician, 74(4), 392–406.\n",
        "\n",
        "6.  [Quantile Regression Forests for Prediction Intervals \\| R-bloggers](URL:%20https://www.r-bloggers.com/2021/04/quantile-regression-forests-for-prediction-intervals/)\n",
        "\n",
        "7.  [Quantile Regression Forests Example from RDocumentation](URL:%20https://www.rdocumentation.org/packages/quantregForest/versions/1.0/topics/quantregForest)\n"
      ],
      "metadata": {
        "id": "SaZTnZx3QPGI"
      }
    }
  ]
}