{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/Machine_Learning/Tree_based/03-01-02-03-tree-based-models-bagging-cforest-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYZbTX0qQrZb"
      },
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGBfrL2GQoII"
      },
      "source": [
        "# 2.3 Conditional Random Forest (cforest)\n",
        "\n",
        "Conditional Random Forest (cforest) builds on ensemble learning method that constructs multiple decision trees but uses **conditional inference trees** (implemented via the `ctree` algorithm) instead of standard CART (Classification and Regression Trees). These trees are based on a statistical framework that tests the independence between predictors and the response variable to guide splitting decisions. This notebook will cover the theoretical background, implementation details, and practical applications of cforest in R."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZqlGV65Qme0"
      },
      "source": [
        "## Overview\n",
        "\n",
        "A **Conditional Random Forest (cforest)** is an extension of the Random Forest algorithm that uses **conditional inference trees** as its base learners instead of standard decision trees. It was introduced to address some limitations of traditional Random Forests, particularly in handling variable selection bias and providing more robust statistical inference. The `cforest` algorithm is implemented in the R package `party` and is designed to work within a conditional inference framework, which ensures unbiased variable selection and better handling of complex data structures.\n",
        "\n",
        "Key Features of cforest:\n",
        "\n",
        "-   `Unbiased Variable Selection`: Unlike traditional Random Forests, which may favor variables with more categories or continuous variables, cforest uses conditional inference to select variables without bias.\n",
        "\n",
        "-   `Statistical Rigor`: It incorporates permutation-based significance tests to decide splits, making it more robust for datasets with complex relationships or correlated predictors.\n",
        "\n",
        "-`Flexibility`: cforest can handle various types of response variables (e.g., continuous, categorical, survival data) and is less sensitive to overfitting in certain scenarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TpOehy1B7gE"
      },
      "source": [
        "### How Does Conditional Random Forest (cforest) Work?\n",
        "\n",
        "The **Conditional Random Forest (cforest)** algorithm combines the ensemble approach of Random Forests with the **conditional inference framework** to reduce bias in variable selection and handle mixed data types effectively. Below is a detailed explanation, incorporating mathematical formulations where relevant:\n",
        "\n",
        "1. Input Data\n",
        "\n",
        "-   `Dataset`: Let $D = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$ be the dataset, where:\n",
        "\n",
        "  -   $\\mathbf{x}_i = (x_{i1}, x_{i2}, \\dots, x_{ip})$ is a vector of $p$ predictor variables (numeric or categorical).\n",
        "\n",
        "  -   $y_i$ is the response variable (continuous for regression, categorical for classification).\n",
        "\n",
        "-   The goal is to predict $y$ given $\\mathbf{x}$ using an ensemble of conditional inference trees.\n",
        "\n",
        "2. Bootstrapping or Subsampling\n",
        "\n",
        "-   `Bagging`: For each tree $t = 1, 2, \\dots, T$, a bootstrap sample $D_t$ is drawn from $D$ with replacement, typically of size $n$. The probability that a specific observation $(\\mathbf{x}_i, y_i)$ is included in $D_t$ is approximately $1 - (1 - 1/n)^n \\approx 1 - e^{-1} \\approx 0.632$.\n",
        "\n",
        "-   `Subsampling`: Alternatively, a random subset of size $m< n$ is drawn without replacement. This reduces correlation between trees compared to bagging.\n",
        "\n",
        "-   `Out-of-Bag (OOB) Sample`: Observations not included in $D_t$ form the OOB sample, used for estimating generalization error.\n",
        "\n",
        "3.  Building Conditional Inference Trees\n",
        "\n",
        "Each tree in cforest is a **conditional inference tree** (`ctree`), constructed using a statistical framework to ensure unbiased variable selection. The process involves:\n",
        "\n",
        "3.1  `Variable Selection via Conditional Inference`:\n",
        "\n",
        "  -   At each node, cforest tests the null hypothesis $H_0: Y \\perp X_j \\mid \\mathbf{X}_{-j}$ for each predictor $X_j$, where $\\mathbf{X}_{-j}$ denotes all other predictors.\n",
        "\n",
        "    -   The test is based on a `permutation test`:\n",
        "\n",
        "        -   Compute a test statistic (e.g., for regression, a correlation-based statistic; for classification, a chi-squared or Gini-based statistic).\n",
        "\n",
        "        -   Permute the values of $X_j$ while keeping $Y$ and $\\mathbf{X}_{-j}$ fixed to generate a null distribution.\n",
        "\n",
        "        -   Calculate the p-value as the proportion of permuted test statistics exceeding the observed statistic:\n",
        "\n",
        "$$  p_j = P(T(\\mathbf{X}_j^{\\text{perm}}, Y) \\geq T(\\mathbf{X}_j, Y) \\mid \\mathbf{X}_{-j}) $$\n",
        "\n",
        "        \n",
        " - Select the predictor $X_j$ with the smallest p-value, provided $p_j < \\alpha$ (e.g., $\\alpha = 0.05$).\n",
        "\n",
        "  - This ensures unbiased variable selection, unlike standard Random Forest, which may favor variables with more split points (e.g., continuous variables).\n",
        "\n",
        "\n",
        "3.2 `Split Point Selection`:\n",
        "\n",
        "  -   For the selected predictor $X_j$:\n",
        "\n",
        "        -   If $X_j$ is continuous, evaluate split points $\\in {x_{ij} \\mid i \\in \\text{node}}$.\n",
        "\n",
        "        -   If $X_j$ is categorical with levels ${c_1, c_2, \\dots, c_k}$, consider all possible binary splits (e.g., ${c_1, c_2}$ vs. ${c_3, \\dots, c_k}$).\n",
        "\n",
        "    -   Choose the split that maximizes a test statistic, such as the standardized linear statistic:\n",
        "\n",
        "$$  T_j(s) = \\sum_{i \\in \\text{node}} w_i (y_i - \\bar{y}) (x_{ij} - \\bar{x}_j) \\cdot I(x_{ij} \\leq s) $$\n",
        "\n",
        "        \n",
        " where $w_i $ are weights (typically 1), and $I$ is the indicator function.\n",
        "\n",
        "\n",
        "-   The split maximizes the separation of $Y$ values in the child nodes.\n",
        "\n",
        "3.3  `Recursive Partitioning*`\n",
        "\n",
        "   -   Split the node into two child nodes based on the selected variable and split point.\n",
        "\n",
        "   -   Recursively apply the above steps to each child node until a stopping criterion is met.\n",
        "\n",
        "3.4  `topping Criteria`:\n",
        "\n",
        "  -   Stop splitting if:\n",
        "\n",
        "       -   No predictor has a p-value $< \\alpha$ (no significant association).\n",
        "\n",
        "        -   The node size is below a threshold (e.g., $n_{\\text{min}} = 10$).\n",
        "\n",
        "        -   A maximum tree depth is reached.\n",
        "\n",
        "    -   The terminal node assigns a prediction (e.g., mean $y$ for regression, majority class for classification).\n",
        "\n",
        "4. Ensemble Prediction\n",
        "\n",
        "-   `Regression`:\n",
        "\n",
        "   -   For a new observation $\\mathbf{x}$, each tree \\$t \\$ predicts $\\hat{y}_t(\\mathbf{x})$.\n",
        "\n",
        "   -   The final prediction is the average across all trees:\n",
        "\n",
        "$$ \\hat{y}(\\mathbf{x}) = \\frac{1}{T} \\sum_{t=1}^T \\hat{y}_t(\\mathbf{x}) $$\n",
        "\n",
        "-   `Classification`:\n",
        "\n",
        "  -   Each tree votes for a class $\\hat{y}_t(\\mathbf{x})$.\n",
        "  -   The final prediction is the majority class or averaged class probabilities:\n",
        "\n",
        "$$  \\hat{y}(\\mathbf{x}) = \\arg\\max_c \\left( \\frac{1}{T} \\sum_{t=1}^T I(\\hat{y}_t(\\mathbf{x}) = c) \\right) $$\n",
        "\n",
        "-   `OOB Error`:\n",
        "\n",
        "   -   For each observation $(\\mathbf{x}_i, y_i)$, use only trees where $(\\mathbf{x}_i, y_i) \\notin D_t$.\n",
        "\n",
        "  -   Compute OOB predictions and estimate error (e.g., RMSE for regression, misclassification rate for classification).\n",
        "\n",
        "5. Variable Importance\n",
        "\n",
        "-   `Permutation Importance`:\n",
        "\n",
        "  -   For predictor $X_j$, permute its values in the OOB sample for tree $t$.\n",
        "  \n",
        "  -   Compute the increase in OOB error (e.g., MSE for regression):\n",
        "\n",
        "$$  \\text{Importance}(X_j) = \\frac{1}{T} \\sum_{t=1}^T \\left( \\text{MSE}_{\\text{perm},t} - \\text{MSE}_{\\text{orig},t} \\right) $$\n",
        "\n",
        "-   Higher values indicate greater importance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfeqJ2MyFVfU"
      },
      "source": [
        "Below is a flowchart illustrating the process of building a Conditional Random Forest (cforest):\n",
        "\n",
        "![alt text](http://drive.google.com/uc?export=view&id=1nRfrCMuys21NkrUx43xOsJ_mkTSQDNyr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kbEVEgICPd5"
      },
      "source": [
        "### Comparison with Standard Random Forest\n",
        "\n",
        "| **Aspect** | **Random Forest (CART)** | **Conditional Random Forest (cforest)** |\n",
        "|------------------|---------------------------|---------------------------|\n",
        "| **Base Learner** | CART (decision trees) | Conditional inference trees (`ctree`) |\n",
        "| **Variable Selection** | Based on impurity (Gini, MSE) | Based on conditional inference (p-values) |\n",
        "| **Bias in Splitting** | Biased toward variables with more categories | Unbiased, uses permutation tests |\n",
        "| **Computational Speed** | Faster | Slower due to statistical tests |\n",
        "| **Implementation** | Widely available (e.g., scikit-learn, R) | Primarily in R’s `party` package |\n",
        "| **Interpretability** | Less statistically rigorous | More rigorous (p-value-based splits) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn4w4oqMCagF"
      },
      "source": [
        "## Setup R in Python Runtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yerTCtKKCmik"
      },
      "source": [
        "### Install {rpy2}\n",
        "\n",
        "{rpy2} is a Python package that provides an interface to the R programming language, allowing Python users to run R code, call R functions, and manipulate R objects directly from Python. It enables seamless integration between Python and R, leveraging R's statistical and graphical capabilities while using Python's flexibility. The package supports passing data between the two languages and is widely used for statistical analysis, data visualization, and machine learning tasks that benefit from R's specialized libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqeCyNf0Crlc",
        "outputId": "4dfe6596-27df-4fa7-a618-5be9678729e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rpy2 3.5.17\n",
            "Uninstalling rpy2-3.5.17:\n",
            "  Successfully uninstalled rpy2-3.5.17\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (1.17.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (3.1.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (2025.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from rpy2==3.5.1) (5.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->rpy2==3.5.1) (3.0.2)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp311-cp311-linux_x86_64.whl size=314981 sha256=7216690ccd0b8b995758bb149236ff2e730ada135a1f080430fc6099d2270de4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/55/d1/47be85a5f3f1e1f4d1e91cb5e3a4dcb40dd72147f184c5a5ef\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall rpy2 -y\n",
        "!pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOzGUgYCCyqg"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lngQQKKC2lc",
        "outputId": "b34461d5-498d-4125-cc48-933f185117d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLU0BT_LCVBr"
      },
      "source": [
        "## Conditional Random Forest (cforest) from scratch\n",
        "\n",
        "I'll implement conditional Random Forest models for both classification (using iris dataset) and regression (using Boston Housing dataset) in R from scratch. Since you specified not to use any R packages for the Random Forest implementation, The implementation will include tree building, bootstrapping, and prediction logic without relying on external libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W-exb0KKCFd"
      },
      "source": [
        "### Decision tree node structure\n",
        "\n",
        "The `create_node` function creates a decision tree node as a list with `feature`, `threshold`, `left`, `right`, `value` (all NULL), and `is_leaf` (FALSE), used for building Random Forest trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnJ7L5JfKEFZ"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Node structure for decision tree\n",
        "create_node <- function() {\n",
        "  list(\n",
        "    feature = NULL,\n",
        "    threshold = NULL,\n",
        "    left = NULL,\n",
        "    right = NULL,\n",
        "    value = NULL,\n",
        "    is_leaf = FALSE\n",
        "  )\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm5QODWQKJVX"
      },
      "source": [
        "### Splitting criteria (Gini for classification, variance reduction for regression)\n",
        "\n",
        "The following functions calculate splitting criteria for classification and regression tasks:\n",
        "\n",
        "- `gini_impurity`: Calculates Gini impurity for classification. Returns 0 if no labels; otherwise, computes 1 minus the sum of squared probabilities of each class.\n",
        "- `variance`: Calculates variance for regression. Returns 0 if one or no values; otherwise, computes average squared deviation from the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUT8e-YsKMkn"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Gini impurity for classification\n",
        "gini_impurity <- function(labels) {\n",
        "  if (length(labels) == 0) return(0)\n",
        "  probs <- table(labels) / length(labels)\n",
        "  1 - sum(probs^2)\n",
        "}\n",
        "\n",
        "# Variance for regression\n",
        "variance <- function(values) {\n",
        "  if (length(values) <= 1) return(0)\n",
        "  mean_val <- mean(values)\n",
        "  sum((values - mean_val)^2) / length(values)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5jja0V6KRFN"
      },
      "source": [
        "### Finding the best split for classification and regression\n",
        "\n",
        "The following functions find the best split for classification and regression tasks:\n",
        "\n",
        "- `find_best_split_classification`: Finds the best split for classification by testing each feature and threshold (midpoints of sorted values). It selects the split with the lowest weighted Gini impurity, returning the feature, threshold, and Gini value.\n",
        "\n",
        "- `find_best_split_regression`: Finds the best split for regression by testing each feature and threshold. It selects the split with the lowest weighted variance, returning the feature, threshold, and variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGiOCpS2KZRD"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Find best split for classification\n",
        "find_best_split_classification <- function(data, labels, features) {\n",
        "  best_gini <- Inf\n",
        "  best_feature <- NULL\n",
        "  best_threshold <- NULL\n",
        "\n",
        "  for (feature in features) {\n",
        "    values <- data[, feature]\n",
        "    unique_vals <- sort(unique(values))\n",
        "    thresholds <- (unique_vals[-length(unique_vals)] + unique_vals[-1]) / 2\n",
        "\n",
        "    for (threshold in thresholds) {\n",
        "      left_idx <- values <= threshold\n",
        "      right_idx <- !left_idx\n",
        "\n",
        "      if (sum(left_idx) == 0 || sum(right_idx) == 0) next\n",
        "\n",
        "      left_labels <- labels[left_idx]\n",
        "      right_labels <- labels[right_idx]\n",
        "\n",
        "      gini_left <- gini_impurity(left_labels)\n",
        "      gini_right <- gini_impurity(right_labels)\n",
        "      weight_left <- sum(left_idx) / length(labels)\n",
        "      weight_right <- sum(right_idx) / length(labels)\n",
        "      gini_total <- weight_left * gini_left + weight_right * gini_right\n",
        "\n",
        "      if (gini_total < best_gini) {\n",
        "        best_gini <- gini_total\n",
        "        best_feature <- feature\n",
        "        best_threshold <- threshold\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  list(feature = best_feature, threshold = best_threshold, gini = best_gini)\n",
        "}\n",
        "\n",
        "# Find best split for regression\n",
        "find_best_split_regression <- function(data, values, features) {\n",
        "  best_var <- Inf\n",
        "  best_feature <- NULL\n",
        "  best_threshold <- NULL\n",
        "\n",
        "  for (feature in features) {\n",
        "    vals <- data[, feature]\n",
        "    unique_vals <- sort(unique(vals))\n",
        "    thresholds <- (unique_vals[-length(unique_vals)] + unique_vals[-1]) / 2\n",
        "\n",
        "    for (threshold in thresholds) {\n",
        "      left_idx <- vals <= threshold\n",
        "      right_idx <- !left_idx\n",
        "\n",
        "      if (sum(left_idx) == 0 || sum(right_idx) == 0) next\n",
        "\n",
        "      left_vals <- values[left_idx]\n",
        "      right_vals <- values[right_idx]\n",
        "\n",
        "      var_left <- variance(left_vals)\n",
        "      var_right <- variance(right_vals)\n",
        "      weight_left <- sum(left_idx) / length(values)\n",
        "      weight_right <- sum(right_idx) / length(values)\n",
        "      var_total <- weight_left * var_left + weight_right * var_right\n",
        "\n",
        "      if (var_total < best_var) {\n",
        "        best_var <- var_total\n",
        "        best_feature <- feature\n",
        "        best_threshold <- threshold\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  list(feature = best_feature, threshold = best_threshold, variance = best_var)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PFZp4r6KTZX"
      },
      "source": [
        "### Random Forest ensemble creation\n",
        "\n",
        "The `build_tree` function recursively builds a decision tree:\n",
        "- Creates a node.\n",
        "- Stops if max depth reached or data size ≤ min_size, setting node as leaf with majority class (classification) or mean value (regression).\n",
        "- Randomly selects sqrt(features) for splitting.\n",
        "- Finds best split using Gini (classification) or variance (regression).\n",
        "- If no valid split, sets node as leaf.\n",
        "- Splits data into left/right based on feature/threshold, recursively builds child nodes.\n",
        "- Returns the node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6VIewBPKgkI"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Build a single decision tree\n",
        "build_tree <- function(data, target, type = \"classification\", max_depth = 10, min_size = 5, depth = 0) {\n",
        "  node <- create_node()\n",
        "\n",
        "  # Stopping criteria\n",
        "  if (depth >= max_depth || nrow(data) <= min_size) {\n",
        "    node$is_leaf <- TRUE\n",
        "    if (type == \"classification\") {\n",
        "      node$value <- names(which.max(table(target)))\n",
        "    } else {\n",
        "      node$value <- mean(target)\n",
        "    }\n",
        "    return(node)\n",
        "  }\n",
        "\n",
        "  # Randomly select features (sqrt of total features)\n",
        "  n_features <- ncol(data)\n",
        "  mtry <- floor(sqrt(n_features))\n",
        "  features <- sample(1:n_features, mtry)\n",
        "\n",
        "  # Find best split\n",
        "  if (type == \"classification\") {\n",
        "    split <- find_best_split_classification(data, target, features)\n",
        "  } else {\n",
        "    split <- find_best_split_regression(data, target, features)\n",
        "  }\n",
        "\n",
        "  if (is.null(split$feature)) {\n",
        "    node$is_leaf <- TRUE\n",
        "    if (type == \"classification\") {\n",
        "      node$value <- names(which.max(table(target)))\n",
        "    } else {\n",
        "      node$value <- mean(target)\n",
        "    }\n",
        "    return(node)\n",
        "  }\n",
        "\n",
        "  # Split data\n",
        "  left_idx <- data[, split$feature] <= split$threshold\n",
        "  right_idx <- !left_idx\n",
        "\n",
        "  if (sum(left_idx) == 0 || sum(right_idx) == 0) {\n",
        "    node$is_leaf <- TRUE\n",
        "    if (type == \"classification\") {\n",
        "      node$value <- names(which.max(table(target)))\n",
        "    } else {\n",
        "      node$value <- mean(target)\n",
        "    }\n",
        "    return(node)\n",
        "  }\n",
        "\n",
        "  # Create child nodes\n",
        "  node$feature <- split$feature\n",
        "  node$threshold <- split$threshold\n",
        "  node$left <- build_tree(data[left_idx, ], target[left_idx], type, max_depth, min_size, depth + 1)\n",
        "  node$right <- build_tree(data[right_idx, ], target[right_idx], type, max_depth, min_size, depth + 1)\n",
        "\n",
        "  node\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxLlrw98KLyp"
      },
      "source": [
        "The `bootstrap_sample` function:\n",
        "\n",
        "- Randomly samples `n` rows (with replacement) from data and target.\n",
        "- Returns list of sampled data and target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h4WeJNRKkKg"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Bootstrap sampling\n",
        "bootstrap_sample <- function(data, target) {\n",
        "  n <- nrow(data)\n",
        "  idx <- sample(1:n, n, replace = TRUE)\n",
        "  list(data = data[idx, ], target = target[idx])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2FWv2CzKozl"
      },
      "source": [
        "The `random_forest` function:\n",
        "\n",
        "- Creates a list of `n_trees` decision trees.\n",
        "- For each tree, takes a bootstrap sample and builds a tree using `build_tree`.\n",
        "- Returns a list with the trees and model type (classification or regression)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kbMJ8KMKpou"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Build Random Forest\n",
        "random_forest <- function(data, target, type = \"classification\", n_trees = 100, max_depth = 10, min_size = 5) {\n",
        "  trees <- list()\n",
        "  for (i in 1:n_trees) {\n",
        "    sample <- bootstrap_sample(data, target)\n",
        "    tree <- build_tree(sample$data, sample$target, type, max_depth, min_size)\n",
        "    trees[[i]] <- tree\n",
        "  }\n",
        "  list(trees = trees, type = type)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6JaxlLvKwL7"
      },
      "source": [
        "\n",
        "### Prediction functions for the Random Forest\n",
        "\n",
        "- `predict_tree`: Predicts for one tree: returns leaf value if leaf node; else recursively follows left or right child based on feature/threshold comparison.\n",
        "\n",
        "- `predict_rf`: Predicts for Random Forest: collects predictions from all trees for each row; returns majority class (classification) or mean value (regression)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLV5BUwOKxAE"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Predict for a single tree\n",
        "predict_tree <- function(tree, row) {\n",
        "  if (tree$is_leaf) return(tree$value)\n",
        "\n",
        "  if (row[tree$feature] <= tree$threshold) {\n",
        "    predict_tree(tree$left, row)\n",
        "  } else {\n",
        "    predict_tree(tree$right, row)\n",
        "  }\n",
        "}\n",
        "\n",
        "# Predict for Random Forest\n",
        "predict_rf <- function(forest, data) {\n",
        "  predictions <- matrix(NA, nrow = nrow(data), ncol = length(forest$trees))\n",
        "\n",
        "  for (i in 1:length(forest$trees)) {\n",
        "    predictions[, i] <- apply(data, 1, function(row) predict_tree(forest$trees[[i]], row))\n",
        "  }\n",
        "\n",
        "  if (forest$type == \"classification\") {\n",
        "    apply(predictions, 1, function(x) names(which.max(table(x))))\n",
        "  } else {\n",
        "    apply(predictions, 1, mean)\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLbnVYCTK2hj"
      },
      "source": [
        "### Example Usage: Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewvVb58MK6Xc",
        "outputId": "50f897ec-6b07-48e3-f501-d47969838be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy (Iris): 0.9777778 \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Load datasets\n",
        "data(iris)\n",
        "\n",
        "# Classification: Iris dataset\n",
        "set.seed(123)\n",
        "train_idx <- sample(1:nrow(iris), 0.7 * nrow(iris))\n",
        "train_iris <- iris[train_idx, ]\n",
        "test_iris <- iris[-train_idx, ]\n",
        "\n",
        "# Train and predict classification Random Forest\n",
        "rf_class <- random_forest(train_iris[, 1:4], train_iris$Species, type = \"classification\", n_trees = 50)\n",
        "pred_class <- predict_rf(rf_class, test_iris[, 1:4])\n",
        "\n",
        "# Evaluate classification (accuracy)\n",
        "accuracy <- mean(pred_class == test_iris$Species)\n",
        "cat(\"Classification Accuracy (Iris):\", accuracy, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5svgZkqmLBEY"
      },
      "source": [
        "### Example Usage: Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDQate6zLGeq",
        "outputId": "aec28429-ff24-4536-fadd-d1a614c33ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regression RMSE (Boston): 2.836893 \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "data(Boston, package = \"MASS\")\n",
        "# Regression: Boston Housing dataset\n",
        "train_idx <- sample(1:nrow(Boston), 0.7 * nrow(Boston))\n",
        "train_boston <- Boston[train_idx, ]\n",
        "test_boston <- Boston[-train_idx, ]\n",
        "\n",
        "# Train and predict regression Random Forest\n",
        "rf_reg <- random_forest(train_boston[, -14], train_boston$medv, type = \"regression\", n_trees = 50)\n",
        "pred_reg <- predict_rf(rf_reg, test_boston[, -14])\n",
        "\n",
        "# Evaluate regression (RMSE)\n",
        "rmse <- sqrt(mean((pred_reg - test_boston$medv)^2))\n",
        "cat(\"Regression RMSE (Boston):\", rmse, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh7jEhGCLDZA"
      },
      "source": [
        "## Conditional Random Forest (cforest) in R\n",
        "\n",
        "I'll guide you through performing Conditional Random Forest (cforest) classification and regression in R using the {partykit} package. I'll include steps for building, pruning, summarizing, plotting, predicting, and assessing variable importance, then compare CIT with CART (using the {rpart} package)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTLU1efLLUUS"
      },
      "source": [
        "### Check amd Install Required R Packages\n",
        "\n",
        "Following R packages are required to run this notebook. If any of these packages are not installed, you can install them using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9rXvjfapLYED"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "packages <- c('tidyverse',\n",
        "              'plyr',\n",
        "              'partykit',\n",
        "              'mlbench',\n",
        "              'ggparty',\n",
        "              'caret'\n",
        "         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDwlBWYYLc1e"
      },
      "source": [
        "### Install Missing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWzWe7xULb2L"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Install missing packages\n",
        "new.packages <- packages[!(packages %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM3Bl4-PLfFF"
      },
      "source": [
        "### Verify Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHr9zUJvLfNl",
        "outputId": "681ff94a-da69-4872-8792-451b558a9b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed packages:\n",
            "tidyverse      plyr  partykit   mlbench   ggparty     caret \n",
            "     TRUE      TRUE      TRUE      TRUE      TRUE      TRUE \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cPLFz1GLlRD"
      },
      "source": [
        "### Load R Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cQl-1GIuLmCD"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Load packages with suppressed messages\n",
        "invisible(lapply(packages, function(pkg) {\n",
        "  suppressPackageStartupMessages(library(pkg, character.only = TRUE))\n",
        "}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH4vKW2yL1OF"
      },
      "source": [
        "### Check Loaded Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du3QbdUeL1Yw",
        "outputId": "abd8ac98-4a11-492e-a801-5658b206d905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded packages:\n",
            " [1] \"package:ggparty\"   \"package:mlbench\"   \"package:partykit\" \n",
            " [4] \"package:mvtnorm\"   \"package:libcoin\"   \"package:grid\"     \n",
            " [7] \"package:plyr\"      \"package:lubridate\" \"package:forcats\"  \n",
            "[10] \"package:stringr\"   \"package:dplyr\"     \"package:purrr\"    \n",
            "[13] \"package:readr\"     \"package:tidyr\"     \"package:tibble\"   \n",
            "[16] \"package:ggplot2\"   \"package:tidyverse\" \"package:tools\"    \n",
            "[19] \"package:stats\"     \"package:graphics\"  \"package:grDevices\"\n",
            "[22] \"package:utils\"     \"package:datasets\"  \"package:methods\"  \n",
            "[25] \"package:base\"     \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Check loaded packages\n",
        "cat(\"Successfully loaded packages:\\n\")\n",
        "print(search()[grepl(\"package:\", search())])# Check loaded packageswer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS-CaRU1MCaR"
      },
      "source": [
        "### Classification Problem\n",
        "\n",
        "This section demonstrates how to use Conditional Random Forest (cforest) for classification tasks in R, specifically using the `{party}` package. We will build a cforest model on the Health Insurance dataset, which contains information about individuals' choices of insurance products based on various features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euKDzTA_OEl-"
      },
      "source": [
        "#### Data\n",
        "\n",
        "For classification, we will use the {party} packages to build a cforest model on [Health Iinsurance](http://peopleanalytics-regression-book.org/data/health_insurance.csv) data. The dataset contains information about individuals' choices of insurance products based on various features.\n",
        "\n",
        "We will use `read_csv()` function of {readr} package to import data as a **tidy** data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiC3ipq-OHim",
        "outputId": "e97f0966-f3b1-4049-a9ff-fbf74e9297fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 1448 Columns: 6\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "chr (2): product, gender\n",
            "dbl (4): age, household, position_level, absent\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "Rows: 1,448\n",
            "Columns: 6\n",
            "$ product        <chr> \"C\", \"A\", \"C\", \"A\", \"A\", \"A\", \"A\", \"B\", \"C\", \"B\", \"B\", …\n",
            "$ age            <dbl> 57, 21, 66, 36, 23, 31, 37, 37, 55, 66, 58, 62, 31, 45,…\n",
            "$ household      <dbl> 2, 7, 7, 4, 0, 5, 3, 0, 3, 2, 1, 2, 2, 5, 3, 5, 4, 7, 7…\n",
            "$ position_level <dbl> 2, 2, 2, 2, 2, 1, 3, 3, 3, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4…\n",
            "$ gender         <chr> \"Male\", \"Male\", \"Male\", \"Female\", \"Male\", \"Male\", \"Male…\n",
            "$ absent         <dbl> 10, 7, 1, 6, 11, 14, 12, 25, 3, 18, 1, 25, 0, 10, 20, 2…\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Load data\n",
        "mf<-readr::read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/Machine_Learning/health_insurance.csv\")\n",
        "glimpse(mf)\n",
        "# convert factor\n",
        "mf$product <- as.factor(mf$product)\n",
        "mf$gender <- as.factor(mf$gender)\n",
        "# Split Data to Train and Test\n",
        "seeds = 11076\n",
        "tr_prop = 0.70\n",
        "# training data (70% data)\n",
        "train= ddply(mf,.(product, gender ),\n",
        "                 function(., seed) { set.seed(seed); .[sample(1:nrow(.), trunc(nrow(.) * tr_prop)), ] }, seed = 101)\n",
        "test = ddply(mf, .(product , gender),\n",
        "            function(., seed) { set.seed(seed); .[-sample(1:nrow(.), trunc(nrow(.) * tr_prop)), ] }, seed = 101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaFT5tP5OrTO"
      },
      "source": [
        "#### Fit the cforest Model\n",
        "\n",
        "The `cforest()` function in the R `{party}` package builds a **conditional random forest** using **conditional inference trees** as base learners. It fits an ensemble of trees on bootstrap samples, with random feature selection at each split. Unlike `randomForest`, it uses unbiased splitting (avoiding bias toward variables with many categories) and aggregates predictions via observation weights. Key parameters include `ntree` (number of trees), `mtry` (number of features per split), and `mincriterion` (tree depth control). It supports classification, regression, censored responses, and multivariate outcomes, with out-of-bag (OOB) predictions via `predict(..., OOB = TRUE)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6vVnAayOuQ6",
        "outputId": "c4be47d8-1140-48e9-ce97-9d0db4e066b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Length Class      Mode    \n",
            "nodes    500    -none-     list    \n",
            "data       6    data.frame list    \n",
            "weights  500    -none-     list    \n",
            "fitted     2    data.frame list    \n",
            "terms      3    terms      call    \n",
            "info       2    -none-     list    \n",
            "trafo      1    -none-     function\n",
            "predictf   2    terms      call    \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Fit the cforest model\n",
        "set.seed(seeds)\n",
        "cforest_model <- cforest(product ~ age + household + position_level + absent + gender,\n",
        "                         data = train,\n",
        "                         control = ctree_control( mtry = floor(sqrt(5)),\n",
        "                                                  teststat = \"quad\",\n",
        "                                                  testtype = \"Univariate\",\n",
        "                                                  mincriterion = 0.95))\n",
        "summary(cforest_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGdnDz8-O2QF"
      },
      "source": [
        "#### Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNGjn3RLO85q",
        "outputId": "504ee680-5791-4d99-c700-ce94eb3b7b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIT Classification Accuracy: 0.8287671 \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Predict with holdout test data\n",
        "cforest_predictions <- predict(cforest_model, newdata = test)\n",
        "\n",
        "# SValidate model\n",
        "cforest_accuracy <- mean(cforest_predictions == test$product)\n",
        "cat(\"CIT Classification Accuracy:\", cforest_accuracy, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vYS51bXyl8J"
      },
      "source": [
        "#### Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXAQVeTJypIY",
        "outputId": "c2e587d8-cec6-4f3d-ef0b-be57cf5e05c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Accuracy (mean): 0.8204462 \n",
            "Cross-Validation Accuracy (std dev): 0.01260583 \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "\n",
        "# Ensure product and gender are factors for classification\n",
        "mf$product <- as.factor(mf$product)\n",
        "mf$gender <- as.factor(mf$gender)\n",
        "\n",
        "# Verify product is a factor\n",
        "if (!is.factor(mf$product)) stop(\"Product is not a factor. Check data.\")\n",
        "\n",
        "\n",
        "# Perform 5-fold cross-validation on training data\n",
        "k <- 5\n",
        "set.seed(seeds)\n",
        "folds <- sample(rep(1:k, length.out = nrow(mf)))\n",
        "cv_accuracy <- numeric(k)\n",
        "\n",
        "for (j in 1:k) {\n",
        "  # Split into training and validation folds\n",
        "  train_cv <- mf[folds != j, ]\n",
        "  val_cv <- mf[folds == j, ]\n",
        "\n",
        "  # Train cforest model\n",
        "  model <- cforest(\n",
        "    product ~ .,\n",
        "    data = train_cv,\n",
        "    ntree = 500,  # Default number of trees\n",
        "    control = ctree_control(\n",
        "      mtry = floor(sqrt(ncol(train_cv) - 1)),  # Number of predictors - 1 (target)\n",
        "      teststat = \"quad\",\n",
        "      testtype = \"Univariate\",\n",
        "      mincriterion = 0.95\n",
        "    )\n",
        "  )\n",
        "\n",
        "  # Predict and calculate accuracy\n",
        "  pred <- predict(model, newdata = val_cv)\n",
        "  cv_accuracy[j] <- mean(pred == val_cv$product)\n",
        "}\n",
        "\n",
        "# Compute mean and standard deviation of accuracy\n",
        "mean_accuracy <- mean(cv_accuracy)\n",
        "sd_accuracy <- sd(cv_accuracy)\n",
        "cat(\"Cross-Validation Accuracy (mean):\", mean_accuracy, \"\\n\")\n",
        "cat(\"Cross-Validation Accuracy (std dev):\", sd_accuracy, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si7ksJ_UyxnN"
      },
      "source": [
        "#### Hyperparameter Tuning for cforest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l8gacUwy23Q"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid <- expand.grid(\n",
        "  mtry = c(2, 4, 6),  # Number of features to consider at each split\n",
        "  ntree = c(100, 500, 1000),  # Number of trees\n",
        "  mincriterion = c(0.90, 0.95, 0.99)  # Tree pruning threshold\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g_YBs_fuy7D8"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Perform 5-fold cross-validation for hyperparameter tuning\n",
        "k <- 5\n",
        "seeds=123\n",
        "set.seed(seeds)\n",
        "folds <- sample(rep(1:k, length.out = nrow(train)))\n",
        "results <- data.frame()\n",
        "\n",
        "for (i in 1:nrow(param_grid)) {\n",
        "  mtry_val <- param_grid$mtry[i]\n",
        "  ntree_val <- param_grid$ntree[i]\n",
        "  mincriterion_val <- param_grid$mincriterion[i]\n",
        "\n",
        "  cv_accuracy <- numeric(k)\n",
        "  for (j in 1:k) {\n",
        "    # Split into training and validation folds\n",
        "    train_cv <- train[folds != j, ]\n",
        "    val_cv <- train[folds == j, ]\n",
        "\n",
        "    # Train cforest model\n",
        "    model <- cforest(\n",
        "      product ~ .,\n",
        "      data = train_cv,\n",
        "      ntree = ntree_val,\n",
        "      control = ctree_control(\n",
        "        mtry = mtry_val,\n",
        "        teststat = \"quad\",\n",
        "        testtype = \"Univariate\",\n",
        "        mincriterion = mincriterion_val\n",
        "      )\n",
        "    )\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    pred <- predict(model, newdata = val_cv)\n",
        "    cv_accuracy[j] <- mean(pred == val_cv$product)\n",
        "  }\n",
        "\n",
        "  # Store results\n",
        "  results <- rbind(results, data.frame(\n",
        "    mtry = mtry_val,\n",
        "    ntree = ntree_val,\n",
        "    mincriterion = mincriterion_val,\n",
        "    mean_accuracy = mean(cv_accuracy),\n",
        "    sd_accuracy = sd(cv_accuracy)\n",
        "  ))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fbKpzG2y-_J"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Select best parameters\n",
        "best_params <- results[which.max(results$mean_accuracy), ]\n",
        "cat(\"Best Parameters:\\n\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwFZBCi-zECi"
      },
      "outputs": [],
      "source": [
        "# Train final cforest model with best parameters\n",
        "set.seed(seeds)\n",
        "cforest_final <- cforest(\n",
        "  product ~ .,\n",
        "  data = train,\n",
        "  ntree = best_params$ntree,\n",
        "  control = ctree_control(\n",
        "    mtry = best_params$mtry,\n",
        "    teststat = \"quad\",\n",
        "    testtype = \"Univariate\",\n",
        "    mincriterion = best_params$mincriterion\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvQ6gsCjzHP6"
      },
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "test$pred_product <- predict(cforest_final, newdata = test)\n",
        "\n",
        "# Evaluate performance on test set\n",
        "test_accuracy <- mean(test$product == test$pred_product)\n",
        "cat(\"Test Accuracy:\", test_accuracy, \"\\n\")\n",
        "\n",
        "# Confusion matrix\n",
        "confusion <- caret::confusionMatrix(test$pred_product, test$product)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbYzS8pYPGVB"
      },
      "source": [
        "#### Variable Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "x_u70FxvPLSr",
        "outputId": "71784e04-7ac6-48b3-b781-f9ac8c0835c1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%%R\n",
        "# Calculate variable importance\n",
        "var_imp_cforest <- varimp(cforest_final)\n",
        "var_imp_cforest <- sort(var_imp_cforest, decreasing = TRUE) # Sort by importance\n",
        "var_imp_cforest <- data.frame(Variable = names(var_imp_cforest), Importance = var_imp_cforest)\n",
        "# plot variable importance\n",
        "ggplot(var_imp_cforest, aes(x = reorder(Variable, Importance), y = Importance)) +\n",
        "  geom_bar(stat = \"identity\") +\n",
        "  coord_flip() +\n",
        "  labs(title = \"Variable Importance for cforest-Classification\", x = \"Variable\", y = \"Importance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN2wTqH2PTqt"
      },
      "source": [
        "### Regression Example\n",
        "\n",
        "For regression, we will use the {partykit} packages to build a cforest model on the Boston Housing dataset. The dataset contains information about housing prices in Boston based on various features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqooJblKPaDv"
      },
      "source": [
        "#### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq9VcQt7Pbm9",
        "outputId": "15387ac9-98f6-4dce-cef9-fddad0f9e3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'data.frame':\t506 obs. of  14 variables:\n",
            " $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...\n",
            " $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n",
            " $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n",
            " $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n",
            " $ chas   : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n",
            " $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n",
            " $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n",
            " $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...\n",
            " $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n",
            " $ rad    : num  1 2 2 3 3 3 5 5 5 5 ...\n",
            " $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n",
            " $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n",
            " $ black  : num  397 397 393 395 397 ...\n",
            " $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Load data\n",
        "library(MASS)\n",
        "data(\"Boston\")\n",
        "# Create a data frame with selected variables\n",
        "df <- Boston %>%\n",
        "  dplyr::select(medv, crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat)\n",
        "\n",
        "# Convert chas to factor (categorical variable)\n",
        "df$chas <- as.factor(df$chas)\n",
        "\n",
        "# Convert rad and tax to numeric (in case they are integers or factors)\n",
        "df$rad <- as.numeric(df$rad)\n",
        "df$tax <- as.numeric(df$tax)\n",
        "\n",
        "# Verify data types\n",
        "str(df)\n",
        "\n",
        "# Split data into training (70%) and test (30%) sets, stratified by chas\n",
        "seeds <- 11076\n",
        "tr_prop <- 0.70\n",
        "set.seed(seeds)\n",
        "\n",
        "# Stratified sampling for training data\n",
        "train <- ddply(df, .(chas),\n",
        "               function(., seed) { set.seed(seed); .[sample(1:nrow(.), trunc(nrow(.) * tr_prop)), ] },\n",
        "               seed = seeds)\n",
        "test <- ddply(df, .(chas),\n",
        "              function(., seed) { set.seed(seed); .[-sample(1:nrow(.), trunc(nrow(.) * tr_prop)), ] },\n",
        "              seed = seeds)\n",
        "\n",
        "# Scale the numeric features (exclude medv and chas)\n",
        "numeric_cols <- c(\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\", \"dis\", \"rad\", \"tax\", \"ptratio\", \"black\", \"lstat\")\n",
        "train[numeric_cols] <- scale(train[numeric_cols])\n",
        "test[numeric_cols] <- scale(test[numeric_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbVv7GD1PgnP"
      },
      "source": [
        "#### Fit the cforest Model\n",
        "\n",
        "Below R code trains a Conditional Random Forest (cforest) regression model to predict `medv` using the specified features from the train data. Key settings include using conditional inference trees, considering a random subset of features (`mtry`) at each split, and controlling tree growth with `mincriterion`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N059JmapPhQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93958576-5fed-4887-b70f-53faaf3ef420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Length Class      Mode    \n",
            "nodes    500    -none-     list    \n",
            "data      14    data.frame list    \n",
            "weights  500    -none-     list    \n",
            "fitted     2    data.frame list    \n",
            "terms      3    terms      call    \n",
            "info       2    -none-     list    \n",
            "trafo      1    -none-     function\n",
            "predictf   2    terms      call    \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "set.seed(seeds)\n",
        "cforest_model <- cforest(\n",
        "  medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat,\n",
        "  data = train,\n",
        "  control = ctree_control(\n",
        "    mtry = floor(sqrt(12)),  # 12 predictors\n",
        "    teststat = \"quad\",       # Quadratic test statistic\n",
        "    testtype = \"Univariate\", # Univariate test type\n",
        "    mincriterion = 0.95\n",
        "  )\n",
        ")\n",
        "summary(cforest_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTOC7MItPyP_"
      },
      "source": [
        "#### Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ycjSCdPwiM",
        "outputId": "57b2f166-4540-4132-a755-87a44ff9ffe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 4.561332 \n",
            "MAE: 2.814329 \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Make predictions on the test set\n",
        "test$medv.pred <- predict(cforest_model, newdata = test)\n",
        "\n",
        "# Evaluate performance\n",
        "RMSE <- Metrics::rmse(test$medv, test$medv.pred)\n",
        "MAE <- Metrics::mae(test$medv, test$medv.pred)\n",
        "cat(\"RMSE:\", RMSE, \"\\n\")\n",
        "cat(\"MAE:\", MAE, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4wP9ALN2nqS"
      },
      "source": [
        "#### Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vc5OX28D2qLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05dc0623-570d-4140-8801-3d6cea5a8efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation RMSE (mean): 4.288097 \n",
            "Cross-Validation RMSE (std dev): 1.096979 \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Define RMSE function\n",
        "rmse <- function(actual, predicted) sqrt(mean((actual - predicted)^2))\n",
        "\n",
        "# Perform 5-fold cross-validation on training data\n",
        "k <- 5\n",
        "set.seed(seeds)\n",
        "folds <- sample(rep(1:k, length.out = nrow(train)))\n",
        "cv_rmse <- numeric(k)\n",
        "\n",
        "for (j in 1:k) {\n",
        "  # Split into training and validation folds\n",
        "  train_cv <- train[folds != j, ]\n",
        "  val_cv <- train[folds == j, ]\n",
        "\n",
        "  # Train cforest model\n",
        "  model <- cforest(\n",
        "    medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat,\n",
        "    data = train_cv,\n",
        "    ntree = 500,  # Default number of trees\n",
        "    control = ctree_control(\n",
        "      mtry = floor(sqrt(12)),  # 12 predictors\n",
        "      teststat = \"quad\",\n",
        "      testtype = \"Univariate\",\n",
        "      mincriterion = 0.95\n",
        "    )\n",
        "  )\n",
        "\n",
        "  # Predict and calculate RMSE\n",
        "  pred <- predict(model, newdata = val_cv)\n",
        "  cv_rmse[j] <- rmse(val_cv$medv, pred)\n",
        "}\n",
        "\n",
        "# Compute mean and standard deviation of RMSE\n",
        "mean_rmse <- mean(cv_rmse)\n",
        "sd_rmse <- sd(cv_rmse)\n",
        "cat(\"Cross-Validation RMSE (mean):\", mean_rmse, \"\\n\")\n",
        "cat(\"Cross-Validation RMSE (std dev):\", sd_rmse, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bGqNAsJ2wTs"
      },
      "source": [
        "#### Hyperparameter Tuning for cforest\n",
        "\n",
        "To perform hyperparameter tuning for a `cforest` regression model using the provided code and the `{party}` package in R, you need to optimize key parameters such as `mtry` (number of features considered at each split), `ntree` (number of trees), and `mincriterion` (controls tree depth). Below is a concise guide to tune these parameters using a grid search with cross-validation, building on your code.\n",
        "\n",
        "Here below the steps for Hyperparameter Tuning:\n",
        "\n",
        "1.  **Define Parameter Grid**: Create a grid for `mtry`, `ntree`, and `mincriterion`.\n",
        "\n",
        "    -   `mtry`: Test values like `floor(sqrt(11))` (\\~3), 5, 7 (since you have 11 predictors).\n",
        "    -   `ntree`: Test 100, 500, 1000 (balance performance and computation).\n",
        "    -   `mincriterion`: Test 0.90, 0.95, 0.99 (controls tree pruning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VOyfS7Rf2xs_"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Define parameter grid\n",
        "param_grid <- expand.grid(\n",
        "  mtry = c(3, 5, 7),\n",
        "  ntree = 25,  # Reduced for speed; use c(100, 500, 1000) in production\n",
        "  mincriterion = c(0.90, 0.95, 0.99)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzwuHmo32302"
      },
      "source": [
        "2.  **Cross-Validation Setup**: Use k-fold cross-validation (e.g., 5-fold) on the training data to evaluate each parameter combination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "afEaobXe24q-"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Create a data frame with selected variables\n",
        "mf <- Boston %>%\n",
        "  dplyr::select(medv, crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat)\n",
        "\n",
        "# Convert chas to factor for regression\n",
        "mf$chas <- as.factor(mf$chas)\n",
        "\n",
        "# Convert rad and tax to numeric to avoid scaling issues\n",
        "mf$rad <- as.numeric(mf$rad)\n",
        "mf$tax <- as.numeric(mf$tax)\n",
        "\n",
        "# Function to calculate RMSE\n",
        "rmse <- function(actual, predicted) sqrt(mean((actual - predicted)^2))\n",
        "# 5-fold cross-validation\n",
        "k <- 5\n",
        "set.seed(seeds)\n",
        "folds <- sample(rep(1:k, length.out = nrow(train)))\n",
        "results <- data.frame()\n",
        "\n",
        "for (i in 1:nrow(param_grid)) {\n",
        "  mtry_val <- param_grid$mtry[i]\n",
        "  ntree_val <- param_grid$ntree[i]\n",
        "  mincriterion_val <- param_grid$mincriterion[i]\n",
        "\n",
        "  cv_rmse <- numeric(k)\n",
        "  for (j in 1:k) {\n",
        "    # Split into training and validation folds\n",
        "    train_cv <- mf[folds != j, ]\n",
        "    val_cv <- mf[folds, ]\n",
        "\n",
        "    # Train model\n",
        "    model <- cforest(\n",
        "      medv ~ crim+ zn+indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat,\n",
        "      data = train_cv,\n",
        "      ntree = ntree_val,\n",
        "      control = ctree_control(\n",
        "        mtry = mtry_val,\n",
        "        teststat = \"quad\",\n",
        "        testtype = \"Univariate\",\n",
        "        mincriterion = mincriterion_val\n",
        "      )\n",
        "    )\n",
        "\n",
        "    # Predict and calculate RMSE\n",
        "    pred <- predict(model, newdata = val_cv)\n",
        "    cv_rmse[j] <- rmse(val_cv$medv, pred)\n",
        "  }\n",
        "\n",
        "  # Store mean RMSE\n",
        "  results <- rbind(results, data.frame(\n",
        "    mtry = mtry_val,\n",
        "    ntree = ntree_val,\n",
        "    mincriterion = mincriterion_val,\n",
        "    mean_rmse = mean(cv_rmse)\n",
        "  ))\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lV_wq0I29nC"
      },
      "source": [
        "3.  **Select Best Parameters**: Choose the combination with the lowest average RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vfrROxeG2-Vd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7647807-c610-4813-d3fb-c86825c7081c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Best Parameters:\"\n",
            "  mtry ntree mincriterion mean_rmse\n",
            "5    5    25         0.95  2.417408\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Best parameters\n",
        "best_params <- results[which.min(results$mean_rmse), ]\n",
        "print(\"Best Parameters:\")\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUa-Lu8m3DAX"
      },
      "source": [
        "4.  **Train Final Model**: Fit the `cforest` model with the best parameters on the full training data and evaluate on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bvGkGPHS3EKO"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Train final model with best parameters\n",
        "set.seed(seeds)\n",
        "cforest_final <- cforest(\n",
        "  medv ~ crim+ zn+indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat,\n",
        "  data = train,\n",
        "  ntree = best_params$ntree,\n",
        "  control = ctree_control(\n",
        "    mtry = best_params$mtry,\n",
        "    teststat = \"quad\",\n",
        "    testtype = \"Univariate\",\n",
        "    mincriterion = best_params$mincriterion\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XltdQkqz3Ijc"
      },
      "source": [
        "5.  Evaluate Final Model\n",
        "\n",
        "Finally, evaluate the performance of the tuned model on the test set using RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-TCqlPNa3JUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079e9027-91f1-47cc-8ff0-2b7226d7f4dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 4.559371 \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# Make predictions on the test set\n",
        "test$medv.pred <- predict(cforest_final, newdata = test)\n",
        "test_rmse <- rmse(test$medv, test$medv.pred )\n",
        "cat(\"Test RMSE:\", test_rmse, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "KY1-zUWLQA88",
        "outputId": "bcdf63dc-2cd0-40aa-bb53-076c132239ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Loading required package: ggpp\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Registered S3 methods overwritten by 'ggpp':\n",
            "  method                  from   \n",
            "  heightDetails.titleGrob ggplot2\n",
            "  widthDetails.titleGrob  ggplot2\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "Attaching package: ‘ggpp’\n",
            "\n",
            "\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The following object is masked from ‘package:ggplot2’:\n",
            "\n",
            "    annotate\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`geom_smooth()` using formula = 'y ~ x'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%R\n",
        "library(ggpmisc)\n",
        "formula <- y ~ x\n",
        "\n",
        "ggplot(test, aes(medv, medv.pred)) +\n",
        "  geom_point() +\n",
        "  geom_smooth(method = \"lm\") +\n",
        "  stat_poly_eq(use_label(c(\"eq\", \"adj.R2\")), formula = formula) +\n",
        "  ggtitle(\"cforest: Predicted vs Observed medv\") +\n",
        "  xlab(\"Observed medv\") + ylab(\"Predicted medv\") +\n",
        "  scale_x_continuous(limits = c(0, 50), breaks = seq(0, 50, 10)) +\n",
        "  scale_y_continuous(limits = c(0, 50), breaks = seq(0, 50, 10)) +\n",
        "  theme(\n",
        "    panel.background = element_rect(fill = \"grey95\", colour = \"gray75\", size = 0.5, linetype = \"solid\"),\n",
        "    axis.line = element_line(colour = \"grey\"),\n",
        "    plot.title = element_text(size = 14, hjust = 0.5),\n",
        "    axis.title.x = element_text(size = 14),\n",
        "    axis.title.y = element_text(size = 14),\n",
        "    axis.text.x = element_text(size = 13, colour = \"black\"),\n",
        "    axis.text.y = element_text(size = 13, angle = 90, vjust = 0.5, hjust = 0.5, colour = \"black\")\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2SC3iPoQF5p"
      },
      "source": [
        "#### Variable Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jiRIzHrcQGt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "d55bbd1c-197b-4a3a-eb39-83e5f738aba5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%R\n",
        "var_imp_cforest <- varimp(cforest_final)\n",
        "var_imp_cforest <- sort(var_imp_cforest, decreasing = TRUE) # Sort by importance\n",
        "var_imp_cforest <- data.frame(Variable = names(var_imp_cforest), Importance = var_imp_cforest)\n",
        "# plot variable importance\n",
        "ggplot(var_imp_cforest, aes(x = reorder(Variable, Importance), y = Importance)) +\n",
        "  geom_bar(stat = \"identity\") +\n",
        "  coord_flip() +\n",
        "  labs(title = \"Variable Importance for cforest-Regression\", x = \"Variable\", y = \"Importance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j759RVMQMut"
      },
      "source": [
        "## Summary and Conclusion\n",
        "\n",
        "Conditional Random Forest (cforest) is a powerful ensemble learning method that builds on the strengths of traditional Random Forests while addressing some of their limitations. By using conditional inference trees and permutation-based significance tests, cforest provides unbiased variable selection, robust statistical inference, and flexibility in handling various types of response variables. It is particularly useful in scenarios where variable importance and interpretability are crucial. This tutorial demonstrated how to implement cforest in R for both classification and regression tasks, showcasing its capabilities in real-world applications. By leveraging the strengths of cforest, data scientists and statisticians can build more reliable and interpretable models for complex datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaZTnZx3QPGI"
      },
      "source": [
        "## References\n",
        "\n",
        "1.  Hothorn, T., Hornik, K., & Zeileis, A. (2006). Unbiased Recursive Partitioning: A Conditional Inference Framework. *Journal of Computational and Graphical Statistics, 15*(3), 651–674.\n",
        "\n",
        "2.  Strobl, C., Boulesteix, A.-L., Zeileis, A., & Hothorn, T. (2007). Bias in Random Forest Variable Importance Measures: Illustrations, Sources and a Solution. *BMC Bioinformatics, 8*(25).\n",
        "\n",
        "3.  Hothorn, T., & Zeileis, A. (2015). partykit: A Modular Toolkit for Recursive Partytioning in R. *The Journal of Machine Learning Research, 16*(1), 3905–3909.\n",
        "\n",
        "4.  Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2nd ed.). Springer.\n",
        "\n",
        "5.  [partykit R Package Documentation](https://cran.r-project.org/web/packages/partykit/partykit.pdf)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPlAOXaj+NJSpVRCBUFn0Y1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}