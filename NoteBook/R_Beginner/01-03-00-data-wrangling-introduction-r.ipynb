{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/R_Beginner/01-03-00-data-wrangling-introduction-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ComcGnVpY7Lh"
      },
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMmNoBYvZAKg"
      },
      "source": [
        "# Introduction to Data Wrangling\n",
        "\n",
        "**Data Wrangling** is a crucial process in data science that involves transforming and cleaning raw data into a usable format. It involves converting data from one form to another, removing missing or duplicated values, and dealing with outliers. Data wrangling also ensures that data formatting is consistent and accurate, making it reliable for analysis and modeling. This process is vital as it helps researchers to obtain accurate results and make informed decisions based on the data. Data wrangling is significant in environmental data as it helps to build maps and models that can provide valuable insights into environmental conditions. Therefore, it is essential to carry out data wrangling consistently and accurately to ensure the data is reliable and can be used for decision-making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Jp1NVy_eZn"
      },
      "source": [
        "This section provides an overview of data wrangling, its importance, and the steps involved in the process. It also highlights some of the key R packages that can be used for data wrangling tasks.\n",
        "\n",
        "1.  [Data Wrangling with {dplyr} and {tidyr}](https://github.com/zia207/r-colab/blob/main/NoteBook/R_Beginner/01-03-01-data-wrangling-dplyr-r.ipynb)\n",
        "\n",
        "2.  [Data Wrangling with {data.table}](https://github.com/zia207/r-colab/blob/main/NoteBook/R_Beginner/01-03-02-data-wrangling-datatable-r.ipynb)\n",
        "\n",
        "3.  [Data Wrangling with {janitor}](https://github.com/zia207/r-colab/blob/main/NoteBook/R_Beginner/01-03-03-data-wrangling-janitor-r.ipynb)\n",
        "\n",
        "4.  [Data Wrangling with {lubricate}](https://github.com/zia207/r-colab/blob/main/NoteBook/R_Beginner/01-03-03-data-wrangling-lubricate-r.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiOapp4QZLRj"
      },
      "source": [
        "## Why is Data Wrangling Important?\n",
        "\n",
        "\n",
        "Here are some key reasons why data wrangling is essential:\n",
        "\n",
        "1. `Data Quality Improvement`: Raw data often contains errors, missing values, inconsistencies, and outliers. Data wrangling identifies and rectifies these issues to ensure data accuracy and reliability.\n",
        "\n",
        "2. `Compatibility`: Data from various sources may have different formats and structures, making it challenging to analyze. Data wrangling standardizes data from different sources, ensuring the compatibility and consistency necessary for accurate analysis.\n",
        "\n",
        "3. `Handling Missing Values`: Data wrangling provides methods to handle missing data, such as imputation or removal, to prevent it from affecting the analysis.\n",
        "\n",
        "4. `Data Transformation`: Transforming raw data into the right format for analysis can be done through data wrangling, which involves converting data types, aggregating information, and creating new variables.\n",
        "\n",
        "5. `Feature Engineering`: Data wrangling allows for the creation of new variables that can enhance the predictive power of machine learning models.\n",
        "\n",
        "6. `Outlier Detection and Handling`: It is crucial to detect and manage outliers to prevent them from skewing analysis results. Data wrangling offers techniques for identifying and dealing with outliers\n",
        "\n",
        "7. `Data Reduction`: In some cases, data can be massive and unwieldy. Wrangling can involve reduction techniques to make the data more manageable without losing critical information.\n",
        "\n",
        "8. `Improved Efficiency`: Efficient analysis and modeling require wrangled data, which saves time and lowers error risk.\n",
        "\n",
        "9. `Data Exploration`: Data wrangling and exploration are intertwined to gain insight and hypotheses for better analysis.\n",
        "\n",
        "10. `Reproducibility`: A well-documented data wrangling process is essential for collaboration and transparency, allowing others to replicate the same data preparation steps and obtain consistent results.\n",
        "\n",
        "11. `Regulatory Compliance`: In regulated industries like finance and healthcare, data wrangling is crucial to ensure data privacy and comply with data protection laws.\n",
        "\n",
        "12. `Better Decision-Making`: Clean and well-structured data resulting from effective data wrangling leads to more accurate insights, supporting better decision-making in business and research contexts.\n",
        "\n",
        "Data wrangling is a crucial step in the data analysis process that enhances the accuracy, reliability, and usability of data. It has a significant role in converting raw data into a format that is suitable for various data-based tasks such as statistical analysis, machine learning, and business intelligence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0zVM3RsZPNR"
      },
      "source": [
        "## Steps of Data Wrangling\n",
        "\n",
        "Here below [6 steps of data wrangling](https://favtutor.com/blogs/data-wrangling):\n",
        "\n",
        "1.  `Discovering`: systematic wrangling based on some criteria which could restrict and divide the data accordingly.\n",
        "\n",
        "2.  `Structuring`: the raw data should be restructured to suit the analytically method. Feature engineering can be done in this stage,\n",
        "\n",
        "3.  `Cleaning`: outliers and missing values identification, transformation and imputation\n",
        "\n",
        "   -   `Outliers`: Outliers are data points that differ significantly from other observations. They can arise due to variability in the data or may indicate experimental errors. Outliers can skew results and affect the performance of machine learning models.\n",
        "\n",
        "   -   `Missing Values`: Missing values occur when no data value is stored for a variable in an observation. They can arise due to various reasons, such as data entry errors, equipment malfunctions, or survey non-responses. Missing values can lead to biased estimates and reduced statistical power.\n",
        "\n",
        "4.  `Enriching` upscale, downsample, or perform data augmentation.\n",
        "\n",
        "   -   `Upscale`: Upscaling is the process of increasing the resolution or size of an image or video. It can be done using various algorithms, such as nearest neighbor interpolation, bilinear interpolation, and bicubic interpolation.\n",
        "\n",
        "   -   `Downsample`: Downsampling is the process of reducing the resolution or size of an image or video. It can be done using various algorithms, such as nearest neighbor interpolation, bilinear interpolation, and bicubic interpolation.\n",
        "`\n",
        "   -   `Data Augmentation`: Data augmentation is a technique used to increase the diversity of training data without actually collecting new data. It involves applying various transformations to the existing data, such as rotation, translation, scaling, and flipping.\n",
        "\n",
        "5.  `Validating`: validation data after processing.\n",
        "\n",
        "6.  `Publishing`: process for further use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3svawKPZSgM"
      },
      "source": [
        "## Important R Packages for Data Wrangling\n",
        "\n",
        "-   [dplyr](https://dplyr.tidyverse.org/index.html)\n",
        "\n",
        "-   [purr](https://purrr.tidyverse.org/)\n",
        "\n",
        "-   [tidyr](https://tidyr.tidyverse.org/)\n",
        "\n",
        "-   [lubridate](https://lubridate.tidyverse.org/)\n",
        "\n",
        "-   [magrittr](https://magrittr.tidyverse.org/)\n",
        "\n",
        "-   [plyr](http://plyr.had.co.nz/)\n",
        "\n",
        "-   [purrrlyr](https://cran.r-project.org/web/packages/purrrlyr/index.html)\n",
        "\n",
        "-   [data.table](https://rdatatable.gitlab.io/data.table/)\n",
        "\n",
        "-   [sqldf](https://cran.r-project.org/web/packages/sqldf/index.html)\n",
        "\n",
        "-   [dtplyr](https://www.tidyverse.org/blog/2019/11/dtplyr-1-0-0/)\n",
        "\n",
        "-   [DT](https://rstudio.github.io/DT/)\n",
        "\n",
        "-   [janitor](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347xNmAzjgUw"
      },
      "source": [
        "\n",
        "## Books Focused on Data Wrangling in R\n",
        "\n",
        "1. `R for Data Science**  by Hadley Wickham & Garrett Grolemund`\n",
        "- [Free online](https://r4ds.hadley.nz/)\n",
        "- Covers `tidyverse`, `dplyr`, `tidyr`, `readr`\n",
        "- Great intro to data wrangling, visualization, and modeling\n",
        "- Ideal for beginners and intermediate users\n",
        "\n",
        "\n",
        "2. `Data Wrangling with R by Bradley C. Boehmke`\n",
        "- Deep dive into `dplyr`, `tidyr`, `stringr`, `lubridate`, etc.\n",
        "- Practical wrangling scenarios\n",
        "- Very hands-on and code-focused\n",
        "\n",
        "3. `Efficient R Programming by Colin Gillespie & Robin Lovelace*`\n",
        "- Covers performance + code efficiency in data wrangling\n",
        "- Includes parallel processing, profiling, and memory management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JxwHGPojiKe"
      },
      "source": [
        "## General/Language-Agnostic Books on Data Wrangling & Cleaning\n",
        "\n",
        "4. `Data Cleaning: The Ultimate Practical Guide by Lee Baker`  \n",
        "- Language-agnostic; full of strategies and pitfalls to avoid\n",
        "- Great for understanding what “clean data” really means\n",
        "\n",
        "5. `The Art of Data Wrangling by Jason L. Callahan`  \n",
        "- Covers entire process from messy to clean across domains\n",
        "- Good for both data scientists and data engineers\n",
        "\n",
        "8. `Data Science Handbook by Jake VanderPlas`\n",
        "\n",
        "- While broader than just wrangling, it includes detailed sections on data preparation and pipelines\n",
        "- Covers R, Python, and general best practices\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNjPzn8bzWDfS98pAAPGscV",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
