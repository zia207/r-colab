{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/r-colab/blob/main/NoteBook/R_Beginner/01-03-02-data-wrangling-datatable-r.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1bLQ3nhDbZrCCqy_WCxxckOne2lgVvn3l)"
      ],
      "metadata": {
        "id": "ZUpmsgn2YuJM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGoP0AbXEAUx"
      },
      "source": [
        "# Data Wrangling with {data.table}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kroLnhoOPPoV"
      },
      "source": [
        "The [data.table](https://github.com/Rdatatable/data.table) is a powerful and widely used package in the R programming language. It provides an alternative to the default data.frame for handling tabular data. One of the primary reasons for its popularity is its exceptional performance, especially when dealing with large datasets. The package's concise syntax is another benefit of using data.table. It allows for complex data manipulations and transformations with less code, making it a favorite among Data Scientists."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1ok_8au0GAsR6nvk5qpejgcn5beGxdWQ5)\n",
        "\n"
      ],
      "metadata": {
        "id": "dzQoRJiR7DZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "{Data.table} is one of the most downloaded packages in R. It's well-liked by developers and analysts, who consider it one of the best things that has happened to the R programming language in terms of speed. The package's syntax differs somewhat from the regular R data.frame. However, it is quite intuitive once you get the hang of it. This makes it easy to use and understand, and once you learn it, you may never want to revert to using the base R data.frame syntax. In summary, data.table is a powerful, fast, and intuitive package for managing tabular data in R. Its popularity among Data Scientists is a testament to its usefulness and efficiency. With data.table, you can write less code and achieve faster results, making it a go-to package for working with large datasets."
      ],
      "metadata": {
        "id": "4Y7Y4yS57Qj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cheat-sheet\n",
        "\n",
        "Here below data transformation with data.table:"
      ],
      "metadata": {
        "id": "6U9i1T2iFPje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1szXCR7uu55tPT1Z18OLAAg5Ni8Hm_bzU)\n",
        "\n",
        "\n",
        "\n",
        "![alt text](http://drive.google.com/uc?export=view&id=1szhta0Trakk7OKLEeSePWJLtCgniVTX3)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wi3Tc_LQFyaE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdQJ-mgsEU9J"
      },
      "source": [
        "## Install rpy2\n",
        "\n",
        "Easy way to run R in Colab with Python runtime using **rpy2** python package. We have to install this package using the pip command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOD7NpajDy5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7180ddf-46a9-4646-c90e-e91401f4ad0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: rpy2 3.4.2\n",
            "Uninstalling rpy2-3.4.2:\n",
            "  Successfully uninstalled rpy2-3.4.2\n",
            "Collecting rpy2==3.5.1\n",
            "  Downloading rpy2-3.5.1.tar.gz (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (1.16.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (3.1.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (2023.4)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (5.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2==3.5.1) (2.1.5)\n",
            "Building wheels for collected packages: rpy2\n",
            "  Building wheel for rpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpy2: filename=rpy2-3.5.1-cp310-cp310-linux_x86_64.whl size=314935 sha256=e0e4fcc964a64d138ce1054670fad757550664f34675b31f1b2eec8fae50fc93\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/a6/ff/4e75dd1ce1cfa2b9a670cbccf6a1e41c553199e9b25f05d953\n",
            "Successfully built rpy2\n",
            "Installing collected packages: rpy2\n",
            "Successfully installed rpy2-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall rpy2 -y\n",
        "! pip install rpy2==3.5.1\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmEDD0ccEurf"
      },
      "source": [
        "##  Mount Google Drive\n",
        "\n",
        "Then you must create a folder in Goole drive named \"R\" to install all packages permanently. Before installing R-package in Python runtime. You have to mount Google Drive and follow on-screen instruction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lClKZUW1Eu_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0713b57-12ba-4a22-9d9c-06575d4b5b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check and Install Required R Packages"
      ],
      "metadata": {
        "id": "O8mTSRI-GknP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "packages <- c(\n",
        "          'tidyverse',\n",
        "          'data.table'\n",
        ")"
      ],
      "metadata": {
        "id": "JbN1rkO7Gh2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Install missing packages\n",
        "new.packages <- packages[!(packages %in% installed.packages(lib='drive/My Drive/R/')[,\"Package\"])]\n",
        "if(length(new.packages)) install.packages(new.packages, lib='drive/My Drive/R/')\n",
        "\n",
        "# Verify installation\n",
        "cat(\"Installed packages:\\n\")\n",
        "print(sapply(packages, requireNamespace, quietly = TRUE))"
      ],
      "metadata": {
        "id": "fHCSLjC98hNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Packages"
      ],
      "metadata": {
        "id": "DjDmVyITGsDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set library path\n",
        ".libPaths('drive/My Drive/R')\n",
        "# Load packages with suppressed messages\n",
        "invisible(lapply(packages, function(pkg) {\n",
        "  suppressPackageStartupMessages(library(pkg, character.only = TRUE))\n",
        "}))"
      ],
      "metadata": {
        "id": "9Pn9zXgyGsMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Check loaded packages\n",
        "cat(\"Successfully loaded packages:\\n\")\n",
        "print(search()[grepl(\"package:\", search())])"
      ],
      "metadata": {
        "id": "RbmbqqfE9Est"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "In this exercise we will use following CSV files:\n",
        "\n",
        "1.  `usa_division.csv`: USA division names with IDs\n",
        "\n",
        "2.  `usa_state.csv`: USA State names with ID and division ID.\n",
        "\n",
        "3.  `usa_corn_production.csv`:  USA grain crop production by state from 2012-2022\n",
        "\n",
        "\n",
        "All data set use in this exercise can be downloaded from my [Dropbox](https://www.dropbox.com/scl/fo/fohioij7h503duitpl040/h?rlkey=3voumajiklwhgqw75fe8kby3o&dl=0) or from my [Github](https://github.com/zia207/r-colab/tree/main/Data/R_Beginners) accounts.\n",
        "\n"
      ],
      "metadata": {
        "id": "pcn48RSJ2Xnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Data\n",
        "\n",
        "We will use `fread()` function of **data.table** package to import data as a **tidy** data. When it comes to working with **data.tables**, it's important to realize that the process is different from working with **data.frames**. Before diving in and using this package, it's essential to understand the differences between the two. One of the most useful functions of data.table is `fread()`, which is a faster and more efficient version of `read.csv()`. It's worth noting that `fread()` can work with local files on your computer, as well as files hosted on the internet. In fact, it's been shown to be at least 20 times faster than `read.csv()`, which can be a huge advantage when dealing with large datasets. This dataset is stored as a csv file and can be easily imported using `fread()`. By using this function, you'll be able to import the data quickly and efficiently into your R environment.\n",
        "*italicized text*"
      ],
      "metadata": {
        "id": "WuwRh_91IxVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "div.dt<-fread(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/usa_division.csv\")\n",
        "state.dt<-fread(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/usa_state.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKhJzcrC0lGY",
        "outputId": "36bc878b-c972-4f7c-fff0-2e4b6bce28fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \r [100%] Downloaded 142 bytes...\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n",
            " [100%] Downloaded 495 bytes...\n",
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "class(div.dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJZEOdy4SCD8",
        "outputId": "cde2f227-d8d5-48f2-930c-b5521c167650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"data.table\" \"data.frame\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert data.frame to data.table\n",
        "\n",
        "When data is imported, it can be stored in various formats. In this case, the data is stored as a data.table. It is worth noting that a `data.table` is a type of data structure that inherits from the data.frame class. This means that the data.table itself can be considered a data.frame. By default, `data.tables` have some unique features that make them efficient when working with large datasets. For example, they have optimized memory usage and fast operations for querying and processing data.\n"
      ],
      "metadata": {
        "id": "dLqzx4c4SK_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.df<-read_csv(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/usa_corn_production.csv\")\n",
        "class(corn.df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prXlGvelSLqr",
        "outputId": "fff55019-f98c-4f5d-f113-d4258420661d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 465 Columns: 3\n",
            "── Column specification ────────────────────────────────────────────────────────\n",
            "Delimiter: \",\"\n",
            "dbl (3): STATE_ID, YEAR, MT\n",
            "\n",
            "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
            "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
            "[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You can use `as.data.table()` or `setDT()` to convert data.frame to data.table:"
      ],
      "metadata": {
        "id": "9i47xaL0q6_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.dt<-as.data.table(corn.df)\n",
        "# Alternately, use setDT() to convert it to data.table in place.\n",
        "corn.dt<-setDT(corn.df)\n",
        "class(corn.dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl7MrY8DStsI",
        "outputId": "3b0f3fb1-b16b-436b-bd0f-82008b8d45af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"data.table\" \"data.frame\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important: The data.table() does not have any rownames. So if the data.frame has any rownames, you need to store it as a separate column before converting to data.table.\n",
        "\n",
        "Conversely, use `as.data.frame(dt)` or `setDF(dt) `to convert a data.table to a data.frame\n",
        "\n"
      ],
      "metadata": {
        "id": "Cd6Apd28Szce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Join\n",
        "\n",
        "The data.table package  offers a faster and more efficient implementation of the `merge()` function. It is designed to handle large datasets with ease, making it ideal for big data management and analysis. With data.table, you can merge two or more datasets based on common columns and perform operations like filtering, sorting, and aggregating on the merged data. The syntax of data.table's `merge()` function is quite similar to base R's `merge()`, making it easy to learn and use for anyone familiar with the latter. Data analysts and data scientists can use data.table to speed up their data manipulation tasks and save time on their projects.\n",
        "\n",
        "We will join state, division and USA corn production data one by one e using `merge()` function with  `all=T` argument:\n"
      ],
      "metadata": {
        "id": "TUVQPkZtLMb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn_state = merge(state.dt, corn.dt, by='STATE_ID', all = T) |>\n",
        "             glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ7YEMR2J2wO",
        "outputId": "4c55f873-634f-4a52-f86e-9501eda8d6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 465\n",
            "Columns: 5\n",
            "$ STATE_ID    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n",
            "$ STATE_NAME  <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Al…\n",
            "$ DIVISION_ID <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n",
            "$ YEAR        <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021…\n",
            "$ MT          <dbl> 734352.8, 1101529.2, 1151061.8, 914829.3, 960170.7, 996875…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn_state_div = merge(corn_state, div.dt, by='DIVISION_ID', all = T) |>\n",
        "             glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKa9GOAGOHcQ",
        "outputId": "26c27206-fe55-4574-fa02-40d26cddb4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 465\n",
            "Columns: 6\n",
            "$ DIVISION_ID   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n",
            "$ STATE_ID      <int> 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, …\n",
            "$ STATE_NAME    <chr> \"Illinois\", \"Illinois\", \"Illinois\", \"Illinois\", \"Illinoi…\n",
            "$ YEAR          <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 20…\n",
            "$ MT            <dbl> 32672475, 53352977, 59693152, 51120199, 57296535, 559070…\n",
            "$ DIVISION_NAME <chr> \"East North Central\", \"East North Central\", \"East North …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can run multiple `merge()` functions in a series with pipe `%>%` or `| >` operator:"
      ],
      "metadata": {
        "id": "y-G3MprPO1o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.usa = merge(state.dt, corn.dt, by='STATE_ID', all = T)  |>\n",
        "          merge(div.dt, by='DIVISION_ID', all = T)  |>\n",
        "          glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "935NyNNYO2pN",
        "outputId": "11c02849-e3a9-40a6-93c2-e9bfdadec426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 465\n",
            "Columns: 6\n",
            "$ DIVISION_ID   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n",
            "$ STATE_ID      <int> 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, …\n",
            "$ STATE_NAME    <chr> \"Illinois\", \"Illinois\", \"Illinois\", \"Illinois\", \"Illinoi…\n",
            "$ YEAR          <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 20…\n",
            "$ MT            <dbl> 32672475, 53352977, 59693152, 51120199, 57296535, 559070…\n",
            "$ DIVISION_NAME <chr> \"East North Central\", \"East North Central\", \"East North …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We merge multiple data.table with a custom `merge()` and `Reduce()` functions  to repeatedly merge multiple data.tables stored in a list."
      ],
      "metadata": {
        "id": "PL1eZcMbXhPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# read four files\n",
        "fips<-fread(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/LBC_Data_ID.csv\")\n",
        "rate<-fread(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/LBC_Data_Rate.csv\")\n",
        "smoking<-fread(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/LBC_Data_Smoking.csv\")\n",
        "pm25<-fread(\"https://github.com/zia207/r-colab/raw/main/Data/R_Beginners/LBC_Data_PM25.csv\")"
      ],
      "metadata": {
        "id": "Aaz2PMaXXh4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# create a list\n",
        "dt_list    <- list(fips, rate, smoking, pm25)\n",
        "# merge function\n",
        "merge_func <- function(...) merge(..., all = TRUE, by='FIPS')\n",
        "#  use Reduce() merge all dt together\n",
        "LBC.usa  <- Reduce(merge_func, dt_list) |>\n",
        "            glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjOKU0SxXsf_",
        "outputId": "25b29e86-aa43-4dd7-fd22-225f8480f0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 3,152\n",
            "Columns: 9\n",
            "$ FIPS      <int> 1001, 1003, 1005, 1007, 1009, 1011, 1013, 1013, 1013, 1013, …\n",
            "$ REGION_ID <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n",
            "$ STATE     <chr> \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alabama\", \"Alab…\n",
            "$ County    <chr> \"Autauga County\", \"Baldwin County\", \"Barbour County\", \"Bibb …\n",
            "$ X         <dbl> 872679.2, 789777.5, 997211.0, 822862.5, 863725.2, 964066.8, …\n",
            "$ Y         <dbl> 1094433.0, 884557.1, 1033023.8, 1141553.6, 1255735.2, 105519…\n",
            "$ LBC_Rate  <dbl> 54.2, 48.1, 48.9, 54.2, 55.2, 66.6, 38.3, 38.3, 38.3, 38.3, …\n",
            "$ Smoking   <dbl> 22.4, 20.8, 24.7, 26.1, 24.1, 25.3, 26.0, 26.0, 26.0, 26.0, …\n",
            "$ PM25      <dbl> 9.20, 7.89, 8.58, 9.28, 9.08, 8.79, 8.46, 8.46, 8.46, 8.46, …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relocate or column reordering\n",
        "\n",
        "In data.table, all `set()` functions change their input by reference. That is, no copy is made at all, other than temporary working memory which is as large as one column. The only other data.table operator that modifies input by reference is :=.\n",
        "\n",
        "Now we will organize DIVISION_FIPS, DIVISION_NAME, STATE_FIPS, STATE_NAME, DIVISION_NAME, YEAR, MT with `setcolorder()` function."
      ],
      "metadata": {
        "id": "FWX9PhEuRy9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.usa<-setcolorder(corn.usa,\n",
        "                        c(\"DIVISION_ID\",\n",
        "                          \"DIVISION_NAME\",\n",
        "                          \"STATE_ID\",\n",
        "                          \"STATE_NAME\",\n",
        "                          \"YEAR\",\n",
        "                          \"MT\"))\n",
        "head(corn.usa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZj-VPQURzfz",
        "outputId": "a95ec8fb-7163-4b05-d1d7-e8cb98f08e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   DIVISION_ID      DIVISION_NAME STATE_ID STATE_NAME YEAR       MT\n",
            "1:           1 East North Central       17   Illinois 2012 32672475\n",
            "2:           1 East North Central       17   Illinois 2013 53352977\n",
            "3:           1 East North Central       17   Illinois 2014 59693152\n",
            "4:           1 East North Central       17   Illinois 2015 51120199\n",
            "5:           1 East North Central       17   Illinois 2016 57296535\n",
            "6:           1 East North Central       17   Illinois 2017 55907082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOk85Ol6GQfH"
      },
      "source": [
        "### Rename\n",
        "\n",
        "`setnames()` operates on data.table and data.frame not other types like list and vector. It can be used to change names by name with built-in checks and warnings\n",
        "\n",
        "\n",
        "We will rename STAT_ID to SATE_FIPS.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXfSYaGPGpbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01474a30-bdae-4716-c61a-523aaef176ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"DIVISION_ID\"   \"DIVISION_NAME\" \"STATE_FIPS\"    \"STATE_NAME\"   \n",
            "[5] \"YEAR\"          \"MT\"           \n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "setnames(corn.usa, \"STATE_ID\", \"STATE_FIPS\")\n",
        "names(corn.usa)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select (Select column(s) in j)\n",
        "\n",
        "In data.table, the `j` argument within square brackets (`[ ]`) is used to select columns. This argument allows you to specify the columns that you want to select from your dataset. You can select columns by either their names or indices. If you want to select columns by their names, you can simply specify the column names within the square brackets, separated by commas.\n",
        "\n",
        "Following code select STATE_NAME column, but return it as a vector.\n",
        "\n"
      ],
      "metadata": {
        "id": "M-Q9xWCLit23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.state <- corn.usa[,STATE_NAME]\n",
        "head(corn.state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBXiV8FK9zHJ",
        "outputId": "3d85d61a-aaf6-43cb-d0b3-d17f3ebdd340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Illinois\" \"Illinois\" \"Illinois\" \"Illinois\" \"Illinois\" \"Illinois\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code select STATE_NAME column, but return  but return as a data.table instead."
      ],
      "metadata": {
        "id": "C_AdKJYqoMSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.state <- corn.usa[,list(STATE_NAME)]\n",
        "head(corn.state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFUJaELqoNBY",
        "outputId": "1d665c68-0107-4aa1-fe92-a96b9ee1e987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   STATE_NAME\n",
            "1:   Illinois\n",
            "2:   Illinois\n",
            "3:   Illinois\n",
            "4:   Illinois\n",
            "5:   Illinois\n",
            "6:   Illinois\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data.table also allows wrapping columns with `.()` instead of `list()`. It is an alias to `list()`; they both mean the same."
      ],
      "metadata": {
        "id": "l8WLHNoloR3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.state <- corn.usa[,list(STATE_NAME, YEAR, MT)]\n",
        "## alternatively\n",
        "corn.state <- corn.usa[,.(STATE_NAME, YEAR, MT)]\n",
        "head(corn.state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYtZdMSboRul",
        "outputId": "aad17f46-0d15-4b0a-b787-d72b9784b163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   STATE_NAME YEAR       MT\n",
            "1:   Illinois 2012 32672475\n",
            "2:   Illinois 2013 53352977\n",
            "3:   Illinois 2014 59693152\n",
            "4:   Illinois 2015 51120199\n",
            "5:   Illinois 2016 57296535\n",
            "6:   Illinois 2017 55907082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter or Subset rows in i\n",
        "\n",
        "Filtering a data.table in R is a powerful and flexible operation that allows you to extract subsets of data based on specific conditions. The **i** argument within square brackets is used to specify these conditions. The conditions can involve one or more columns in the data.table and can be combined using logical operators such as `&, |`, and `!`. For example, you can filter a data.table to extract only the rows where a particular column meets a certain criterion, or where two or more columns satisfy a complex condition. Additionally, you can use the `.SD` variable to refer to the subset of data.table that matches the filtering criteria. This enables you to perform further operations on the filtered data, such as summarization or aggregation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1jX5VaKM0MMV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lm8_XGaG8Il",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3146dbea-1457-43c7-dacf-bc7891e06369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Illinois\"  \"Indiana\"   \"Michigan\"  \"Ohio\"      \"Wisconsin\"\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "df.01<-corn.usa[DIVISION_NAME == \"East North Central\",]\n",
        "levels(as.factor(df.01$STATE_NAME))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering by multiple criteria within a single logical expression - select data from East North Central, South Central and Middle Atlantic Division"
      ],
      "metadata": {
        "id": "d35_rXRfjFxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.02<- corn.usa[DIVISION_NAME %in%c(\"East North Central\",\n",
        "                                     \"East South Central\",\n",
        "                                     \"Middle Atlantic\"),]\n",
        "levels(as.factor(df.02$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6LcSJkfytdz",
        "outputId": "71984ca1-5bfc-4ae6-aac3-f943af6349c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1] \"Alabama\"      \"Illinois\"     \"Indiana\"      \"Kentucky\"     \"Michigan\"    \n",
            " [6] \"Mississippi\"  \"New Jersey\"   \"New York\"     \"Ohio\"         \"Pennsylvania\"\n",
            "[11] \"Tennessee\"    \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or we can use `|` which represents `OR` in the logical condition, any of the two conditions."
      ],
      "metadata": {
        "id": "SqJQoPMbC4sA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.03<- corn.usa [DIVISION_NAME == \"East North Central\" | DIVISION_NAME == \"Middle Atlantic\",]\n",
        "levels(as.factor(df.03$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK9Hjeb0zLcH",
        "outputId": "f1b89de6-7d1c-4876-99c7-b9b2f1b64ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Illinois\"     \"Indiana\"      \"Michigan\"     \"New Jersey\"   \"New York\"    \n",
            "[6] \"Ohio\"         \"Pennsylvania\" \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following filter create a files for the Middle Atlantic Division only with New York state."
      ],
      "metadata": {
        "id": "yW9YgYly0LXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "df.ny<-corn.usa[DIVISION_NAME == \"Middle Atlantic\" & STATE_NAME == \"New York\",]\n",
        "head(df.ny)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OOhwWP40Loc",
        "outputId": "6879e19b-6ccf-4587-d71a-0fd25387cd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   DIVISION_ID   DIVISION_NAME STATE_FIPS STATE_NAME YEAR      MT\n",
            "1:           3 Middle Atlantic         36   New York 2012 2314570\n",
            "2:           3 Middle Atlantic         36   New York 2013 2401189\n",
            "3:           3 Middle Atlantic         36   New York 2014 2556391\n",
            "4:           3 Middle Atlantic         36   New York 2015 2143111\n",
            "5:           3 Middle Atlantic         36   New York 2016 1867761\n",
            "6:           3 Middle Atlantic         36   New York 2017 1983464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following filters will select State where corn production (MT) is greater than the global average of production"
      ],
      "metadata": {
        "id": "nfFxl4_t0Tzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mean.prod <- corn.usa[MT > mean(MT, na.rm = TRUE),]\n",
        "levels(as.factor(mean.prod$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvEB5Hfj0UcJ",
        "outputId": "5f83233b-ebe1-4b01-b441-f1705f43317a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1] \"Illinois\"     \"Indiana\"      \"Iowa\"         \"Kansas\"       \"Michigan\"    \n",
            " [6] \"Minnesota\"    \"Missouri\"     \"Nebraska\"     \"North Dakota\" \"Ohio\"        \n",
            "[11] \"South Dakota\" \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use will `&` in the following filters to select states or rows where MT is greater than the global average of for the year 2017"
      ],
      "metadata": {
        "id": "O1hHSzbp0dns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "mean.prod.2017 <- corn.usa[MT > mean(MT, na.rm = TRUE) & YEAR ==2017,]\n",
        "levels(as.factor(mean.prod.2017$STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee_erSje0ek_",
        "outputId": "2a55849f-bc39-4f35-aeef-2e6c69b4aa43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [1] \"Illinois\"     \"Indiana\"      \"Iowa\"         \"Kansas\"       \"Minnesota\"   \n",
            " [6] \"Missouri\"     \"Nebraska\"     \"North Dakota\" \"Ohio\"         \"South Dakota\"\n",
            "[11] \"Wisconsin\"   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following command will select counties starting with \"A\". filter() with `grepl()` is used to search for pattern matching."
      ],
      "metadata": {
        "id": "s9GrOCBW0kBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "state.a <- corn.usa[grepl(\"^A\", STATE_NAME),]\n",
        "levels(as.factor(state.a $STATE_NAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmoaywlx0kIq",
        "outputId": "5b29e896-078c-4e04-b8b2-58cbdbfa1996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Alabama\"  \"Arizona\"  \"Arkansas\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarize\n",
        "\n",
        "Data.table is a powerful package in R that offers an efficient and fast way to perform operations on large datasets. One of its main features is the ability to summarize data using various functions such as `sum()`, `mean()`, `count()`, and many others. To use these functions, you simply need to enclose them within square brackets `([ ])`. This will allow you to summarize the data based on certain criteria or conditions, and quickly retrieve important information such as the total sum, average, or count of a specific column or group of columns. By utilizing data.table, you can easily analyze your data in a more efficient and streamlined manner.\n"
      ],
      "metadata": {
        "id": "XugoFtb7jy5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKU4UEAtHTHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352e05df-b33b-45ce-a117-84a1c1762410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 2072749\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# mean\n",
        "corn.usa[,mean(MT)]\n",
        "# median\n",
        "corn.usa[,median(MT)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiple variables:\n",
        "\n",
        "In data.table, you can calculate the mean of multiple columns by specifying them within the `j` argument and using the `lapply()` function to apply the `mean()` function across those columns. Here's an example:"
      ],
      "metadata": {
        "id": "PA_POhKSj_ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "LBC.usa[, lapply(.SD, mean), .SDcols = c(\"LBC_Rate\", \"Smoking\", \"PM25\")]"
      ],
      "metadata": {
        "id": "d7aVcx1wkxXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8252a17-844c-45aa-d405-e2f4148e6afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   LBC_Rate  Smoking     PM25\n",
            "1: 47.17349 21.47538 7.132129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, `.SD` refers to the Subset of Data and `.SDcols` specifies the columns on which the operation needs to be performed (in this case, columns \"LBC_Rate\", \"Smoking\", \"PM25\"). The `lapply()` function applies the mean() function across these selected columns to calculate their mean\n",
        "\n",
        "You can compute both the mean and standard deviation of multiple columns simultaneously within a data.table in R."
      ],
      "metadata": {
        "id": "ifAPPmS81l4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "summary_stats <- LBC.usa[, lapply(.SD,\n",
        "                           function(x) c(mean = mean(x), sd = sd(x))),\n",
        "                           .SDcols = c(\"LBC_Rate\", \"Smoking\", \"PM25\")]\n",
        "summary_stats"
      ],
      "metadata": {
        "id": "uBiwbThVlOE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde05c1d-a2e8-46e2-d247-18755727dbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   LBC_Rate   Smoking     PM25\n",
            "1: 47.17349 21.475381 7.132129\n",
            "2: 13.46195  3.292703 1.761107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Group by\n",
        "\n",
        "In data.table, you can use the `by` argument to group your data based on one or more columns, and then calculate summary statistics for each group. This is useful when you want to perform calculations on subsets of your data. For example, you can group your data by a categorical variable, such as gender or age group, and then calculate the `mean`, `standard deviation`, `count`, or other summary statistics for each group. The resulting data table will have one row for each group, with the summary statistics calculated for that group. This allows you to quickly compare different groups and identify any patterns or trends in your data.\n",
        "\n",
        "We can calculate mean and SD of LBC rate by regions:"
      ],
      "metadata": {
        "id": "DQMVgQZwoWkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Calculate mean grouped by 'Region_ID'\n",
        "mean.lbc<-LBC.usa[, lapply(.SD, mean), .SDcols = c(\"LBC_Rate\", \"Smoking\", \"PM25\"), by = REGION_ID]\n",
        "# Calculate mean grouped by 'Region_ID'\n",
        "sd.lbc<-LBC.usa[, lapply(.SD, sd), .SDcols = c(\"LBC_Rate\", \"Smoking\", \"PM25\"), by = REGION_ID]\n",
        "mean.lbc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "150ABc5I2GUi",
        "outputId": "7365c3a7-6c4c-46c1-c9a9-47bd1782eae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   REGION_ID LBC_Rate  Smoking     PM25\n",
            "1:         3 52.23064 22.74744 7.766694\n",
            "2:         4 33.48258 18.62512 4.364589\n",
            "3:         1 42.96590 19.65945 7.215853\n",
            "4:         2 46.37865 21.19829 7.318738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also calculate  statistics of multiple variables using following code:"
      ],
      "metadata": {
        "id": "C9rhWSN1XYI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "LBC.usa[, lapply(.SD,\n",
        "                     function(x) c(mean = mean(x), sd = sd(x))),\n",
        "                      .SDcols = c(\"LBC_Rate\", \"Smoking\", \"PM25\"),   by = REGION_ID]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UxGnCLoXY1E",
        "outputId": "41dc9479-a6cd-4737-9b2c-a4da87b8230a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   REGION_ID  LBC_Rate   Smoking     PM25\n",
            "1:         3 52.230641 22.747444 7.766694\n",
            "2:         3 13.780368  3.199699 1.031159\n",
            "3:         4 33.482585 18.625121 4.364589\n",
            "4:         4  9.901008  3.063832 1.147293\n",
            "5:         1 42.965899 19.659447 7.215853\n",
            "6:         1  7.758635  2.244585 1.435032\n",
            "7:         2 46.378653 21.198292 7.318738\n",
            "8:         2 10.654334  2.696246 1.803687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can calculate summary statistics by group using following code:"
      ],
      "metadata": {
        "id": "09lNZswWXfX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        " LBC.usa[, as.list(summary(LBC_Rate)), by = REGION_ID]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81-dP2ykXiPO",
        "outputId": "689e73cc-fb5a-4789-9dd7-d462785797f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   REGION_ID  Min. 1st Qu. Median     Mean 3rd Qu.  Max.\n",
            "1:         3 13.96 43.1500 51.300 52.23064   59.65 134.7\n",
            "2:         4 10.10 26.4850 33.235 33.48258   39.80  67.1\n",
            "3:         1 25.20 37.7000 43.700 42.96590   48.00  69.7\n",
            "4:         2 18.90 38.2925 45.400 46.37865   52.90  93.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a new column\n",
        "\n",
        "One of the key features of data.table is the ability to create a new column by assigning values to it within the square brackets. This can be done using the **`:=`** operator, which allows you to assign a value to a column by reference.\n",
        "\n"
      ],
      "metadata": {
        "id": "LoHVxqxLz9UZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise we will create a new column (MT_1000) in df.corn dataframe dividing MT column by 1000"
      ],
      "metadata": {
        "id": "AHdP2wLs3jWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "corn.usa[, MT_1000 := MT / 10000] |>\n",
        "    glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh615aRi0Ev4",
        "outputId": "3f5df555-0f13-48bc-b393-dddf3cc3ed02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 465\n",
            "Columns: 7\n",
            "$ DIVISION_ID   <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n",
            "$ DIVISION_NAME <chr> \"East North Central\", \"East North Central\", \"East North …\n",
            "$ STATE_FIPS    <int> 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, …\n",
            "$ STATE_NAME    <chr> \"Illinois\", \"Illinois\", \"Illinois\", \"Illinois\", \"Illinoi…\n",
            "$ YEAR          <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 20…\n",
            "$ MT            <dbl> 32672475, 53352977, 59693152, 51120199, 57296535, 559070…\n",
            "$ MT_1000       <dbl> 3267.2475, 5335.2977, 5969.3152, 5112.0199, 5729.6535, 5…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pivoting Data-frame\n",
        "\n",
        "In R, there are several packages that provide functions for pivoting data frames. The reshape2 package offers `melt()` and `cast()` functions that make it easy to reshape data. The tidyr package provides `gather()` and `spread()` functions that are useful for reshaping data from wide to long or vice versa.\n",
        "\n",
        "Finally, the data.table package provides the `dcast()` and `melt()` function that can be used to pivot data frames in a more efficient way, especially for large data sets. To perform pivoting, you need to specify the variables that will be used as rows, columns, and values. The rows variable will be the key variable that you use to group the data. The columns variable will be used to generate new columns in the output, and the values variable will be used to populate the cells in the output. Overall, pivoting a data frame is an essential skill for data analysts and scientists, and R provides powerful tools to make this transformation easy and efficient.\n"
      ],
      "metadata": {
        "id": "iHCT14aE5nmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will drop  data of several states:"
      ],
      "metadata": {
        "id": "HQ4JUN_QYrMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Drop state where reporting years less than 11\n",
        "state_list <- c(\"Connecticut\",\n",
        "                \"Maine\",\n",
        "                \"Massachusetts\",\n",
        "                \"Nevada\",\n",
        "                \"New Hampshire\",\n",
        "                \"Rhode Island\",\n",
        "                \"Vermont\")\n",
        "\n",
        "slected_state<-corn.usa[!STATE_NAME %in% state_list]\n",
        "head(slected_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du6qn4dBYtel",
        "outputId": "101de447-46bd-4407-84a9-30f78985d969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   DIVISION_ID      DIVISION_NAME STATE_FIPS STATE_NAME YEAR       MT  MT_1000\n",
            "1:           1 East North Central         17   Illinois 2012 32672475 3267.248\n",
            "2:           1 East North Central         17   Illinois 2013 53352977 5335.298\n",
            "3:           1 East North Central         17   Illinois 2014 59693152 5969.315\n",
            "4:           1 East North Central         17   Illinois 2015 51120199 5112.020\n",
            "5:           1 East North Central         17   Illinois 2016 57296535 5729.654\n",
            "6:           1 East North Central         17   Illinois 2017 55907082 5590.708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pivot wider\n",
        "\n",
        "The `dcast()` function is a highly efficient data reshaping tool provided by the data.table package. It is used for converting long-form data into wide-form data, and it can handle very large data sets with ease.\n",
        "\n",
        "One of the main advantages of using `dcast()` is its speed and memory efficiency due to its optimized algorithms, the function is capable of handling large data sets in RAM without slowing down or causing memory issues. This makes it an excellent choice for data analysts and scientists who work with large-scale data.\n",
        "\n",
        "Another advantage of `dcast()` is its ability to handle multiple value.var columns. This means that users can easily cast multiple columns of their dataset simultaneously, without having to perform multiple reshaping operations. Furthermore, the function supports multiple functions to fun.aggregate, which allows users to compute multiple summary statistics on their data at once.\n",
        "\n",
        "Overall, `dcast()` is a powerful and efficient tool that can greatly simplify the data reshaping process for users working with large and complex data sets.\n"
      ],
      "metadata": {
        "id": "rMasbZzkG4k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "slected_state  |>  dcast(YEAR ~ STATE_NAME,\n",
        "             value.var = \"MT\") |>\n",
        "glimpse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjFh0Wg-5nZg",
        "outputId": "4b5c6fbf-1770-4955-caec-2b3d9950cb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 11\n",
            "Columns: 42\n",
            "$ YEAR             <dbl> 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020,…\n",
            "$ Alabama          <dbl> 734352.8, 1101529.2, 1151061.8, 914829.3, 960170.7, 9…\n",
            "$ Arizona          <dbl> 158504.4, 229297.9, 149359.9, 192034.1, 273064.4, 158…\n",
            "$ Arkansas         <dbl> 3142400, 4110445, 2517527, 2045951, 3236004, 2765825,…\n",
            "$ California       <dbl> 823003.5, 873298.1, 398166.0, 239280.6, 469924.8, 339…\n",
            "$ Colorado         <dbl> 3412162, 3261024, 3745682, 3426641, 4071581, 4722109,…\n",
            "$ Delaware         <dbl> 610394.2, 733692.3, 853485.1, 799837.4, 708189.4, 820…\n",
            "$ Florida          <dbl> 116846.2, 263513.5, 137167.2, 179079.5, 147327.8, 151…\n",
            "$ Georgia          <dbl> 1417395, 2067034, 1338651, 1237934, 1425015, 1095306,…\n",
            "$ Idaho            <dbl> 668690.3, 528728.9, 406421.5, 368065.4, 477545.2, 592…\n",
            "$ Illinois         <dbl> 32672475, 53352977, 59693152, 51120199, 57296535, 559…\n",
            "$ Indiana          <dbl> 15163839, 26211898, 27554359, 20879902, 24037543, 237…\n",
            "$ Iowa             <dbl> 47675777, 54363950, 60135135, 63645600, 69612376, 661…\n",
            "$ Kansas           <dbl> 9531853, 12802276, 14382239, 14736842, 17746393, 1743…\n",
            "$ Kentucky         <dbl> 2642756, 6175066, 5739179, 5723430, 5654339, 5516155,…\n",
            "$ Louisiana        <dbl> 2329049, 2944270, 1812894, 1694015, 2305172, 2290185,…\n",
            "$ Maryland         <dbl> 1348049, 1685633, 1911451, 1583012, 1544402, 1834993,…\n",
            "$ Michigan         <dbl> 7980085, 8779974, 9038051, 8518086, 8135542, 7633357,…\n",
            "$ Minnesota        <dbl> 34912873, 32875940, 29917700, 36293436, 39219671, 375…\n",
            "$ Mississippi      <dbl> 3332021, 3710628, 2279135, 2178165, 3035968, 2400427,…\n",
            "$ Missouri         <dbl> 6286832, 11054664, 15969315, 11109531, 14491465, 1403…\n",
            "$ Montana          <dbl> 158504.4, 219086.6, 190510.1, 139707.4, 139707.4, 115…\n",
            "$ Nebraska         <dbl> 32823613, 40996495, 40694219, 42998120, 43179740, 427…\n",
            "$ `New Jersey`     <dbl> 257772.8, 282462.9, 315052.8, 268847.8, 261506.8, 296…\n",
            "$ `New Mexico`     <dbl> 185683.8, 183397.7, 237756.6, 182889.7, 156218.3, 146…\n",
            "$ `New York`       <dbl> 2314570, 2401189, 2556391, 2143111, 1867761, 1983464,…\n",
            "$ `North Carolina` <dbl> 2437005, 3102012, 2615322, 2095357, 3080167, 3029872,…\n",
            "$ `North Dakota`   <dbl> 10722414, 10058931, 7968909, 8323512, 13123857, 11404…\n",
            "$ Ohio             <dbl> 11125787, 16530177, 15557814, 12669681, 13328084, 141…\n",
            "$ Oklahoma         <dbl> 824273.5, 1141790.3, 1082859.2, 917496.4, 1075746.8, …\n",
            "$ Oregon           <dbl> 270778.3, 171916.3, 188223.9, 143263.6, 227850.0, 236…\n",
            "$ Pennsylvania     <dbl> 3327576, 4042369, 4029161, 3509957, 3112934, 3762447,…\n",
            "$ `South Carolina` <dbl> 960678.7, 1097719.0, 832147.9, 614204.4, 1129089.6, 1…\n",
            "$ `South Dakota`   <dbl> 13597338, 20392705, 20000000, 20315231, 20979730, 187…\n",
            "$ Tennessee        <dbl> 2072749, 3209714, 3584637, 2966877, 3183550, 3083977,…\n",
            "$ Texas            <dbl> 5078998, 6736436, 7481203, 6755487, 8226224, 7965861,…\n",
            "$ Utah             <dbl> 144228.8, 133865.1, 113798.0, 74705.3, 128911.8, 8941…\n",
            "$ Virginia         <dbl> 915718.4, 1408250.4, 1289118.1, 1226884.8, 1278195.5,…\n",
            "$ Washington       <dbl> 628048.2, 573435.3, 600741.7, 409596.6, 507391.8, 457…\n",
            "$ `West Virginia`  <dbl> 113798.0, 134423.9, 136252.8, 131579.0, 128911.8, 127…\n",
            "$ Wisconsin        <dbl> 10058931, 11160079, 12323715, 12497460, 14559033, 129…\n",
            "$ Wyoming          <dbl> 216419.4, 216140.0, 210323.1, 238290.0, 257645.8, 248…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dcast()` function supports multiple functions to `fun.aggregate`, which allows users to compute multiple summary statistics on their data at once."
      ],
      "metadata": {
        "id": "b__RJ2tiZLRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "dt.wider<-dcast(slected_state,\n",
        "                YEAR ~ DIVISION_NAME,\n",
        "                fun.aggregate = mean,\n",
        "                value.var = 'MT')\n",
        "head(dt.wider)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOfmvlGpZLY7",
        "outputId": "dc8304d2-f8d0-49ae-879e-0bbd4b00f886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   YEAR East North Central East South Central Middle Atlantic Mountain  Pacific\n",
            "1: 2012           15400224            2195470         1966640 706313.3 573943.3\n",
            "2: 2013           23207021            3549234         2242007 681648.6 539549.9\n",
            "3: 2014           24833418            3188503         2300202 721978.7 395710.5\n",
            "4: 2015           21137066            2945825         1973972 660333.3 264046.9\n",
            "5: 2016           23471347            3208507         1747401 786382.0 401722.2\n",
            "6: 2017           22885745            2999359         2014284 867571.9 344509.9\n",
            "   South Atlantic West North Central West South Central\n",
            "1:       989985.5           22221529            2843680\n",
            "2:      1311534.8           26077851            3733235\n",
            "3:      1139199.4           27009645            3223621\n",
            "4:       983486.0           28203182            2853237\n",
            "5:      1180162.2           31193319            3710787\n",
            "6:      1173961.1           29733322            3499511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pivot longer\n",
        "\n",
        "In R's data.table, it's possible to transform wide data into long format using the `melt()` function. This function is useful for reshaping data when it's needed to transform a dataset into a format that is more suitable for analysis or visualization. To use the `melt()` function, you first need to specify the data.table object that contains the data you want to reshape. Then, you need to set the variables that you want to retain as the `id.vars` argument, which will keep these variables in the reshaped dataset. Finally, you will need to specify the variables that you want to reshape as the `measure.vars` argument, which will be used to create the new variables in the reshaped dataset.\n",
        "\n",
        "The `melt()` function can be used to pivot a data frame from a wide format to a long format."
      ],
      "metadata": {
        "id": "UWh5fSgJHLmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "dt.longer<-dt.wider |>\n",
        "               melt(id.vars = \"YEAR\",\n",
        "               value.name = \"MT\",\n",
        "               variable.name = \"DIVISION_NAME\",)\n",
        "head(dt.longer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqdGV2gro-bH",
        "outputId": "359dd38d-c816-447b-8a2e-2afc4998a2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   YEAR      DIVISION_NAME       MT\n",
            "1: 2012 East North Central 15400224\n",
            "2: 2013 East North Central 23207021\n",
            "3: 2014 East North Central 24833418\n",
            "4: 2015 East North Central 21137066\n",
            "5: 2016 East North Central 23471347\n",
            "6: 2017 East North Central 22885745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary and Conclusion\n",
        "\n",
        "This tutorial explores data wrangling using the R package \"data.table,\" a powerful framework for managing large datasets. We will cover data filtering, column selection, grouping, and summarization. Advanced features include indexing, fast joins, and efficient data manipulation. With data. table, you can handle large datasets and complex operations. Practice with diverse datasets to streamline your workflows using the power of data.table."
      ],
      "metadata": {
        "id": "NHmgs1LDVFPJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ovc25MJTsD8"
      },
      "source": [
        "## Reference\n",
        "\n",
        "1.  [Data Wrangling in R: data.table](https://clayford.github.io/dwir/dwr_10_datatable.html)\n",
        "\n",
        "2.  [data.table in R -- The Complete Beginners Guide](https://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOEqQt/Pe4+v07aDiEAJejb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}